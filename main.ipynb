{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5247ddf3-4e56-42d3-8112-54fb9e627965",
   "metadata": {},
   "source": [
    "### References:\n",
    "    https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=cifar\n",
    "    https://github.com/kuangliu/pytorch-cifar/blob/master/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fa0cc9-4b2c-489b-8894-5cf425bdac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de0c46db-3f2d-4c89-94e0-081441925e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "815eb49b-306d-4207-8242-834f24f88607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4995754"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [13, 9, 3, 1])\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ec7b57-8c70-4dbd-997e-cda708fede01",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_BATCH_SIZE_LIMIT = 512\n",
    "\n",
    "def train(model, criterion, optimizer, dataloader, device, scheduler = None, use_scheduler = False, batch_size = 32):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        if batch_size >= GPU_BATCH_SIZE_LIMIT:\n",
    "            if(count == 0):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                count = batch_size/32\n",
    "\n",
    "            output = model(image)\n",
    "\n",
    "            loss = criterion(output, label)*32/batch_size\n",
    "            loss.backward()\n",
    "            count = count - 1\n",
    "\n",
    "            pred = torch.max(output.data, 1)[1]\n",
    "            \n",
    "            cur_correct = (pred == label).sum().item()\n",
    "            cur_loss = loss.item()\n",
    "        \n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(image)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            pred = torch.max(output.data, 1)[1]\n",
    "            cur_correct = (pred == label).sum().item()\n",
    "            cur_loss = loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        train_loss += cur_loss\n",
    "\n",
    "        if use_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "    accuracy = correct/total\n",
    "    train_loss = train_loss/len(dataloader)\n",
    "\n",
    "    return train_loss, accuracy\n",
    "\n",
    "def test(model, criterion, dataloader, device, batch_size = 32):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "                \n",
    "        if batch_size >= GPU_BATCH_SIZE_LIMIT:\n",
    "            if(count == 0):\n",
    "                count = batch_size/32\n",
    "\n",
    "            output = model(image)\n",
    "\n",
    "            loss = criterion(output, label)*32/batch_size\n",
    "            count = count - 1\n",
    "\n",
    "            pred = torch.max(output.data, 1)[1]\n",
    "            \n",
    "            cur_correct = (pred == label).sum().item()\n",
    "            cur_loss = loss.item()\n",
    "        \n",
    "        else:\n",
    "            output = model(image)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            pred = torch.max(output.data, 1)[1]\n",
    "            cur_correct = (pred == label).sum().item()\n",
    "            cur_loss = loss.item()\n",
    "            \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        test_loss += cur_loss\n",
    "\n",
    "    accuracy = correct/total\n",
    "    test_loss = test_loss/len(dataloader)\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dba1f3b-279e-4343-887c-83b99ac4170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d37bb1-65d6-450b-9a15-5116596818b8",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba2f7acc-6063-4a83-8c72-ef8994b8ca5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.7667; Training Accuracy: 50.012%\n",
      "\tTesting Loss: 1.0856; Testing Accuracy: 60.96%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.8884; Training Accuracy: 66.552%\n",
      "\tTesting Loss: 0.866; Testing Accuracy: 69.59%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.4736; Training Accuracy: 73.988%\n",
      "\tTesting Loss: 0.7729; Testing Accuracy: 72.5%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.1534; Training Accuracy: 79.998%\n",
      "\tTesting Loss: 0.6941; Testing Accuracy: 75.57%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 0.9014; Training Accuracy: 84.61%\n",
      "\tTesting Loss: 0.6739; Testing Accuracy: 77.01%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0108be6-851d-44b3-a43d-d1de666a3a7c",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb550f5c-2075-4dbe-8456-ce27f5c57ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.9655; Training Accuracy: 45.326%\n",
      "\tTesting Loss: 1.1382; Testing Accuracy: 58.93%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.143; Training Accuracy: 61.744%\n",
      "\tTesting Loss: 1.0245; Testing Accuracy: 64.76%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.7926; Training Accuracy: 68.48%\n",
      "\tTesting Loss: 0.9324; Testing Accuracy: 67.98%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.5641; Training Accuracy: 72.524%\n",
      "\tTesting Loss: 0.7302; Testing Accuracy: 74.19%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.3962; Training Accuracy: 75.616%\n",
      "\tTesting Loss: 0.6483; Testing Accuracy: 77.49%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf8e6fd-a163-445d-9553-da3335e760be",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48025e37-5931-403d-8737-f4b46d475db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.8723; Training Accuracy: 47.636%\n",
      "\tTesting Loss: 1.2933; Testing Accuracy: 56.78%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.9635; Training Accuracy: 65.19%\n",
      "\tTesting Loss: 0.9888; Testing Accuracy: 66.12%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.5566; Training Accuracy: 73.154%\n",
      "\tTesting Loss: 0.7659; Testing Accuracy: 73.7%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.3297; Training Accuracy: 76.942%\n",
      "\tTesting Loss: 0.6325; Testing Accuracy: 78.42%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.1761; Training Accuracy: 79.468%\n",
      "\tTesting Loss: 0.5846; Testing Accuracy: 80.94%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c9e8f-aeb2-409f-8505-93f9042ecf6e",
   "metadata": {},
   "source": [
    "### Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcab3701-5097-478a-8d42-0f3c36bc1ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.2463; Training Accuracy: 40.35%\n",
      "\tTesting Loss: 1.2443; Testing Accuracy: 54.71%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.2736; Training Accuracy: 59.376%\n",
      "\tTesting Loss: 1.0165; Testing Accuracy: 65.18%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.8031; Training Accuracy: 68.314%\n",
      "\tTesting Loss: 0.8641; Testing Accuracy: 69.9%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.5125; Training Accuracy: 73.568%\n",
      "\tTesting Loss: 0.7711; Testing Accuracy: 73.79%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.3173; Training Accuracy: 77.168%\n",
      "\tTesting Loss: 0.6735; Testing Accuracy: 77.68%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b3922-c460-445c-8ee6-8686a61ab07b",
   "metadata": {},
   "source": [
    "### Experiment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bd2ac63-c433-4dd7-b821-7ed4348b855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.3944; Training Accuracy: 37.364%\n",
      "\tTesting Loss: 1.4196; Testing Accuracy: 48.3%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.7294; Training Accuracy: 50.724%\n",
      "\tTesting Loss: 1.3531; Testing Accuracy: 56.6%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.4085; Training Accuracy: 57.072%\n",
      "\tTesting Loss: 1.1211; Testing Accuracy: 61.84%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 2.1639; Training Accuracy: 61.616%\n",
      "\tTesting Loss: 0.9121; Testing Accuracy: 68.48%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.9941; Training Accuracy: 64.97%\n",
      "\tTesting Loss: 0.9682; Testing Accuracy: 66.47%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "    torchvision.transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c21d18-438d-4107-ba1a-64b90a9e68cf",
   "metadata": {},
   "source": [
    "### Experiment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f268bc16-f3a8-4874-bc58-e62669fb4c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.3209; Training Accuracy: 38.834%\n",
      "\tTesting Loss: 1.3701; Testing Accuracy: 51.43%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.6639; Training Accuracy: 51.722%\n",
      "\tTesting Loss: 1.3112; Testing Accuracy: 55.95%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.3437; Training Accuracy: 58.34%\n",
      "\tTesting Loss: 1.0078; Testing Accuracy: 65.06%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 2.1284; Training Accuracy: 62.414%\n",
      "\tTesting Loss: 0.9128; Testing Accuracy: 68.87%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.9559; Training Accuracy: 65.542%\n",
      "\tTesting Loss: 0.7819; Testing Accuracy: 72.9%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "    torchvision.transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e20ae-6e9f-4fc0-9966-d7a087ffde60",
   "metadata": {},
   "source": [
    "### Experiment 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43a2f6ab-47fe-4e30-a26d-0f0953cab888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.642; Training Accuracy: 32.844%\n",
      "\tTesting Loss: 1.4509; Testing Accuracy: 46.77%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.9684; Training Accuracy: 45.978%\n",
      "\tTesting Loss: 1.4119; Testing Accuracy: 53.14%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.5526; Training Accuracy: 54.442%\n",
      "\tTesting Loss: 1.1424; Testing Accuracy: 61.25%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 2.2957; Training Accuracy: 59.394%\n",
      "\tTesting Loss: 1.2255; Testing Accuracy: 60.57%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 2.1109; Training Accuracy: 62.856%\n",
      "\tTesting Loss: 0.9835; Testing Accuracy: 67.76%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "    torchvision.transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd412ee-810e-44c5-b645-97adbbd899a4",
   "metadata": {},
   "source": [
    "### Experiment 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e98d446-1a74-4000-b406-e438e466af09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.0835; Training Accuracy: 43.502%\n",
      "\tTesting Loss: 1.1675; Testing Accuracy: 58.22%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.3042; Training Accuracy: 58.644%\n",
      "\tTesting Loss: 1.1658; Testing Accuracy: 60.2%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.9298; Training Accuracy: 65.832%\n",
      "\tTesting Loss: 0.9036; Testing Accuracy: 69.68%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.6952; Training Accuracy: 70.314%\n",
      "\tTesting Loss: 0.8469; Testing Accuracy: 72.64%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.5312; Training Accuracy: 73.14%\n",
      "\tTesting Loss: 0.7011; Testing Accuracy: 76.33%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324f816e-cd31-41db-81a4-ca598bd75102",
   "metadata": {},
   "source": [
    "### Experiment 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d18fc85d-8073-4cc1-9798-363432eb9ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.9925; Training Accuracy: 45.42%\n",
      "\tTesting Loss: 1.1651; Testing Accuracy: 57.68%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.1577; Training Accuracy: 61.398%\n",
      "\tTesting Loss: 0.9998; Testing Accuracy: 64.76%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.8073; Training Accuracy: 68.032%\n",
      "\tTesting Loss: 0.8095; Testing Accuracy: 72.64%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.5712; Training Accuracy: 72.424%\n",
      "\tTesting Loss: 0.6548; Testing Accuracy: 77.54%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.412; Training Accuracy: 75.32%\n",
      "\tTesting Loss: 0.6788; Testing Accuracy: 77.39%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497b691-3556-4411-af5c-7e9303265f4e",
   "metadata": {},
   "source": [
    "### Experiment 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55771e92-1f51-484d-8f40-5ee02574ad57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.1113; Training Accuracy: 42.69%\n",
      "\tTesting Loss: 1.3343; Testing Accuracy: 53.07%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.3764; Training Accuracy: 57.158%\n",
      "\tTesting Loss: 1.1477; Testing Accuracy: 61.64%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.0474; Training Accuracy: 63.578%\n",
      "\tTesting Loss: 0.9351; Testing Accuracy: 67.49%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.7978; Training Accuracy: 68.458%\n",
      "\tTesting Loss: 0.7166; Testing Accuracy: 75.16%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.6213; Training Accuracy: 71.424%\n",
      "\tTesting Loss: 0.6531; Testing Accuracy: 77.36%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff65595-8fa6-40e0-b19b-63ea81432fa6",
   "metadata": {},
   "source": [
    "### Experiment 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad54e1f8-3e8a-4bc5-bc67-7e4fde96179e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.302; Training Accuracy: 39.422%\n",
      "\tTesting Loss: 1.254; Testing Accuracy: 53.81%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.5051; Training Accuracy: 54.63%\n",
      "\tTesting Loss: 1.0566; Testing Accuracy: 63.47%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.1467; Training Accuracy: 61.798%\n",
      "\tTesting Loss: 0.9029; Testing Accuracy: 68.43%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.8728; Training Accuracy: 66.908%\n",
      "\tTesting Loss: 0.884; Testing Accuracy: 70.27%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.6656; Training Accuracy: 70.648%\n",
      "\tTesting Loss: 0.6646; Testing Accuracy: 77.54%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc2731-116d-4374-a31d-a82246055317",
   "metadata": {},
   "source": [
    "### Experiment 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abe9d44f-7710-4615-813c-7cbdbaa12b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.4; Training Accuracy: 36.974%\n",
      "\tTesting Loss: 1.3463; Testing Accuracy: 49.1%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.62; Training Accuracy: 52.444%\n",
      "\tTesting Loss: 1.1415; Testing Accuracy: 59.94%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.218; Training Accuracy: 60.346%\n",
      "\tTesting Loss: 0.9475; Testing Accuracy: 66.81%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.975; Training Accuracy: 65.116%\n",
      "\tTesting Loss: 0.8218; Testing Accuracy: 71.99%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.7621; Training Accuracy: 69.124%\n",
      "\tTesting Loss: 0.742; Testing Accuracy: 73.55%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.075, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de656da-e0b6-40b3-aaf7-dc6140bca916",
   "metadata": {},
   "source": [
    "### Experiment 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "951eded4-4c7b-45c7-9a64-a67216d9fd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.3515; Training Accuracy: 38.206%\n",
      "\tTesting Loss: 1.458; Testing Accuracy: 48.59%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.5859; Training Accuracy: 52.998%\n",
      "\tTesting Loss: 1.1997; Testing Accuracy: 57.94%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.2156; Training Accuracy: 60.366%\n",
      "\tTesting Loss: 0.9809; Testing Accuracy: 65.84%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.9713; Training Accuracy: 65.284%\n",
      "\tTesting Loss: 0.8788; Testing Accuracy: 70.32%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.7682; Training Accuracy: 68.818%\n",
      "\tTesting Loss: 0.7629; Testing Accuracy: 72.58%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.06, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0098e6df-43ab-47a0-85f9-99ac018ce2d5",
   "metadata": {},
   "source": [
    "### Experiment 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f677bbf-042d-4001-9e75-dcfa0e75c3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.3225; Training Accuracy: 38.332%\n",
      "\tTesting Loss: 1.3154; Testing Accuracy: 53.49%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.5591; Training Accuracy: 53.814%\n",
      "\tTesting Loss: 1.1136; Testing Accuracy: 61.09%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.1821; Training Accuracy: 61.154%\n",
      "\tTesting Loss: 0.9609; Testing Accuracy: 67.25%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.9458; Training Accuracy: 65.308%\n",
      "\tTesting Loss: 0.9409; Testing Accuracy: 68.38%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.7446; Training Accuracy: 69.02%\n",
      "\tTesting Loss: 0.8189; Testing Accuracy: 70.96%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.04, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8705b4-4cd1-4d73-ba65-8133fd870d40",
   "metadata": {},
   "source": [
    "### Experiment 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65abbf27-7465-416c-bf6f-bf9739ce91ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.3325; Training Accuracy: 38.806%\n",
      "\tTesting Loss: 1.3085; Testing Accuracy: 51.63%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.5593; Training Accuracy: 53.708%\n",
      "\tTesting Loss: 1.0251; Testing Accuracy: 63.24%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.1877; Training Accuracy: 60.898%\n",
      "\tTesting Loss: 1.0142; Testing Accuracy: 65.27%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.9567; Training Accuracy: 65.5%\n",
      "\tTesting Loss: 0.8049; Testing Accuracy: 71.62%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.7464; Training Accuracy: 69.264%\n",
      "\tTesting Loss: 0.8074; Testing Accuracy: 73.08%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.055, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b7694-5729-4559-9b53-1a72ca5aa34b",
   "metadata": {},
   "source": [
    "### Experiment 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64a4b70e-01d3-4fd2-b7bb-80eca2b3a060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.2998; Training Accuracy: 39.026%\n",
      "\tTesting Loss: 1.4011; Testing Accuracy: 49.13%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.5151; Training Accuracy: 54.708%\n",
      "\tTesting Loss: 1.1535; Testing Accuracy: 60.21%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.1415; Training Accuracy: 61.882%\n",
      "\tTesting Loss: 0.8952; Testing Accuracy: 68.29%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.8932; Training Accuracy: 66.546%\n",
      "\tTesting Loss: 0.9351; Testing Accuracy: 68.3%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.6797; Training Accuracy: 70.32%\n",
      "\tTesting Loss: 0.7241; Testing Accuracy: 75.16%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece6cce7-6788-4e01-adfc-3d787d8096ca",
   "metadata": {},
   "source": [
    "### Experiment 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55ecbbd9-677c-4c42-8e77-2dd18ee007b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.3636; Training Accuracy: 38.234%\n",
      "\tTesting Loss: 1.3329; Testing Accuracy: 51.38%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.6387; Training Accuracy: 52.36%\n",
      "\tTesting Loss: 1.2368; Testing Accuracy: 56.9%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.2993; Training Accuracy: 58.896%\n",
      "\tTesting Loss: 1.0868; Testing Accuracy: 63.22%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 2.1267; Training Accuracy: 62.364%\n",
      "\tTesting Loss: 0.939; Testing Accuracy: 67.81%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.968; Training Accuracy: 65.744%\n",
      "\tTesting Loss: 0.9173; Testing Accuracy: 69.4%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca67c4c-3691-47ef-b756-b82d103f6118",
   "metadata": {},
   "source": [
    "### Experiment 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b64ca4f-9688-44ac-bca8-6f57bf7fdf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.3376; Training Accuracy: 38.508%\n",
      "\tTesting Loss: 1.366; Testing Accuracy: 50.21%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.5915; Training Accuracy: 53.026%\n",
      "\tTesting Loss: 1.1001; Testing Accuracy: 60.88%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.2289; Training Accuracy: 60.142%\n",
      "\tTesting Loss: 1.0309; Testing Accuracy: 63.19%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.9933; Training Accuracy: 64.85%\n",
      "\tTesting Loss: 0.9037; Testing Accuracy: 68.69%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.777; Training Accuracy: 68.81%\n",
      "\tTesting Loss: 0.7885; Testing Accuracy: 73.21%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=0.0002)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c729f-bde3-45b4-82da-6843aa18fae7",
   "metadata": {},
   "source": [
    "### Experiment 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1160a0e7-b961-4224-bd44-998feaa44fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.2079; Training Accuracy: 41.196%\n",
      "\tTesting Loss: 1.2863; Testing Accuracy: 54.28%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.4307; Training Accuracy: 56.526%\n",
      "\tTesting Loss: 1.0198; Testing Accuracy: 64.29%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.092; Training Accuracy: 62.956%\n",
      "\tTesting Loss: 0.9101; Testing Accuracy: 67.67%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.855; Training Accuracy: 67.366%\n",
      "\tTesting Loss: 0.7747; Testing Accuracy: 72.99%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.6575; Training Accuracy: 71.082%\n",
      "\tTesting Loss: 0.697; Testing Accuracy: 76.1%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3a5c7-d3ca-4c07-842b-810ad506b847",
   "metadata": {},
   "source": [
    "### Experiment 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df12ec10-1aeb-44f3-b12c-eb16075fbcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.2406; Training Accuracy: 40.342%\n",
      "\tTesting Loss: 1.3901; Testing Accuracy: 52.03%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.443; Training Accuracy: 55.966%\n",
      "\tTesting Loss: 1.0469; Testing Accuracy: 61.85%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.0991; Training Accuracy: 62.636%\n",
      "\tTesting Loss: 0.8484; Testing Accuracy: 69.9%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.8708; Training Accuracy: 66.786%\n",
      "\tTesting Loss: 0.7403; Testing Accuracy: 74.14%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.6816; Training Accuracy: 70.416%\n",
      "\tTesting Loss: 0.7146; Testing Accuracy: 75.79%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 1.539; Training Accuracy: 73.148%\n",
      "\tTesting Loss: 0.6257; Testing Accuracy: 78.99%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 1.4279; Training Accuracy: 74.998%\n",
      "\tTesting Loss: 0.6519; Testing Accuracy: 77.7%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 1.3414; Training Accuracy: 76.54%\n",
      "\tTesting Loss: 0.5664; Testing Accuracy: 81.08%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 1.2728; Training Accuracy: 77.676%\n",
      "\tTesting Loss: 0.5281; Testing Accuracy: 82.22%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 1.2187; Training Accuracy: 78.68%\n",
      "\tTesting Loss: 0.507; Testing Accuracy: 83.23%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 1.1776; Training Accuracy: 79.62%\n",
      "\tTesting Loss: 0.5365; Testing Accuracy: 82.25%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 1.137; Training Accuracy: 80.2%\n",
      "\tTesting Loss: 0.4838; Testing Accuracy: 84.03%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 1.1035; Training Accuracy: 80.926%\n",
      "\tTesting Loss: 0.4599; Testing Accuracy: 84.8%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 1.0747; Training Accuracy: 81.252%\n",
      "\tTesting Loss: 0.492; Testing Accuracy: 83.8%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 1.0483; Training Accuracy: 81.796%\n",
      "\tTesting Loss: 0.4411; Testing Accuracy: 84.27%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 1.0264; Training Accuracy: 82.216%\n",
      "\tTesting Loss: 0.5059; Testing Accuracy: 83.04%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 1.0041; Training Accuracy: 82.516%\n",
      "\tTesting Loss: 0.4315; Testing Accuracy: 85.46%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.9821; Training Accuracy: 83.044%\n",
      "\tTesting Loss: 0.5178; Testing Accuracy: 82.92%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.967; Training Accuracy: 83.104%\n",
      "\tTesting Loss: 0.5078; Testing Accuracy: 83.15%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.9539; Training Accuracy: 83.376%\n",
      "\tTesting Loss: 0.3991; Testing Accuracy: 86.49%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.9449; Training Accuracy: 83.62%\n",
      "\tTesting Loss: 0.4091; Testing Accuracy: 86.46%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.9287; Training Accuracy: 83.954%\n",
      "\tTesting Loss: 0.4133; Testing Accuracy: 85.85%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.9212; Training Accuracy: 83.9%\n",
      "\tTesting Loss: 0.4385; Testing Accuracy: 85.17%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.8993; Training Accuracy: 84.38%\n",
      "\tTesting Loss: 0.4135; Testing Accuracy: 86.06%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.8933; Training Accuracy: 84.488%\n",
      "\tTesting Loss: 0.3938; Testing Accuracy: 87.02%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f15649e-f827-42bd-ab03-8427bfb4a237",
   "metadata": {},
   "source": [
    "### Experiment 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "664c91f0-907e-417d-9fb5-1b1c0ce91eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.134; Training Accuracy: 42.594%\n",
      "\tTesting Loss: 1.258; Testing Accuracy: 53.98%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.3799; Training Accuracy: 56.926%\n",
      "\tTesting Loss: 1.0215; Testing Accuracy: 64.19%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.0249; Training Accuracy: 64.034%\n",
      "\tTesting Loss: 0.9987; Testing Accuracy: 66.57%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.8068; Training Accuracy: 68.006%\n",
      "\tTesting Loss: 0.7703; Testing Accuracy: 73.37%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.6042; Training Accuracy: 71.846%\n",
      "\tTesting Loss: 0.7841; Testing Accuracy: 73.34%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 1.4742; Training Accuracy: 73.964%\n",
      "\tTesting Loss: 0.6081; Testing Accuracy: 79.2%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 1.3671; Training Accuracy: 76.096%\n",
      "\tTesting Loss: 0.6307; Testing Accuracy: 79.78%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 1.2678; Training Accuracy: 77.608%\n",
      "\tTesting Loss: 0.5951; Testing Accuracy: 80.1%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 1.1985; Training Accuracy: 78.916%\n",
      "\tTesting Loss: 0.5621; Testing Accuracy: 81.47%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 1.149; Training Accuracy: 79.946%\n",
      "\tTesting Loss: 0.5184; Testing Accuracy: 83.17%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 1.0909; Training Accuracy: 80.876%\n",
      "\tTesting Loss: 0.4891; Testing Accuracy: 83.35%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 1.0479; Training Accuracy: 81.786%\n",
      "\tTesting Loss: 0.5223; Testing Accuracy: 82.08%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 1.0021; Training Accuracy: 82.536%\n",
      "\tTesting Loss: 0.4815; Testing Accuracy: 83.93%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.9724; Training Accuracy: 83.11%\n",
      "\tTesting Loss: 0.4643; Testing Accuracy: 84.32%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.9417; Training Accuracy: 83.528%\n",
      "\tTesting Loss: 0.4125; Testing Accuracy: 86.33%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.9036; Training Accuracy: 84.328%\n",
      "\tTesting Loss: 0.4603; Testing Accuracy: 85.07%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.8804; Training Accuracy: 84.574%\n",
      "\tTesting Loss: 0.4317; Testing Accuracy: 86.27%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.8612; Training Accuracy: 85.018%\n",
      "\tTesting Loss: 0.4082; Testing Accuracy: 86.87%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.8476; Training Accuracy: 85.214%\n",
      "\tTesting Loss: 0.3842; Testing Accuracy: 87.33%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.8215; Training Accuracy: 85.788%\n",
      "\tTesting Loss: 0.4027; Testing Accuracy: 86.65%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.807; Training Accuracy: 85.978%\n",
      "\tTesting Loss: 0.3891; Testing Accuracy: 87.25%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.7833; Training Accuracy: 86.414%\n",
      "\tTesting Loss: 0.3678; Testing Accuracy: 87.64%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.7691; Training Accuracy: 86.614%\n",
      "\tTesting Loss: 0.3872; Testing Accuracy: 87.74%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.7616; Training Accuracy: 86.654%\n",
      "\tTesting Loss: 0.4045; Testing Accuracy: 86.81%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.7453; Training Accuracy: 86.9%\n",
      "\tTesting Loss: 0.39; Testing Accuracy: 87.24%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = 64)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = 64)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fee704-fed4-46a7-bded-3da5fc56adf1",
   "metadata": {},
   "source": [
    "### Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5202054f-2397-493f-9ad9-86f3daf74111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: no; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.8012; Training Accuracy   : 49.294%\n",
      "\tValidation Loss : 1.2899; Validation Accuracy : 56.95%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.775; Training Accuracy   : 68.76%\n",
      "\tValidation Loss : 0.7429; Validation Accuracy : 74.31%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.3327; Training Accuracy   : 76.552%\n",
      "\tValidation Loss : 0.6936; Validation Accuracy : 76.33%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.0503; Training Accuracy   : 81.54%\n",
      "\tValidation Loss : 0.6543; Validation Accuracy : 77.69%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 0.8564; Training Accuracy   : 85.174%\n",
      "\tValidation Loss : 0.5525; Validation Accuracy : 81.19%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: no; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.6844; Training Accuracy   : 51.362%\n",
      "\tValidation Loss : 1.0871; Validation Accuracy : 61.0%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.7076; Training Accuracy   : 69.988%\n",
      "\tValidation Loss : 0.7884; Validation Accuracy : 72.62%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.2862; Training Accuracy   : 77.544%\n",
      "\tValidation Loss : 0.7082; Validation Accuracy : 75.47%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.0202; Training Accuracy   : 82.366%\n",
      "\tValidation Loss : 0.614; Validation Accuracy : 79.24%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 0.8243; Training Accuracy   : 85.348%\n",
      "\tValidation Loss : 0.5511; Validation Accuracy : 81.77%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: no; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.2087; Training Accuracy   : 41.516%\n",
      "\tValidation Loss : 1.289; Validation Accuracy : 52.65%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.0841; Training Accuracy   : 62.91%\n",
      "\tValidation Loss : 0.9269; Validation Accuracy : 66.32%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.5864; Training Accuracy   : 72.054%\n",
      "\tValidation Loss : 1.1529; Validation Accuracy : 63.21%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.2805; Training Accuracy   : 77.584%\n",
      "\tValidation Loss : 0.782; Validation Accuracy : 73.99%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.0492; Training Accuracy   : 81.768%\n",
      "\tValidation Loss : 0.8107; Validation Accuracy : 73.52%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: no; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.8083; Training Accuracy   : 49.138%\n",
      "\tValidation Loss : 1.6449; Validation Accuracy : 46.02%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.5797; Training Accuracy   : 54.068%\n",
      "\tValidation Loss : 1.3326; Validation Accuracy : 51.81%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.4893; Training Accuracy   : 55.744%\n",
      "\tValidation Loss : 1.427; Validation Accuracy : 49.85%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.4984; Training Accuracy   : 55.422%\n",
      "\tValidation Loss : 10.8278; Validation Accuracy : 22.75%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.586; Training Accuracy   : 54.276%\n",
      "\tValidation Loss : 1.6591; Validation Accuracy : 40.51%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: no; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.5843; Training Accuracy   : 53.388%\n",
      "\tValidation Loss : 1.1917; Validation Accuracy : 58.61%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.0846; Training Accuracy   : 63.268%\n",
      "\tValidation Loss : 1.0144; Validation Accuracy : 64.51%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.9046; Training Accuracy   : 66.962%\n",
      "\tValidation Loss : 0.9383; Validation Accuracy : 67.44%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.8169; Training Accuracy   : 68.344%\n",
      "\tValidation Loss : 0.9816; Validation Accuracy : 66.25%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.8408; Training Accuracy   : 67.942%\n",
      "\tValidation Loss : 1.02; Validation Accuracy : 64.22%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: no; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.4438; Training Accuracy   : 37.636%\n",
      "\tValidation Loss : 1.3661; Validation Accuracy : 49.24%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3845; Training Accuracy   : 57.576%\n",
      "\tValidation Loss : 1.0988; Validation Accuracy : 60.83%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.842; Training Accuracy   : 67.662%\n",
      "\tValidation Loss : 1.1965; Validation Accuracy : 59.84%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.4597; Training Accuracy   : 74.584%\n",
      "\tValidation Loss : 0.8411; Validation Accuracy : 71.18%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.1779; Training Accuracy   : 79.542%\n",
      "\tValidation Loss : 0.7857; Validation Accuracy : 73.56%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_crop; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.0316; Training Accuracy   : 44.624%\n",
      "\tValidation Loss : 1.3374; Validation Accuracy : 52.88%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.0382; Training Accuracy   : 63.812%\n",
      "\tValidation Loss : 0.9409; Validation Accuracy : 67.5%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.5774; Training Accuracy   : 72.444%\n",
      "\tValidation Loss : 0.7908; Validation Accuracy : 72.77%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3289; Training Accuracy   : 76.906%\n",
      "\tValidation Loss : 0.6859; Validation Accuracy : 77.24%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.156; Training Accuracy   : 79.888%\n",
      "\tValidation Loss : 0.5439; Validation Accuracy : 81.51%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_crop; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9429; Training Accuracy   : 46.478%\n",
      "\tValidation Loss : 1.1542; Validation Accuracy : 58.72%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9995; Training Accuracy   : 64.508%\n",
      "\tValidation Loss : 0.9386; Validation Accuracy : 67.9%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.5571; Training Accuracy   : 72.79%\n",
      "\tValidation Loss : 0.804; Validation Accuracy : 72.27%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3121; Training Accuracy   : 77.262%\n",
      "\tValidation Loss : 0.6096; Validation Accuracy : 79.18%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.1477; Training Accuracy   : 80.24%\n",
      "\tValidation Loss : 0.5783; Validation Accuracy : 80.63%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_crop; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.4082; Training Accuracy   : 37.446%\n",
      "\tValidation Loss : 1.4353; Validation Accuracy : 47.12%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3487; Training Accuracy   : 57.986%\n",
      "\tValidation Loss : 1.112; Validation Accuracy : 61.2%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8226; Training Accuracy   : 67.762%\n",
      "\tValidation Loss : 1.3867; Validation Accuracy : 59.27%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.532; Training Accuracy   : 73.084%\n",
      "\tValidation Loss : 1.0403; Validation Accuracy : 68.58%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.3454; Training Accuracy   : 76.532%\n",
      "\tValidation Loss : 0.8756; Validation Accuracy : 71.68%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_crop; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.072; Training Accuracy   : 43.792%\n",
      "\tValidation Loss : 1.9008; Validation Accuracy : 37.11%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.8224; Training Accuracy   : 49.034%\n",
      "\tValidation Loss : 1.6039; Validation Accuracy : 42.76%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.7894; Training Accuracy   : 49.628%\n",
      "\tValidation Loss : 2.0717; Validation Accuracy : 38.93%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.8224; Training Accuracy   : 49.272%\n",
      "\tValidation Loss : 1.5417; Validation Accuracy : 44.56%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.913; Training Accuracy   : 47.858%\n",
      "\tValidation Loss : 5.4199; Validation Accuracy : 24.99%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_crop; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9269; Training Accuracy   : 46.614%\n",
      "\tValidation Loss : 1.3105; Validation Accuracy : 54.05%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3789; Training Accuracy   : 57.784%\n",
      "\tValidation Loss : 1.4816; Validation Accuracy : 50.41%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.1229; Training Accuracy   : 62.76%\n",
      "\tValidation Loss : 1.1731; Validation Accuracy : 59.49%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.0141; Training Accuracy   : 64.992%\n",
      "\tValidation Loss : 1.066; Validation Accuracy : 63.43%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.0268; Training Accuracy   : 64.588%\n",
      "\tValidation Loss : 1.3379; Validation Accuracy : 56.64%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_crop; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.6195; Training Accuracy   : 33.814%\n",
      "\tValidation Loss : 1.4175; Validation Accuracy : 47.93%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.6114; Training Accuracy   : 52.982%\n",
      "\tValidation Loss : 1.246; Validation Accuracy : 55.9%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.1184; Training Accuracy   : 62.372%\n",
      "\tValidation Loss : 1.1073; Validation Accuracy : 61.81%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.7526; Training Accuracy   : 69.028%\n",
      "\tValidation Loss : 1.0; Validation Accuracy : 67.53%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.4913; Training Accuracy   : 74.086%\n",
      "\tValidation Loss : 1.6317; Validation Accuracy : 58.35%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_horizontal_flip; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.7745; Training Accuracy   : 49.914%\n",
      "\tValidation Loss : 1.3166; Validation Accuracy : 55.08%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.7787; Training Accuracy   : 68.486%\n",
      "\tValidation Loss : 0.7821; Validation Accuracy : 72.58%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.3559; Training Accuracy   : 76.364%\n",
      "\tValidation Loss : 0.6769; Validation Accuracy : 76.82%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.128; Training Accuracy   : 80.37%\n",
      "\tValidation Loss : 0.5706; Validation Accuracy : 80.75%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 0.968; Training Accuracy   : 83.114%\n",
      "\tValidation Loss : 0.6707; Validation Accuracy : 76.72%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_horizontal_flip; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.7077; Training Accuracy   : 51.112%\n",
      "\tValidation Loss : 1.355; Validation Accuracy : 54.31%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.7229; Training Accuracy   : 69.894%\n",
      "\tValidation Loss : 0.8562; Validation Accuracy : 70.38%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.314; Training Accuracy   : 77.192%\n",
      "\tValidation Loss : 0.7527; Validation Accuracy : 74.48%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.0898; Training Accuracy   : 81.192%\n",
      "\tValidation Loss : 0.6155; Validation Accuracy : 79.0%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 0.9467; Training Accuracy   : 83.478%\n",
      "\tValidation Loss : 0.5977; Validation Accuracy : 79.6%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_horizontal_flip; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.194; Training Accuracy   : 41.704%\n",
      "\tValidation Loss : 1.9293; Validation Accuracy : 44.01%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.1009; Training Accuracy   : 62.6%\n",
      "\tValidation Loss : 1.0196; Validation Accuracy : 63.7%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.6503; Training Accuracy   : 70.974%\n",
      "\tValidation Loss : 1.2185; Validation Accuracy : 60.94%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3536; Training Accuracy   : 76.372%\n",
      "\tValidation Loss : 0.8217; Validation Accuracy : 72.12%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.1583; Training Accuracy   : 79.886%\n",
      "\tValidation Loss : 1.0576; Validation Accuracy : 66.96%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_horizontal_flip; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.7945; Training Accuracy   : 49.182%\n",
      "\tValidation Loss : 1.6636; Validation Accuracy : 44.89%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.5266; Training Accuracy   : 54.988%\n",
      "\tValidation Loss : 1.4239; Validation Accuracy : 50.61%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.4852; Training Accuracy   : 55.776%\n",
      "\tValidation Loss : 1.1765; Validation Accuracy : 57.94%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.4885; Training Accuracy   : 55.932%\n",
      "\tValidation Loss : 1.6033; Validation Accuracy : 44.51%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.5648; Training Accuracy   : 54.668%\n",
      "\tValidation Loss : 2.0194; Validation Accuracy : 41.25%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_horizontal_flip; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.6278; Training Accuracy   : 52.46%\n",
      "\tValidation Loss : 1.3196; Validation Accuracy : 54.09%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.1188; Training Accuracy   : 62.846%\n",
      "\tValidation Loss : 1.1255; Validation Accuracy : 60.21%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.9097; Training Accuracy   : 66.65%\n",
      "\tValidation Loss : 1.0055; Validation Accuracy : 65.17%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.8345; Training Accuracy   : 68.258%\n",
      "\tValidation Loss : 1.016; Validation Accuracy : 66.5%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.872; Training Accuracy   : 67.306%\n",
      "\tValidation Loss : 1.2257; Validation Accuracy : 58.71%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_horizontal_flip; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.4301; Training Accuracy   : 37.59%\n",
      "\tValidation Loss : 1.3868; Validation Accuracy : 49.22%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3761; Training Accuracy   : 57.378%\n",
      "\tValidation Loss : 1.0642; Validation Accuracy : 61.34%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8406; Training Accuracy   : 67.708%\n",
      "\tValidation Loss : 1.0486; Validation Accuracy : 62.75%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.4956; Training Accuracy   : 73.866%\n",
      "\tValidation Loss : 0.8278; Validation Accuracy : 70.86%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.262; Training Accuracy   : 77.896%\n",
      "\tValidation Loss : 1.293; Validation Accuracy : 63.06%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_rotate; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9392; Training Accuracy   : 46.32%\n",
      "\tValidation Loss : 1.1476; Validation Accuracy : 59.34%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.0223; Training Accuracy   : 64.014%\n",
      "\tValidation Loss : 0.973; Validation Accuracy : 65.99%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.6032; Training Accuracy   : 71.698%\n",
      "\tValidation Loss : 0.7183; Validation Accuracy : 74.29%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3566; Training Accuracy   : 76.162%\n",
      "\tValidation Loss : 0.6463; Validation Accuracy : 77.44%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.2001; Training Accuracy   : 79.07%\n",
      "\tValidation Loss : 0.5999; Validation Accuracy : 79.97%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_rotate; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.8566; Training Accuracy   : 47.98%\n",
      "\tValidation Loss : 1.1485; Validation Accuracy : 58.59%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9858; Training Accuracy   : 64.838%\n",
      "\tValidation Loss : 0.8718; Validation Accuracy : 69.09%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.5694; Training Accuracy   : 72.536%\n",
      "\tValidation Loss : 0.6509; Validation Accuracy : 77.28%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3239; Training Accuracy   : 76.996%\n",
      "\tValidation Loss : 0.5922; Validation Accuracy : 79.46%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.1611; Training Accuracy   : 79.84%\n",
      "\tValidation Loss : 0.6095; Validation Accuracy : 78.65%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_rotate; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.3301; Training Accuracy   : 39.154%\n",
      "\tValidation Loss : 1.4347; Validation Accuracy : 48.02%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3291; Training Accuracy   : 58.222%\n",
      "\tValidation Loss : 1.1787; Validation Accuracy : 59.25%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8836; Training Accuracy   : 66.634%\n",
      "\tValidation Loss : 0.9889; Validation Accuracy : 65.92%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.5886; Training Accuracy   : 72.088%\n",
      "\tValidation Loss : 0.7704; Validation Accuracy : 73.28%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.3801; Training Accuracy   : 75.81%\n",
      "\tValidation Loss : 0.9239; Validation Accuracy : 69.67%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_rotate; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.0174; Training Accuracy   : 44.984%\n",
      "\tValidation Loss : 1.9903; Validation Accuracy : 37.83%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.8741; Training Accuracy   : 47.812%\n",
      "\tValidation Loss : 1.8225; Validation Accuracy : 39.66%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.8504; Training Accuracy   : 48.254%\n",
      "\tValidation Loss : 1.4185; Validation Accuracy : 49.54%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.8537; Training Accuracy   : 48.302%\n",
      "\tValidation Loss : 1.8232; Validation Accuracy : 41.16%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.9183; Training Accuracy   : 47.036%\n",
      "\tValidation Loss : 1.878; Validation Accuracy : 37.95%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_rotate; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.7961; Training Accuracy   : 49.398%\n",
      "\tValidation Loss : 1.7747; Validation Accuracy : 47.92%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.341; Training Accuracy   : 58.7%\n",
      "\tValidation Loss : 1.1194; Validation Accuracy : 60.48%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.1478; Training Accuracy   : 62.1%\n",
      "\tValidation Loss : 1.0177; Validation Accuracy : 64.71%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.0828; Training Accuracy   : 63.334%\n",
      "\tValidation Loss : 0.9821; Validation Accuracy : 65.47%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.112; Training Accuracy   : 62.882%\n",
      "\tValidation Loss : 1.0828; Validation Accuracy : 63.03%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_rotate; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.5058; Training Accuracy   : 36.298%\n",
      "\tValidation Loss : 1.3673; Validation Accuracy : 50.19%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.515; Training Accuracy   : 55.006%\n",
      "\tValidation Loss : 1.129; Validation Accuracy : 59.9%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.0385; Training Accuracy   : 63.844%\n",
      "\tValidation Loss : 0.9078; Validation Accuracy : 67.78%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.7179; Training Accuracy   : 69.886%\n",
      "\tValidation Loss : 0.9168; Validation Accuracy : 68.47%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.4875; Training Accuracy   : 74.012%\n",
      "\tValidation Loss : 0.7983; Validation Accuracy : 73.14%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_resized_crop; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9518; Training Accuracy   : 46.724%\n",
      "\tValidation Loss : 1.2166; Validation Accuracy : 58.72%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9483; Training Accuracy   : 65.778%\n",
      "\tValidation Loss : 0.8972; Validation Accuracy : 69.22%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.506; Training Accuracy   : 73.428%\n",
      "\tValidation Loss : 0.8161; Validation Accuracy : 72.0%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.2664; Training Accuracy   : 77.9%\n",
      "\tValidation Loss : 0.5964; Validation Accuracy : 79.43%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.0976; Training Accuracy   : 81.024%\n",
      "\tValidation Loss : 0.6698; Validation Accuracy : 77.72%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_resized_crop; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.8249; Training Accuracy   : 48.854%\n",
      "\tValidation Loss : 1.2322; Validation Accuracy : 58.79%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.8811; Training Accuracy   : 66.744%\n",
      "\tValidation Loss : 1.1659; Validation Accuracy : 63.78%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.4791; Training Accuracy   : 74.104%\n",
      "\tValidation Loss : 0.9213; Validation Accuracy : 69.95%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.2409; Training Accuracy   : 78.622%\n",
      "\tValidation Loss : 0.6496; Validation Accuracy : 77.99%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.0846; Training Accuracy   : 81.04%\n",
      "\tValidation Loss : 0.5521; Validation Accuracy : 80.83%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_resized_crop; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.3121; Training Accuracy   : 39.764%\n",
      "\tValidation Loss : 1.4422; Validation Accuracy : 48.66%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.325; Training Accuracy   : 58.152%\n",
      "\tValidation Loss : 1.6574; Validation Accuracy : 47.82%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8195; Training Accuracy   : 67.874%\n",
      "\tValidation Loss : 1.0266; Validation Accuracy : 65.14%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.5117; Training Accuracy   : 73.464%\n",
      "\tValidation Loss : 0.9278; Validation Accuracy : 69.05%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.3166; Training Accuracy   : 77.064%\n",
      "\tValidation Loss : 0.8013; Validation Accuracy : 73.27%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_resized_crop; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9854; Training Accuracy   : 45.652%\n",
      "\tValidation Loss : 1.3468; Validation Accuracy : 51.91%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.6872; Training Accuracy   : 51.884%\n",
      "\tValidation Loss : 1.6106; Validation Accuracy : 45.62%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.6384; Training Accuracy   : 52.84%\n",
      "\tValidation Loss : 1.4218; Validation Accuracy : 50.62%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.6597; Training Accuracy   : 52.55%\n",
      "\tValidation Loss : 1.6492; Validation Accuracy : 45.7%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.748; Training Accuracy   : 51.154%\n",
      "\tValidation Loss : 1.5209; Validation Accuracy : 46.65%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_resized_crop; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.7598; Training Accuracy   : 49.764%\n",
      "\tValidation Loss : 1.2434; Validation Accuracy : 56.79%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.242; Training Accuracy   : 60.516%\n",
      "\tValidation Loss : 1.1904; Validation Accuracy : 59.55%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.0332; Training Accuracy   : 64.786%\n",
      "\tValidation Loss : 1.0684; Validation Accuracy : 63.67%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.9777; Training Accuracy   : 65.58%\n",
      "\tValidation Loss : 1.019; Validation Accuracy : 64.57%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.9911; Training Accuracy   : 65.158%\n",
      "\tValidation Loss : 1.1091; Validation Accuracy : 62.19%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_resized_crop; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.4703; Training Accuracy   : 37.044%\n",
      "\tValidation Loss : 1.3818; Validation Accuracy : 48.65%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.4982; Training Accuracy   : 55.338%\n",
      "\tValidation Loss : 1.1601; Validation Accuracy : 58.28%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.019; Training Accuracy   : 64.436%\n",
      "\tValidation Loss : 0.8979; Validation Accuracy : 68.98%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.6588; Training Accuracy   : 71.056%\n",
      "\tValidation Loss : 0.9825; Validation Accuracy : 66.63%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.4312; Training Accuracy   : 75.11%\n",
      "\tValidation Loss : 0.8394; Validation Accuracy : 70.71%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_affine; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.1475; Training Accuracy   : 42.176%\n",
      "\tValidation Loss : 1.3193; Validation Accuracy : 53.39%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3081; Training Accuracy   : 58.858%\n",
      "\tValidation Loss : 1.0958; Validation Accuracy : 63.04%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8679; Training Accuracy   : 67.078%\n",
      "\tValidation Loss : 0.8641; Validation Accuracy : 70.66%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.6126; Training Accuracy   : 71.74%\n",
      "\tValidation Loss : 0.7681; Validation Accuracy : 73.72%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.4452; Training Accuracy   : 74.766%\n",
      "\tValidation Loss : 0.5947; Validation Accuracy : 79.44%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_affine; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.0576; Training Accuracy   : 44.33%\n",
      "\tValidation Loss : 1.2297; Validation Accuracy : 57.86%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.2175; Training Accuracy   : 60.844%\n",
      "\tValidation Loss : 1.112; Validation Accuracy : 62.51%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8029; Training Accuracy   : 68.42%\n",
      "\tValidation Loss : 0.7284; Validation Accuracy : 75.16%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.5461; Training Accuracy   : 72.948%\n",
      "\tValidation Loss : 0.6987; Validation Accuracy : 75.79%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.3753; Training Accuracy   : 76.018%\n",
      "\tValidation Loss : 0.6307; Validation Accuracy : 78.55%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_affine; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.4786; Training Accuracy   : 36.11%\n",
      "\tValidation Loss : 1.8997; Validation Accuracy : 36.4%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.5725; Training Accuracy   : 53.798%\n",
      "\tValidation Loss : 1.0698; Validation Accuracy : 62.2%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.1642; Training Accuracy   : 61.428%\n",
      "\tValidation Loss : 1.0328; Validation Accuracy : 66.17%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.8518; Training Accuracy   : 67.29%\n",
      "\tValidation Loss : 0.9735; Validation Accuracy : 67.93%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.6453; Training Accuracy   : 71.208%\n",
      "\tValidation Loss : 0.8236; Validation Accuracy : 72.16%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_affine; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.2515; Training Accuracy   : 40.394%\n",
      "\tValidation Loss : 1.6316; Validation Accuracy : 40.67%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.0853; Training Accuracy   : 43.296%\n",
      "\tValidation Loss : 1.5939; Validation Accuracy : 43.34%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 3.049; Training Accuracy   : 44.426%\n",
      "\tValidation Loss : 1.5185; Validation Accuracy : 45.6%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 3.0606; Training Accuracy   : 44.14%\n",
      "\tValidation Loss : 1.9367; Validation Accuracy : 35.79%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 3.1541; Training Accuracy   : 42.03%\n",
      "\tValidation Loss : 2.229; Validation Accuracy : 30.47%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_affine; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.0286; Training Accuracy   : 44.638%\n",
      "\tValidation Loss : 1.5123; Validation Accuracy : 47.88%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.6596; Training Accuracy   : 52.196%\n",
      "\tValidation Loss : 1.3131; Validation Accuracy : 52.93%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.4355; Training Accuracy   : 56.814%\n",
      "\tValidation Loss : 1.1836; Validation Accuracy : 59.71%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.3094; Training Accuracy   : 59.35%\n",
      "\tValidation Loss : 1.2482; Validation Accuracy : 57.6%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.3194; Training Accuracy   : 59.184%\n",
      "\tValidation Loss : 1.0831; Validation Accuracy : 62.18%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_affine; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.6169; Training Accuracy   : 33.612%\n",
      "\tValidation Loss : 1.3895; Validation Accuracy : 49.82%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.7057; Training Accuracy   : 51.52%\n",
      "\tValidation Loss : 1.4735; Validation Accuracy : 50.99%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.2472; Training Accuracy   : 60.092%\n",
      "\tValidation Loss : 1.0561; Validation Accuracy : 62.95%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.966; Training Accuracy   : 65.406%\n",
      "\tValidation Loss : 1.2446; Validation Accuracy : 61.57%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.727; Training Accuracy   : 69.808%\n",
      "\tValidation Loss : 0.8644; Validation Accuracy : 70.76%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_erasing; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9442; Training Accuracy   : 46.438%\n",
      "\tValidation Loss : 1.24; Validation Accuracy : 57.44%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.002; Training Accuracy   : 64.702%\n",
      "\tValidation Loss : 0.8523; Validation Accuracy : 69.54%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.5502; Training Accuracy   : 72.798%\n",
      "\tValidation Loss : 0.8204; Validation Accuracy : 71.89%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3071; Training Accuracy   : 77.206%\n",
      "\tValidation Loss : 0.6781; Validation Accuracy : 75.72%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.1077; Training Accuracy   : 80.628%\n",
      "\tValidation Loss : 0.6555; Validation Accuracy : 78.04%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_erasing; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.8622; Training Accuracy   : 48.316%\n",
      "\tValidation Loss : 1.1676; Validation Accuracy : 58.95%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9121; Training Accuracy   : 66.286%\n",
      "\tValidation Loss : 0.8721; Validation Accuracy : 70.09%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.503; Training Accuracy   : 73.932%\n",
      "\tValidation Loss : 0.6932; Validation Accuracy : 76.36%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.2506; Training Accuracy   : 78.192%\n",
      "\tValidation Loss : 0.6598; Validation Accuracy : 77.52%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.0776; Training Accuracy   : 81.13%\n",
      "\tValidation Loss : 0.7102; Validation Accuracy : 76.79%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_erasing; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.3397; Training Accuracy   : 39.07%\n",
      "\tValidation Loss : 1.4443; Validation Accuracy : 46.7%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.293; Training Accuracy   : 58.976%\n",
      "\tValidation Loss : 1.1977; Validation Accuracy : 58.46%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8422; Training Accuracy   : 67.338%\n",
      "\tValidation Loss : 0.9312; Validation Accuracy : 67.02%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.5426; Training Accuracy   : 72.812%\n",
      "\tValidation Loss : 0.8412; Validation Accuracy : 71.86%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.3361; Training Accuracy   : 76.732%\n",
      "\tValidation Loss : 0.9609; Validation Accuracy : 68.94%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_erasing; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.0343; Training Accuracy   : 44.694%\n",
      "\tValidation Loss : 1.5949; Validation Accuracy : 44.77%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.8299; Training Accuracy   : 48.818%\n",
      "\tValidation Loss : 1.4497; Validation Accuracy : 45.67%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.8297; Training Accuracy   : 48.652%\n",
      "\tValidation Loss : 1.7157; Validation Accuracy : 43.87%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.8406; Training Accuracy   : 48.392%\n",
      "\tValidation Loss : 1.6185; Validation Accuracy : 44.58%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.893; Training Accuracy   : 47.536%\n",
      "\tValidation Loss : 1.507; Validation Accuracy : 48.15%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_erasing; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.8103; Training Accuracy   : 49.01%\n",
      "\tValidation Loss : 1.4667; Validation Accuracy : 50.5%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3559; Training Accuracy   : 58.144%\n",
      "\tValidation Loss : 1.1914; Validation Accuracy : 57.69%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.157; Training Accuracy   : 62.11%\n",
      "\tValidation Loss : 1.0413; Validation Accuracy : 63.55%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.0777; Training Accuracy   : 63.246%\n",
      "\tValidation Loss : 1.3294; Validation Accuracy : 58.49%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.0885; Training Accuracy   : 63.436%\n",
      "\tValidation Loss : 1.0128; Validation Accuracy : 63.85%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 32; Augmentation: random_erasing; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.5085; Training Accuracy   : 36.406%\n",
      "\tValidation Loss : 1.4564; Validation Accuracy : 47.1%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.5144; Training Accuracy   : 55.066%\n",
      "\tValidation Loss : 1.1484; Validation Accuracy : 60.38%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.0051; Training Accuracy   : 64.586%\n",
      "\tValidation Loss : 1.2946; Validation Accuracy : 59.08%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.6542; Training Accuracy   : 70.956%\n",
      "\tValidation Loss : 0.8338; Validation Accuracy : 70.89%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.4172; Training Accuracy   : 75.094%\n",
      "\tValidation Loss : 0.9288; Validation Accuracy : 69.84%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: no; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9144; Training Accuracy   : 46.598%\n",
      "\tValidation Loss : 1.4474; Validation Accuracy : 48.65%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9012; Training Accuracy   : 66.402%\n",
      "\tValidation Loss : 1.1285; Validation Accuracy : 61.93%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.4311; Training Accuracy   : 74.956%\n",
      "\tValidation Loss : 0.7473; Validation Accuracy : 74.4%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.1591; Training Accuracy   : 79.632%\n",
      "\tValidation Loss : 0.7659; Validation Accuracy : 74.55%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 0.924; Training Accuracy   : 83.81%\n",
      "\tValidation Loss : 0.6286; Validation Accuracy : 78.7%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: no; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.8556; Training Accuracy   : 48.112%\n",
      "\tValidation Loss : 1.2503; Validation Accuracy : 56.14%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.776; Training Accuracy   : 68.606%\n",
      "\tValidation Loss : 1.0295; Validation Accuracy : 64.98%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.3431; Training Accuracy   : 76.528%\n",
      "\tValidation Loss : 0.8214; Validation Accuracy : 73.2%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.0711; Training Accuracy   : 81.226%\n",
      "\tValidation Loss : 0.9234; Validation Accuracy : 70.17%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 0.8666; Training Accuracy   : 84.87%\n",
      "\tValidation Loss : 0.6156; Validation Accuracy : 79.91%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: no; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.6419; Training Accuracy   : 33.93%\n",
      "\tValidation Loss : 2.6147; Validation Accuracy : 30.4%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.4998; Training Accuracy   : 55.072%\n",
      "\tValidation Loss : 1.3384; Validation Accuracy : 51.59%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.9391; Training Accuracy   : 65.7%\n",
      "\tValidation Loss : 1.581; Validation Accuracy : 49.69%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.5568; Training Accuracy   : 72.452%\n",
      "\tValidation Loss : 2.1418; Validation Accuracy : 44.69%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.2611; Training Accuracy   : 78.08%\n",
      "\tValidation Loss : 3.2963; Validation Accuracy : 36.6%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: no; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.5895; Training Accuracy   : 53.168%\n",
      "\tValidation Loss : 1.0661; Validation Accuracy : 62.73%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9763; Training Accuracy   : 65.264%\n",
      "\tValidation Loss : 2.1394; Validation Accuracy : 46.96%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.0027; Training Accuracy   : 64.862%\n",
      "\tValidation Loss : 1.1388; Validation Accuracy : 60.85%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.0486; Training Accuracy   : 64.094%\n",
      "\tValidation Loss : 4.0469; Validation Accuracy : 29.06%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.0808; Training Accuracy   : 63.804%\n",
      "\tValidation Loss : 1.9111; Validation Accuracy : 44.47%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: no; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.4939; Training Accuracy   : 54.736%\n",
      "\tValidation Loss : 1.0033; Validation Accuracy : 65.21%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.7614; Training Accuracy   : 69.302%\n",
      "\tValidation Loss : 1.0815; Validation Accuracy : 63.88%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.6436; Training Accuracy   : 71.388%\n",
      "\tValidation Loss : 1.1486; Validation Accuracy : 61.5%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.5875; Training Accuracy   : 72.53%\n",
      "\tValidation Loss : 0.8887; Validation Accuracy : 68.71%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.494; Training Accuracy   : 74.264%\n",
      "\tValidation Loss : 0.8753; Validation Accuracy : 69.85%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: no; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.827; Training Accuracy   : 30.414%\n",
      "\tValidation Loss : 1.5662; Validation Accuracy : 43.16%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.7728; Training Accuracy   : 50.428%\n",
      "\tValidation Loss : 1.4335; Validation Accuracy : 49.74%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.2579; Training Accuracy   : 59.916%\n",
      "\tValidation Loss : 1.1767; Validation Accuracy : 57.41%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.8606; Training Accuracy   : 67.332%\n",
      "\tValidation Loss : 1.4063; Validation Accuracy : 54.33%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.5399; Training Accuracy   : 73.246%\n",
      "\tValidation Loss : 1.0612; Validation Accuracy : 64.41%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_crop; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.1541; Training Accuracy   : 41.96%\n",
      "\tValidation Loss : 1.3884; Validation Accuracy : 50.62%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.1971; Training Accuracy   : 60.744%\n",
      "\tValidation Loss : 1.4114; Validation Accuracy : 56.66%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.728; Training Accuracy   : 69.512%\n",
      "\tValidation Loss : 1.1005; Validation Accuracy : 65.76%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.4405; Training Accuracy   : 75.036%\n",
      "\tValidation Loss : 0.9015; Validation Accuracy : 71.53%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.2599; Training Accuracy   : 78.208%\n",
      "\tValidation Loss : 0.9877; Validation Accuracy : 69.21%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_crop; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.1092; Training Accuracy   : 42.876%\n",
      "\tValidation Loss : 1.416; Validation Accuracy : 49.95%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.111; Training Accuracy   : 62.428%\n",
      "\tValidation Loss : 1.1598; Validation Accuracy : 60.88%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.6732; Training Accuracy   : 70.582%\n",
      "\tValidation Loss : 0.894; Validation Accuracy : 69.92%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.4041; Training Accuracy   : 75.5%\n",
      "\tValidation Loss : 0.8238; Validation Accuracy : 73.25%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.2117; Training Accuracy   : 79.008%\n",
      "\tValidation Loss : 0.6501; Validation Accuracy : 78.16%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_crop; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.782; Training Accuracy   : 30.602%\n",
      "\tValidation Loss : 1.6296; Validation Accuracy : 40.43%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.7739; Training Accuracy   : 49.532%\n",
      "\tValidation Loss : 2.371; Validation Accuracy : 30.77%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.2213; Training Accuracy   : 60.164%\n",
      "\tValidation Loss : 1.8674; Validation Accuracy : 49.34%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.846; Training Accuracy   : 67.248%\n",
      "\tValidation Loss : 2.197; Validation Accuracy : 44.16%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.5694; Training Accuracy   : 72.388%\n",
      "\tValidation Loss : 1.4483; Validation Accuracy : 58.76%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_crop; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.8759; Training Accuracy   : 47.568%\n",
      "\tValidation Loss : 1.3445; Validation Accuracy : 53.58%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3021; Training Accuracy   : 58.742%\n",
      "\tValidation Loss : 1.3162; Validation Accuracy : 56.66%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.2815; Training Accuracy   : 59.78%\n",
      "\tValidation Loss : 1.7033; Validation Accuracy : 51.51%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.3048; Training Accuracy   : 59.184%\n",
      "\tValidation Loss : 1.8106; Validation Accuracy : 43.8%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.2859; Training Accuracy   : 59.532%\n",
      "\tValidation Loss : 1.6971; Validation Accuracy : 46.82%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_crop; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.7532; Training Accuracy   : 50.088%\n",
      "\tValidation Loss : 1.3209; Validation Accuracy : 55.48%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.0364; Training Accuracy   : 64.04%\n",
      "\tValidation Loss : 1.3638; Validation Accuracy : 56.09%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8359; Training Accuracy   : 67.786%\n",
      "\tValidation Loss : 1.0055; Validation Accuracy : 66.02%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.7656; Training Accuracy   : 69.404%\n",
      "\tValidation Loss : 1.6077; Validation Accuracy : 55.29%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.6568; Training Accuracy   : 71.198%\n",
      "\tValidation Loss : 0.8583; Validation Accuracy : 70.66%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_crop; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.9506; Training Accuracy   : 27.148%\n",
      "\tValidation Loss : 1.6674; Validation Accuracy : 38.32%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.9697; Training Accuracy   : 46.23%\n",
      "\tValidation Loss : 1.3602; Validation Accuracy : 49.75%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.4594; Training Accuracy   : 55.954%\n",
      "\tValidation Loss : 1.1778; Validation Accuracy : 58.67%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.0951; Training Accuracy   : 63.05%\n",
      "\tValidation Loss : 1.2837; Validation Accuracy : 57.09%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.8139; Training Accuracy   : 68.124%\n",
      "\tValidation Loss : 1.2109; Validation Accuracy : 59.62%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_horizontal_flip; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9176; Training Accuracy   : 46.778%\n",
      "\tValidation Loss : 1.3755; Validation Accuracy : 49.09%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.8893; Training Accuracy   : 66.294%\n",
      "\tValidation Loss : 0.9152; Validation Accuracy : 68.05%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.4711; Training Accuracy   : 74.19%\n",
      "\tValidation Loss : 0.6977; Validation Accuracy : 75.53%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.2084; Training Accuracy   : 78.904%\n",
      "\tValidation Loss : 0.6835; Validation Accuracy : 76.6%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.0335; Training Accuracy   : 82.048%\n",
      "\tValidation Loss : 0.5834; Validation Accuracy : 80.05%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_horizontal_flip; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.8804; Training Accuracy   : 48.066%\n",
      "\tValidation Loss : 1.2209; Validation Accuracy : 56.09%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.8216; Training Accuracy   : 67.554%\n",
      "\tValidation Loss : 1.2499; Validation Accuracy : 57.82%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.3976; Training Accuracy   : 75.464%\n",
      "\tValidation Loss : 0.7772; Validation Accuracy : 73.0%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.1611; Training Accuracy   : 79.88%\n",
      "\tValidation Loss : 0.6772; Validation Accuracy : 76.23%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 0.9951; Training Accuracy   : 82.616%\n",
      "\tValidation Loss : 0.8243; Validation Accuracy : 73.04%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_horizontal_flip; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.6127; Training Accuracy   : 34.56%\n",
      "\tValidation Loss : 2.734; Validation Accuracy : 25.13%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.5099; Training Accuracy   : 54.688%\n",
      "\tValidation Loss : 1.9417; Validation Accuracy : 37.42%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.96; Training Accuracy   : 65.13%\n",
      "\tValidation Loss : 1.2504; Validation Accuracy : 56.18%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.6317; Training Accuracy   : 71.192%\n",
      "\tValidation Loss : 1.3141; Validation Accuracy : 57.21%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.3682; Training Accuracy   : 75.912%\n",
      "\tValidation Loss : 0.9754; Validation Accuracy : 67.82%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_horizontal_flip; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.5384; Training Accuracy   : 54.044%\n",
      "\tValidation Loss : 1.0017; Validation Accuracy : 63.43%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9674; Training Accuracy   : 65.246%\n",
      "\tValidation Loss : 1.1388; Validation Accuracy : 59.73%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.0147; Training Accuracy   : 64.658%\n",
      "\tValidation Loss : 1.277; Validation Accuracy : 54.82%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.0785; Training Accuracy   : 63.448%\n",
      "\tValidation Loss : 1.2445; Validation Accuracy : 57.58%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.0684; Training Accuracy   : 63.896%\n",
      "\tValidation Loss : 1.2858; Validation Accuracy : 56.06%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_horizontal_flip; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.4977; Training Accuracy   : 54.938%\n",
      "\tValidation Loss : 1.1651; Validation Accuracy : 60.06%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.7614; Training Accuracy   : 69.296%\n",
      "\tValidation Loss : 1.0375; Validation Accuracy : 63.21%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.6492; Training Accuracy   : 71.414%\n",
      "\tValidation Loss : 1.0507; Validation Accuracy : 64.27%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.5816; Training Accuracy   : 72.784%\n",
      "\tValidation Loss : 1.0728; Validation Accuracy : 63.55%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.5256; Training Accuracy   : 73.606%\n",
      "\tValidation Loss : 0.9979; Validation Accuracy : 65.75%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_horizontal_flip; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.8181; Training Accuracy   : 30.66%\n",
      "\tValidation Loss : 1.578; Validation Accuracy : 43.37%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.7819; Training Accuracy   : 50.352%\n",
      "\tValidation Loss : 1.3808; Validation Accuracy : 49.71%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.2697; Training Accuracy   : 59.792%\n",
      "\tValidation Loss : 1.1815; Validation Accuracy : 57.52%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.9077; Training Accuracy   : 66.24%\n",
      "\tValidation Loss : 1.0279; Validation Accuracy : 62.69%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.6263; Training Accuracy   : 71.374%\n",
      "\tValidation Loss : 1.1167; Validation Accuracy : 61.99%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_rotate; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.0831; Training Accuracy   : 43.576%\n",
      "\tValidation Loss : 1.7569; Validation Accuracy : 45.65%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.146; Training Accuracy   : 61.56%\n",
      "\tValidation Loss : 1.0563; Validation Accuracy : 62.73%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.7417; Training Accuracy   : 69.19%\n",
      "\tValidation Loss : 0.7353; Validation Accuracy : 74.18%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.4766; Training Accuracy   : 73.962%\n",
      "\tValidation Loss : 0.6994; Validation Accuracy : 75.63%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.2829; Training Accuracy   : 77.298%\n",
      "\tValidation Loss : 0.7346; Validation Accuracy : 75.32%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_rotate; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.0317; Training Accuracy   : 44.734%\n",
      "\tValidation Loss : 1.3547; Validation Accuracy : 51.93%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.059; Training Accuracy   : 63.428%\n",
      "\tValidation Loss : 1.0577; Validation Accuracy : 64.71%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.6404; Training Accuracy   : 71.064%\n",
      "\tValidation Loss : 0.8131; Validation Accuracy : 71.66%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3897; Training Accuracy   : 75.676%\n",
      "\tValidation Loss : 0.6677; Validation Accuracy : 76.81%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.2149; Training Accuracy   : 78.81%\n",
      "\tValidation Loss : 0.6617; Validation Accuracy : 77.58%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_rotate; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.6888; Training Accuracy   : 32.57%\n",
      "\tValidation Loss : 1.6438; Validation Accuracy : 39.95%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.6855; Training Accuracy   : 51.4%\n",
      "\tValidation Loss : 1.6026; Validation Accuracy : 43.72%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.2025; Training Accuracy   : 60.44%\n",
      "\tValidation Loss : 1.0478; Validation Accuracy : 61.73%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.8665; Training Accuracy   : 66.952%\n",
      "\tValidation Loss : 2.8279; Validation Accuracy : 38.27%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.5992; Training Accuracy   : 71.902%\n",
      "\tValidation Loss : 1.2051; Validation Accuracy : 62.12%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_rotate; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.7704; Training Accuracy   : 49.794%\n",
      "\tValidation Loss : 1.2101; Validation Accuracy : 56.24%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.247; Training Accuracy   : 60.282%\n",
      "\tValidation Loss : 1.2622; Validation Accuracy : 55.54%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.2841; Training Accuracy   : 59.51%\n",
      "\tValidation Loss : 1.3785; Validation Accuracy : 54.31%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.3123; Training Accuracy   : 58.698%\n",
      "\tValidation Loss : 1.4476; Validation Accuracy : 50.47%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.3454; Training Accuracy   : 58.238%\n",
      "\tValidation Loss : 1.3404; Validation Accuracy : 52.32%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_rotate; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.6877; Training Accuracy   : 51.344%\n",
      "\tValidation Loss : 1.3842; Validation Accuracy : 51.04%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.0373; Training Accuracy   : 63.926%\n",
      "\tValidation Loss : 1.9091; Validation Accuracy : 48.81%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8835; Training Accuracy   : 67.104%\n",
      "\tValidation Loss : 1.6113; Validation Accuracy : 51.92%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.8376; Training Accuracy   : 67.948%\n",
      "\tValidation Loss : 0.9093; Validation Accuracy : 67.84%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.7597; Training Accuracy   : 69.238%\n",
      "\tValidation Loss : 0.964; Validation Accuracy : 66.7%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_rotate; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.8615; Training Accuracy   : 29.42%\n",
      "\tValidation Loss : 1.5887; Validation Accuracy : 41.62%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.8923; Training Accuracy   : 47.49%\n",
      "\tValidation Loss : 1.4181; Validation Accuracy : 49.37%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.4397; Training Accuracy   : 56.294%\n",
      "\tValidation Loss : 1.4103; Validation Accuracy : 50.4%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.0964; Training Accuracy   : 62.76%\n",
      "\tValidation Loss : 1.1287; Validation Accuracy : 59.99%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.8332; Training Accuracy   : 67.794%\n",
      "\tValidation Loss : 1.0559; Validation Accuracy : 63.39%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_resized_crop; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.0363; Training Accuracy   : 44.316%\n",
      "\tValidation Loss : 2.2779; Validation Accuracy : 37.56%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.0832; Training Accuracy   : 63.108%\n",
      "\tValidation Loss : 0.846; Validation Accuracy : 70.43%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.6177; Training Accuracy   : 71.802%\n",
      "\tValidation Loss : 1.0055; Validation Accuracy : 67.75%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3483; Training Accuracy   : 76.52%\n",
      "\tValidation Loss : 0.6858; Validation Accuracy : 76.53%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.1609; Training Accuracy   : 79.816%\n",
      "\tValidation Loss : 0.7184; Validation Accuracy : 77.37%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_resized_crop; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9636; Training Accuracy   : 45.994%\n",
      "\tValidation Loss : 1.6785; Validation Accuracy : 46.7%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.0027; Training Accuracy   : 64.308%\n",
      "\tValidation Loss : 1.1712; Validation Accuracy : 62.64%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.575; Training Accuracy   : 72.354%\n",
      "\tValidation Loss : 0.7903; Validation Accuracy : 72.06%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3323; Training Accuracy   : 76.718%\n",
      "\tValidation Loss : 0.7509; Validation Accuracy : 74.62%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.1556; Training Accuracy   : 79.786%\n",
      "\tValidation Loss : 0.8715; Validation Accuracy : 72.45%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_resized_crop; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.6327; Training Accuracy   : 33.994%\n",
      "\tValidation Loss : 1.9839; Validation Accuracy : 33.64%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.6264; Training Accuracy   : 52.406%\n",
      "\tValidation Loss : 2.0017; Validation Accuracy : 41.1%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.1398; Training Accuracy   : 61.692%\n",
      "\tValidation Loss : 2.9419; Validation Accuracy : 32.06%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.7778; Training Accuracy   : 68.672%\n",
      "\tValidation Loss : 1.3154; Validation Accuracy : 60.48%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.4956; Training Accuracy   : 73.986%\n",
      "\tValidation Loss : 1.7136; Validation Accuracy : 53.18%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_resized_crop; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.7476; Training Accuracy   : 50.274%\n",
      "\tValidation Loss : 1.2095; Validation Accuracy : 58.86%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.1266; Training Accuracy   : 62.424%\n",
      "\tValidation Loss : 1.3231; Validation Accuracy : 55.8%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.1739; Training Accuracy   : 61.482%\n",
      "\tValidation Loss : 1.6834; Validation Accuracy : 50.96%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.2197; Training Accuracy   : 61.382%\n",
      "\tValidation Loss : 1.3244; Validation Accuracy : 56.65%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.227; Training Accuracy   : 60.702%\n",
      "\tValidation Loss : 1.4514; Validation Accuracy : 51.09%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_resized_crop; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.6784; Training Accuracy   : 51.158%\n",
      "\tValidation Loss : 1.0766; Validation Accuracy : 61.75%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9531; Training Accuracy   : 65.566%\n",
      "\tValidation Loss : 1.2099; Validation Accuracy : 60.91%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8086; Training Accuracy   : 68.314%\n",
      "\tValidation Loss : 1.4279; Validation Accuracy : 56.95%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.7563; Training Accuracy   : 69.364%\n",
      "\tValidation Loss : 0.9528; Validation Accuracy : 67.39%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.6647; Training Accuracy   : 71.268%\n",
      "\tValidation Loss : 0.8362; Validation Accuracy : 71.19%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_resized_crop; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.8132; Training Accuracy   : 30.164%\n",
      "\tValidation Loss : 1.5639; Validation Accuracy : 43.33%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.859; Training Accuracy   : 48.59%\n",
      "\tValidation Loss : 1.2978; Validation Accuracy : 53.17%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.4043; Training Accuracy   : 57.08%\n",
      "\tValidation Loss : 1.3301; Validation Accuracy : 53.46%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.0584; Training Accuracy   : 63.68%\n",
      "\tValidation Loss : 1.4257; Validation Accuracy : 53.79%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.7861; Training Accuracy   : 68.604%\n",
      "\tValidation Loss : 1.3049; Validation Accuracy : 59.49%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_affine; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.2134; Training Accuracy   : 40.902%\n",
      "\tValidation Loss : 1.4458; Validation Accuracy : 47.81%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3806; Training Accuracy   : 57.224%\n",
      "\tValidation Loss : 1.8623; Validation Accuracy : 45.55%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.0154; Training Accuracy   : 64.192%\n",
      "\tValidation Loss : 0.8678; Validation Accuracy : 70.74%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.7201; Training Accuracy   : 69.794%\n",
      "\tValidation Loss : 0.8033; Validation Accuracy : 73.1%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.5198; Training Accuracy   : 73.486%\n",
      "\tValidation Loss : 0.6979; Validation Accuracy : 75.9%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_affine; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.1797; Training Accuracy   : 41.56%\n",
      "\tValidation Loss : 1.3015; Validation Accuracy : 54.19%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.2806; Training Accuracy   : 59.362%\n",
      "\tValidation Loss : 1.0875; Validation Accuracy : 61.26%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.903; Training Accuracy   : 66.424%\n",
      "\tValidation Loss : 1.2681; Validation Accuracy : 63.74%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.6331; Training Accuracy   : 71.696%\n",
      "\tValidation Loss : 0.7709; Validation Accuracy : 73.91%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.4527; Training Accuracy   : 74.678%\n",
      "\tValidation Loss : 0.7149; Validation Accuracy : 75.17%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_affine; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.8103; Training Accuracy   : 29.878%\n",
      "\tValidation Loss : 1.7234; Validation Accuracy : 38.33%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.8677; Training Accuracy   : 47.672%\n",
      "\tValidation Loss : 1.5854; Validation Accuracy : 43.0%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.3992; Training Accuracy   : 57.092%\n",
      "\tValidation Loss : 1.5504; Validation Accuracy : 48.79%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.0806; Training Accuracy   : 63.114%\n",
      "\tValidation Loss : 2.7777; Validation Accuracy : 36.15%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.8344; Training Accuracy   : 67.784%\n",
      "\tValidation Loss : 3.0253; Validation Accuracy : 39.21%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_affine; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.0258; Training Accuracy   : 44.614%\n",
      "\tValidation Loss : 1.7399; Validation Accuracy : 46.61%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.504; Training Accuracy   : 55.288%\n",
      "\tValidation Loss : 1.6243; Validation Accuracy : 49.2%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.4988; Training Accuracy   : 55.252%\n",
      "\tValidation Loss : 1.7615; Validation Accuracy : 45.78%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.4923; Training Accuracy   : 55.572%\n",
      "\tValidation Loss : 1.5173; Validation Accuracy : 49.59%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.5183; Training Accuracy   : 54.974%\n",
      "\tValidation Loss : 1.4933; Validation Accuracy : 49.84%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_affine; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9022; Training Accuracy   : 46.95%\n",
      "\tValidation Loss : 1.1324; Validation Accuracy : 59.25%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3079; Training Accuracy   : 58.698%\n",
      "\tValidation Loss : 1.1962; Validation Accuracy : 57.84%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.1515; Training Accuracy   : 62.158%\n",
      "\tValidation Loss : 1.1557; Validation Accuracy : 60.97%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.0686; Training Accuracy   : 63.592%\n",
      "\tValidation Loss : 1.09; Validation Accuracy : 63.45%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.9624; Training Accuracy   : 65.658%\n",
      "\tValidation Loss : 1.3079; Validation Accuracy : 58.99%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_affine; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.9645; Training Accuracy   : 26.848%\n",
      "\tValidation Loss : 1.6359; Validation Accuracy : 40.19%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.0739; Training Accuracy   : 44.454%\n",
      "\tValidation Loss : 1.4404; Validation Accuracy : 48.19%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.6509; Training Accuracy   : 52.388%\n",
      "\tValidation Loss : 1.2649; Validation Accuracy : 54.93%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.3207; Training Accuracy   : 58.59%\n",
      "\tValidation Loss : 1.2167; Validation Accuracy : 56.06%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.0798; Training Accuracy   : 63.03%\n",
      "\tValidation Loss : 1.2327; Validation Accuracy : 57.58%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_erasing; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.0638; Training Accuracy   : 43.986%\n",
      "\tValidation Loss : 1.7928; Validation Accuracy : 44.74%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.1215; Training Accuracy   : 62.326%\n",
      "\tValidation Loss : 0.9784; Validation Accuracy : 65.46%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.6569; Training Accuracy   : 70.802%\n",
      "\tValidation Loss : 0.9099; Validation Accuracy : 68.65%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3883; Training Accuracy   : 75.54%\n",
      "\tValidation Loss : 0.7326; Validation Accuracy : 74.42%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.1852; Training Accuracy   : 79.232%\n",
      "\tValidation Loss : 0.6781; Validation Accuracy : 78.14%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_erasing; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9939; Training Accuracy   : 45.678%\n",
      "\tValidation Loss : 1.3105; Validation Accuracy : 54.57%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9959; Training Accuracy   : 64.43%\n",
      "\tValidation Loss : 1.0333; Validation Accuracy : 64.89%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.5785; Training Accuracy   : 72.43%\n",
      "\tValidation Loss : 0.9649; Validation Accuracy : 66.94%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3294; Training Accuracy   : 76.63%\n",
      "\tValidation Loss : 0.7977; Validation Accuracy : 73.01%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.1312; Training Accuracy   : 80.066%\n",
      "\tValidation Loss : 0.6581; Validation Accuracy : 77.49%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_erasing; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.718; Training Accuracy   : 32.646%\n",
      "\tValidation Loss : 1.8199; Validation Accuracy : 32.63%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.6657; Training Accuracy   : 51.88%\n",
      "\tValidation Loss : 1.4322; Validation Accuracy : 49.96%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.1438; Training Accuracy   : 61.594%\n",
      "\tValidation Loss : 1.6122; Validation Accuracy : 47.21%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.7982; Training Accuracy   : 68.166%\n",
      "\tValidation Loss : 1.2467; Validation Accuracy : 56.72%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.5335; Training Accuracy   : 72.666%\n",
      "\tValidation Loss : 1.2959; Validation Accuracy : 60.39%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_erasing; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.8238; Training Accuracy   : 48.67%\n",
      "\tValidation Loss : 1.3428; Validation Accuracy : 51.88%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.2346; Training Accuracy   : 60.446%\n",
      "\tValidation Loss : 1.6648; Validation Accuracy : 51.74%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.2675; Training Accuracy   : 60.062%\n",
      "\tValidation Loss : 3.9547; Validation Accuracy : 29.01%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.2864; Training Accuracy   : 59.524%\n",
      "\tValidation Loss : 1.4187; Validation Accuracy : 52.54%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.2919; Training Accuracy   : 59.38%\n",
      "\tValidation Loss : 1.4911; Validation Accuracy : 50.94%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_erasing; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.6614; Training Accuracy   : 51.826%\n",
      "\tValidation Loss : 1.0208; Validation Accuracy : 63.43%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9732; Training Accuracy   : 65.13%\n",
      "\tValidation Loss : 0.9905; Validation Accuracy : 65.5%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8621; Training Accuracy   : 67.428%\n",
      "\tValidation Loss : 1.0179; Validation Accuracy : 64.83%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.8176; Training Accuracy   : 68.266%\n",
      "\tValidation Loss : 1.0646; Validation Accuracy : 64.52%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.7177; Training Accuracy   : 70.124%\n",
      "\tValidation Loss : 1.0273; Validation Accuracy : 66.82%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 64; Augmentation: random_erasing; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.9188; Training Accuracy   : 29.122%\n",
      "\tValidation Loss : 1.5518; Validation Accuracy : 44.27%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.8819; Training Accuracy   : 48.344%\n",
      "\tValidation Loss : 1.3113; Validation Accuracy : 52.97%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.387; Training Accuracy   : 57.228%\n",
      "\tValidation Loss : 1.1586; Validation Accuracy : 59.49%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.0317; Training Accuracy   : 63.808%\n",
      "\tValidation Loss : 1.3223; Validation Accuracy : 56.82%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.7489; Training Accuracy   : 69.102%\n",
      "\tValidation Loss : 1.0862; Validation Accuracy : 61.79%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: no; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.318; Training Accuracy   : 39.654%\n",
      "\tValidation Loss : 1.4692; Validation Accuracy : 48.54%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.1771; Training Accuracy   : 60.952%\n",
      "\tValidation Loss : 1.0362; Validation Accuracy : 63.09%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.6405; Training Accuracy   : 70.924%\n",
      "\tValidation Loss : 1.2138; Validation Accuracy : 59.79%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.2975; Training Accuracy   : 77.182%\n",
      "\tValidation Loss : 0.9939; Validation Accuracy : 66.76%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.0431; Training Accuracy   : 81.692%\n",
      "\tValidation Loss : 0.6886; Validation Accuracy : 76.58%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: no; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.2908; Training Accuracy   : 40.392%\n",
      "\tValidation Loss : 1.2597; Validation Accuracy : 54.5%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.0676; Training Accuracy   : 63.156%\n",
      "\tValidation Loss : 1.0655; Validation Accuracy : 62.01%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.5549; Training Accuracy   : 72.52%\n",
      "\tValidation Loss : 0.8473; Validation Accuracy : 70.41%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.2119; Training Accuracy   : 78.632%\n",
      "\tValidation Loss : 0.8384; Validation Accuracy : 71.75%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 0.9695; Training Accuracy   : 83.028%\n",
      "\tValidation Loss : 0.7038; Validation Accuracy : 76.15%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: no; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.0714; Training Accuracy   : 25.646%\n",
      "\tValidation Loss : 1.7314; Validation Accuracy : 37.75%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.1195; Training Accuracy   : 43.766%\n",
      "\tValidation Loss : 1.4232; Validation Accuracy : 48.85%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.5861; Training Accuracy   : 53.514%\n",
      "\tValidation Loss : 1.3116; Validation Accuracy : 53.23%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.1818; Training Accuracy   : 60.868%\n",
      "\tValidation Loss : 1.2433; Validation Accuracy : 56.02%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.8526; Training Accuracy   : 67.218%\n",
      "\tValidation Loss : 1.8148; Validation Accuracy : 48.66%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: no; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.4875; Training Accuracy   : 55.04%\n",
      "\tValidation Loss : 1.2622; Validation Accuracy : 57.91%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.7002; Training Accuracy   : 70.022%\n",
      "\tValidation Loss : 1.004; Validation Accuracy : 65.25%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.4849; Training Accuracy   : 74.176%\n",
      "\tValidation Loss : 1.1054; Validation Accuracy : 63.1%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.4906; Training Accuracy   : 73.842%\n",
      "\tValidation Loss : 0.8672; Validation Accuracy : 70.42%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.5554; Training Accuracy   : 73.244%\n",
      "\tValidation Loss : 1.1121; Validation Accuracy : 60.93%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: no; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.5184; Training Accuracy   : 54.376%\n",
      "\tValidation Loss : 1.0435; Validation Accuracy : 63.01%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.6811; Training Accuracy   : 70.218%\n",
      "\tValidation Loss : 1.0804; Validation Accuracy : 63.25%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.3719; Training Accuracy   : 75.946%\n",
      "\tValidation Loss : 0.8359; Validation Accuracy : 72.11%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.2554; Training Accuracy   : 78.064%\n",
      "\tValidation Loss : 0.7821; Validation Accuracy : 73.49%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.2136; Training Accuracy   : 78.882%\n",
      "\tValidation Loss : 0.8447; Validation Accuracy : 72.31%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: no; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.2286; Training Accuracy   : 21.694%\n",
      "\tValidation Loss : 1.8253; Validation Accuracy : 35.69%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.3346; Training Accuracy   : 40.706%\n",
      "\tValidation Loss : 1.5176; Validation Accuracy : 45.11%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.8328; Training Accuracy   : 49.334%\n",
      "\tValidation Loss : 1.3343; Validation Accuracy : 51.72%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.4545; Training Accuracy   : 56.328%\n",
      "\tValidation Loss : 1.2557; Validation Accuracy : 54.67%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.161; Training Accuracy   : 61.934%\n",
      "\tValidation Loss : 1.1811; Validation Accuracy : 57.68%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_crop; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.4595; Training Accuracy   : 36.324%\n",
      "\tValidation Loss : 1.3816; Validation Accuracy : 49.71%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.39; Training Accuracy   : 56.948%\n",
      "\tValidation Loss : 1.2351; Validation Accuracy : 57.61%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.9528; Training Accuracy   : 65.24%\n",
      "\tValidation Loss : 1.1002; Validation Accuracy : 63.18%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.6118; Training Accuracy   : 71.588%\n",
      "\tValidation Loss : 1.0289; Validation Accuracy : 67.03%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.377; Training Accuracy   : 75.968%\n",
      "\tValidation Loss : 0.8853; Validation Accuracy : 71.87%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_crop; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.415; Training Accuracy   : 37.184%\n",
      "\tValidation Loss : 1.3722; Validation Accuracy : 49.5%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3166; Training Accuracy   : 58.54%\n",
      "\tValidation Loss : 1.3123; Validation Accuracy : 57.18%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8497; Training Accuracy   : 67.182%\n",
      "\tValidation Loss : 0.9569; Validation Accuracy : 66.08%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.525; Training Accuracy   : 73.106%\n",
      "\tValidation Loss : 0.9823; Validation Accuracy : 68.8%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.3049; Training Accuracy   : 77.264%\n",
      "\tValidation Loss : 0.7182; Validation Accuracy : 76.63%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_crop; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.163; Training Accuracy   : 23.13%\n",
      "\tValidation Loss : 1.7781; Validation Accuracy : 34.0%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.3141; Training Accuracy   : 39.204%\n",
      "\tValidation Loss : 1.5434; Validation Accuracy : 43.2%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.852; Training Accuracy   : 48.156%\n",
      "\tValidation Loss : 1.4025; Validation Accuracy : 49.36%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.4606; Training Accuracy   : 55.634%\n",
      "\tValidation Loss : 1.1372; Validation Accuracy : 59.88%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.1524; Training Accuracy   : 61.568%\n",
      "\tValidation Loss : 1.0991; Validation Accuracy : 60.77%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_crop; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.8278; Training Accuracy   : 48.362%\n",
      "\tValidation Loss : 1.272; Validation Accuracy : 56.16%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.0281; Training Accuracy   : 64.028%\n",
      "\tValidation Loss : 0.9971; Validation Accuracy : 65.38%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.7387; Training Accuracy   : 69.672%\n",
      "\tValidation Loss : 1.0937; Validation Accuracy : 61.97%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.6887; Training Accuracy   : 70.72%\n",
      "\tValidation Loss : 1.3794; Validation Accuracy : 58.7%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.7225; Training Accuracy   : 70.156%\n",
      "\tValidation Loss : 0.9795; Validation Accuracy : 65.91%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_crop; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.7662; Training Accuracy   : 49.404%\n",
      "\tValidation Loss : 1.4317; Validation Accuracy : 51.46%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9011; Training Accuracy   : 66.43%\n",
      "\tValidation Loss : 1.3154; Validation Accuracy : 60.23%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.5682; Training Accuracy   : 72.678%\n",
      "\tValidation Loss : 1.1557; Validation Accuracy : 64.58%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.4357; Training Accuracy   : 75.044%\n",
      "\tValidation Loss : 0.9156; Validation Accuracy : 70.61%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.3985; Training Accuracy   : 75.934%\n",
      "\tValidation Loss : 1.1291; Validation Accuracy : 63.97%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_crop; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.2654; Training Accuracy   : 20.588%\n",
      "\tValidation Loss : 1.875; Validation Accuracy : 31.23%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.4998; Training Accuracy   : 36.584%\n",
      "\tValidation Loss : 1.604; Validation Accuracy : 40.98%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 3.055; Training Accuracy   : 44.42%\n",
      "\tValidation Loss : 1.4342; Validation Accuracy : 47.59%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.7388; Training Accuracy   : 50.384%\n",
      "\tValidation Loss : 1.3655; Validation Accuracy : 50.54%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.4801; Training Accuracy   : 55.566%\n",
      "\tValidation Loss : 1.4373; Validation Accuracy : 50.18%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_horizontal_flip; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.3101; Training Accuracy   : 39.656%\n",
      "\tValidation Loss : 1.3866; Validation Accuracy : 48.98%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.1646; Training Accuracy   : 61.266%\n",
      "\tValidation Loss : 1.0356; Validation Accuracy : 62.56%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.6957; Training Accuracy   : 69.992%\n",
      "\tValidation Loss : 1.0922; Validation Accuracy : 63.69%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3879; Training Accuracy   : 75.588%\n",
      "\tValidation Loss : 0.801; Validation Accuracy : 71.93%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.1497; Training Accuracy   : 79.816%\n",
      "\tValidation Loss : 0.7893; Validation Accuracy : 75.1%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_horizontal_flip; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.2778; Training Accuracy   : 40.572%\n",
      "\tValidation Loss : 1.376; Validation Accuracy : 50.72%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.0802; Training Accuracy   : 62.868%\n",
      "\tValidation Loss : 1.0753; Validation Accuracy : 61.72%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.5597; Training Accuracy   : 72.708%\n",
      "\tValidation Loss : 0.8837; Validation Accuracy : 70.79%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.2587; Training Accuracy   : 77.982%\n",
      "\tValidation Loss : 0.8233; Validation Accuracy : 72.51%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.0592; Training Accuracy   : 81.56%\n",
      "\tValidation Loss : 0.6929; Validation Accuracy : 76.17%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_horizontal_flip; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.1113; Training Accuracy   : 25.37%\n",
      "\tValidation Loss : 1.744; Validation Accuracy : 37.4%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.1122; Training Accuracy   : 44.046%\n",
      "\tValidation Loss : 1.9284; Validation Accuracy : 37.26%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.5609; Training Accuracy   : 53.914%\n",
      "\tValidation Loss : 1.2632; Validation Accuracy : 54.53%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.1882; Training Accuracy   : 60.834%\n",
      "\tValidation Loss : 1.3021; Validation Accuracy : 55.88%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.8917; Training Accuracy   : 66.354%\n",
      "\tValidation Loss : 1.2454; Validation Accuracy : 55.7%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_horizontal_flip; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.541; Training Accuracy   : 54.022%\n",
      "\tValidation Loss : 1.1432; Validation Accuracy : 59.67%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.7631; Training Accuracy   : 68.854%\n",
      "\tValidation Loss : 1.0633; Validation Accuracy : 64.59%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.5338; Training Accuracy   : 73.296%\n",
      "\tValidation Loss : 1.2169; Validation Accuracy : 58.64%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.5217; Training Accuracy   : 73.696%\n",
      "\tValidation Loss : 1.3608; Validation Accuracy : 58.31%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.5787; Training Accuracy   : 72.698%\n",
      "\tValidation Loss : 0.9277; Validation Accuracy : 69.01%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_horizontal_flip; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.5243; Training Accuracy   : 54.27%\n",
      "\tValidation Loss : 1.1485; Validation Accuracy : 60.2%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.706; Training Accuracy   : 69.866%\n",
      "\tValidation Loss : 0.8338; Validation Accuracy : 71.09%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.4164; Training Accuracy   : 75.068%\n",
      "\tValidation Loss : 0.9337; Validation Accuracy : 68.56%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.3006; Training Accuracy   : 77.324%\n",
      "\tValidation Loss : 0.6986; Validation Accuracy : 76.12%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.2524; Training Accuracy   : 78.366%\n",
      "\tValidation Loss : 0.7751; Validation Accuracy : 73.54%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_horizontal_flip; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.1541; Training Accuracy   : 24.47%\n",
      "\tValidation Loss : 1.8044; Validation Accuracy : 35.69%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.2915; Training Accuracy   : 41.026%\n",
      "\tValidation Loss : 1.4973; Validation Accuracy : 45.93%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.8069; Training Accuracy   : 49.706%\n",
      "\tValidation Loss : 1.3197; Validation Accuracy : 52.32%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.4555; Training Accuracy   : 56.12%\n",
      "\tValidation Loss : 1.2197; Validation Accuracy : 56.72%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.1955; Training Accuracy   : 61.1%\n",
      "\tValidation Loss : 1.1361; Validation Accuracy : 58.19%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_rotate; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.3799; Training Accuracy   : 38.272%\n",
      "\tValidation Loss : 1.5317; Validation Accuracy : 44.5%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3502; Training Accuracy   : 57.474%\n",
      "\tValidation Loss : 1.4145; Validation Accuracy : 50.82%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.9338; Training Accuracy   : 65.558%\n",
      "\tValidation Loss : 1.0169; Validation Accuracy : 65.12%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.6361; Training Accuracy   : 71.146%\n",
      "\tValidation Loss : 0.8378; Validation Accuracy : 70.97%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.3839; Training Accuracy   : 75.708%\n",
      "\tValidation Loss : 0.7242; Validation Accuracy : 75.58%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_rotate; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.3759; Training Accuracy   : 38.368%\n",
      "\tValidation Loss : 1.4182; Validation Accuracy : 49.64%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.2961; Training Accuracy   : 58.622%\n",
      "\tValidation Loss : 1.0839; Validation Accuracy : 60.95%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8201; Training Accuracy   : 67.6%\n",
      "\tValidation Loss : 1.135; Validation Accuracy : 62.11%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.5309; Training Accuracy   : 72.956%\n",
      "\tValidation Loss : 0.7712; Validation Accuracy : 73.22%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.32; Training Accuracy   : 76.828%\n",
      "\tValidation Loss : 0.682; Validation Accuracy : 77.0%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_rotate; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.135; Training Accuracy   : 24.808%\n",
      "\tValidation Loss : 1.7858; Validation Accuracy : 34.93%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.2283; Training Accuracy   : 41.472%\n",
      "\tValidation Loss : 1.4626; Validation Accuracy : 46.78%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.754; Training Accuracy   : 50.07%\n",
      "\tValidation Loss : 1.4639; Validation Accuracy : 46.53%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.3989; Training Accuracy   : 56.992%\n",
      "\tValidation Loss : 1.2741; Validation Accuracy : 54.13%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.0994; Training Accuracy   : 62.444%\n",
      "\tValidation Loss : 1.31; Validation Accuracy : 53.71%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_rotate; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.7697; Training Accuracy   : 49.364%\n",
      "\tValidation Loss : 1.1158; Validation Accuracy : 60.13%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.033; Training Accuracy   : 63.618%\n",
      "\tValidation Loss : 0.9186; Validation Accuracy : 67.59%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.7774; Training Accuracy   : 68.722%\n",
      "\tValidation Loss : 1.0408; Validation Accuracy : 65.81%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.7819; Training Accuracy   : 68.788%\n",
      "\tValidation Loss : 1.0835; Validation Accuracy : 62.69%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.8315; Training Accuracy   : 68.12%\n",
      "\tValidation Loss : 0.9716; Validation Accuracy : 65.89%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_rotate; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.6978; Training Accuracy   : 50.966%\n",
      "\tValidation Loss : 1.1626; Validation Accuracy : 59.15%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9; Training Accuracy   : 66.192%\n",
      "\tValidation Loss : 1.1071; Validation Accuracy : 62.49%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.6299; Training Accuracy   : 71.256%\n",
      "\tValidation Loss : 1.2036; Validation Accuracy : 57.54%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.533; Training Accuracy   : 73.136%\n",
      "\tValidation Loss : 1.209; Validation Accuracy : 61.11%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.4918; Training Accuracy   : 73.836%\n",
      "\tValidation Loss : 0.8132; Validation Accuracy : 73.02%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_rotate; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.286; Training Accuracy   : 20.434%\n",
      "\tValidation Loss : 1.8586; Validation Accuracy : 31.81%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.4231; Training Accuracy   : 38.322%\n",
      "\tValidation Loss : 1.5577; Validation Accuracy : 42.31%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.9679; Training Accuracy   : 46.32%\n",
      "\tValidation Loss : 1.3795; Validation Accuracy : 49.98%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.6212; Training Accuracy   : 52.808%\n",
      "\tValidation Loss : 1.2302; Validation Accuracy : 55.58%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.3597; Training Accuracy   : 57.808%\n",
      "\tValidation Loss : 1.1297; Validation Accuracy : 59.49%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_resized_crop; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.3278; Training Accuracy   : 39.308%\n",
      "\tValidation Loss : 1.3369; Validation Accuracy : 50.91%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.314; Training Accuracy   : 58.628%\n",
      "\tValidation Loss : 1.0397; Validation Accuracy : 63.16%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8225; Training Accuracy   : 67.836%\n",
      "\tValidation Loss : 1.0585; Validation Accuracy : 64.45%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.501; Training Accuracy   : 73.66%\n",
      "\tValidation Loss : 0.9007; Validation Accuracy : 70.96%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.2946; Training Accuracy   : 77.25%\n",
      "\tValidation Loss : 0.6949; Validation Accuracy : 76.75%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_resized_crop; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.3182; Training Accuracy   : 39.59%\n",
      "\tValidation Loss : 1.4892; Validation Accuracy : 45.88%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.2745; Training Accuracy   : 59.204%\n",
      "\tValidation Loss : 1.1128; Validation Accuracy : 60.3%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.7825; Training Accuracy   : 68.392%\n",
      "\tValidation Loss : 1.2505; Validation Accuracy : 61.2%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.462; Training Accuracy   : 74.238%\n",
      "\tValidation Loss : 0.8655; Validation Accuracy : 70.85%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.248; Training Accuracy   : 78.176%\n",
      "\tValidation Loss : 0.7509; Validation Accuracy : 74.21%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_resized_crop; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.0577; Training Accuracy   : 25.978%\n",
      "\tValidation Loss : 1.7512; Validation Accuracy : 37.2%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.1512; Training Accuracy   : 42.926%\n",
      "\tValidation Loss : 1.4562; Validation Accuracy : 46.91%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.6884; Training Accuracy   : 51.616%\n",
      "\tValidation Loss : 1.4811; Validation Accuracy : 48.39%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.3458; Training Accuracy   : 58.192%\n",
      "\tValidation Loss : 1.2139; Validation Accuracy : 56.3%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.0677; Training Accuracy   : 63.124%\n",
      "\tValidation Loss : 1.192; Validation Accuracy : 57.42%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_resized_crop; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.6764; Training Accuracy   : 51.218%\n",
      "\tValidation Loss : 1.2195; Validation Accuracy : 57.9%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.8925; Training Accuracy   : 66.65%\n",
      "\tValidation Loss : 0.9804; Validation Accuracy : 66.15%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.6765; Training Accuracy   : 70.962%\n",
      "\tValidation Loss : 0.9557; Validation Accuracy : 68.69%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.6877; Training Accuracy   : 70.636%\n",
      "\tValidation Loss : 0.944; Validation Accuracy : 67.88%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.7351; Training Accuracy   : 69.724%\n",
      "\tValidation Loss : 1.017; Validation Accuracy : 66.05%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_resized_crop; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.6536; Training Accuracy   : 52.012%\n",
      "\tValidation Loss : 1.1726; Validation Accuracy : 58.63%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.8133; Training Accuracy   : 67.824%\n",
      "\tValidation Loss : 0.9165; Validation Accuracy : 69.37%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.5324; Training Accuracy   : 73.182%\n",
      "\tValidation Loss : 1.9134; Validation Accuracy : 54.95%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.4079; Training Accuracy   : 75.338%\n",
      "\tValidation Loss : 0.9452; Validation Accuracy : 69.56%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.3983; Training Accuracy   : 75.76%\n",
      "\tValidation Loss : 0.9957; Validation Accuracy : 67.84%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_resized_crop; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.1661; Training Accuracy   : 24.128%\n",
      "\tValidation Loss : 1.8367; Validation Accuracy : 35.21%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.3573; Training Accuracy   : 39.9%\n",
      "\tValidation Loss : 1.5412; Validation Accuracy : 44.14%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.8973; Training Accuracy   : 48.136%\n",
      "\tValidation Loss : 1.3581; Validation Accuracy : 50.1%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.5893; Training Accuracy   : 53.71%\n",
      "\tValidation Loss : 1.2388; Validation Accuracy : 55.88%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.3404; Training Accuracy   : 58.37%\n",
      "\tValidation Loss : 1.1477; Validation Accuracy : 59.34%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_affine; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.5081; Training Accuracy   : 34.878%\n",
      "\tValidation Loss : 1.4556; Validation Accuracy : 47.02%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.5693; Training Accuracy   : 53.612%\n",
      "\tValidation Loss : 1.1063; Validation Accuracy : 60.44%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.1651; Training Accuracy   : 61.688%\n",
      "\tValidation Loss : 1.0216; Validation Accuracy : 63.52%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.8932; Training Accuracy   : 66.668%\n",
      "\tValidation Loss : 0.9183; Validation Accuracy : 68.24%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.6728; Training Accuracy   : 70.404%\n",
      "\tValidation Loss : 0.6927; Validation Accuracy : 75.47%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_affine; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.5151; Training Accuracy   : 35.442%\n",
      "\tValidation Loss : 1.3621; Validation Accuracy : 49.7%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.4977; Training Accuracy   : 54.78%\n",
      "\tValidation Loss : 1.2149; Validation Accuracy : 56.47%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.0507; Training Accuracy   : 63.602%\n",
      "\tValidation Loss : 1.02; Validation Accuracy : 64.06%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.7874; Training Accuracy   : 68.332%\n",
      "\tValidation Loss : 1.0532; Validation Accuracy : 65.68%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.5741; Training Accuracy   : 72.208%\n",
      "\tValidation Loss : 0.7159; Validation Accuracy : 75.37%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_affine; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.1542; Training Accuracy   : 23.556%\n",
      "\tValidation Loss : 1.7958; Validation Accuracy : 35.52%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.3638; Training Accuracy   : 38.57%\n",
      "\tValidation Loss : 1.523; Validation Accuracy : 44.63%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.9105; Training Accuracy   : 47.01%\n",
      "\tValidation Loss : 1.447; Validation Accuracy : 49.25%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.6132; Training Accuracy   : 52.864%\n",
      "\tValidation Loss : 1.7166; Validation Accuracy : 43.69%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.3408; Training Accuracy   : 58.098%\n",
      "\tValidation Loss : 1.1225; Validation Accuracy : 59.51%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_affine; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9379; Training Accuracy   : 46.208%\n",
      "\tValidation Loss : 1.6242; Validation Accuracy : 47.0%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.2931; Training Accuracy   : 58.722%\n",
      "\tValidation Loss : 1.3482; Validation Accuracy : 53.95%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.0301; Training Accuracy   : 64.25%\n",
      "\tValidation Loss : 1.101; Validation Accuracy : 63.1%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.0013; Training Accuracy   : 65.172%\n",
      "\tValidation Loss : 1.1491; Validation Accuracy : 62.44%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.0425; Training Accuracy   : 64.368%\n",
      "\tValidation Loss : 1.4616; Validation Accuracy : 57.96%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_affine; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.9026; Training Accuracy   : 46.728%\n",
      "\tValidation Loss : 1.2513; Validation Accuracy : 54.89%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.188; Training Accuracy   : 60.848%\n",
      "\tValidation Loss : 1.0147; Validation Accuracy : 64.22%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8672; Training Accuracy   : 67.136%\n",
      "\tValidation Loss : 1.4477; Validation Accuracy : 59.26%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.7383; Training Accuracy   : 69.394%\n",
      "\tValidation Loss : 0.9189; Validation Accuracy : 69.3%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.6822; Training Accuracy   : 70.588%\n",
      "\tValidation Loss : 0.9831; Validation Accuracy : 68.54%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_affine; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.2844; Training Accuracy   : 20.714%\n",
      "\tValidation Loss : 1.8784; Validation Accuracy : 32.01%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.5343; Training Accuracy   : 35.71%\n",
      "\tValidation Loss : 1.5638; Validation Accuracy : 42.56%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 3.0804; Training Accuracy   : 44.056%\n",
      "\tValidation Loss : 1.4228; Validation Accuracy : 47.85%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.777; Training Accuracy   : 49.604%\n",
      "\tValidation Loss : 1.2795; Validation Accuracy : 53.51%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.5472; Training Accuracy   : 54.208%\n",
      "\tValidation Loss : 1.2416; Validation Accuracy : 55.91%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_erasing; Optimizer: SGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.3776; Training Accuracy   : 38.522%\n",
      "\tValidation Loss : 1.3441; Validation Accuracy : 51.26%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.3435; Training Accuracy   : 57.79%\n",
      "\tValidation Loss : 1.3924; Validation Accuracy : 50.87%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.8705; Training Accuracy   : 66.768%\n",
      "\tValidation Loss : 0.942; Validation Accuracy : 67.54%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.546; Training Accuracy   : 72.722%\n",
      "\tValidation Loss : 0.9021; Validation Accuracy : 68.48%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.3149; Training Accuracy   : 76.77%\n",
      "\tValidation Loss : 0.7407; Validation Accuracy : 74.57%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_erasing; Optimizer: SGD with Nesterov; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 3.3752; Training Accuracy   : 38.23%\n",
      "\tValidation Loss : 1.3279; Validation Accuracy : 51.87%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 2.2293; Training Accuracy   : 60.012%\n",
      "\tValidation Loss : 1.3685; Validation Accuracy : 55.09%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.7361; Training Accuracy   : 69.366%\n",
      "\tValidation Loss : 1.1459; Validation Accuracy : 63.36%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.4249; Training Accuracy   : 74.928%\n",
      "\tValidation Loss : 1.291; Validation Accuracy : 63.16%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.2184; Training Accuracy   : 78.466%\n",
      "\tValidation Loss : 1.2667; Validation Accuracy : 63.24%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_erasing; Optimizer: ASGD; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.0835; Training Accuracy   : 26.238%\n",
      "\tValidation Loss : 1.7457; Validation Accuracy : 37.75%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.2165; Training Accuracy   : 42.136%\n",
      "\tValidation Loss : 1.5189; Validation Accuracy : 45.29%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.7228; Training Accuracy   : 50.742%\n",
      "\tValidation Loss : 1.3403; Validation Accuracy : 52.31%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.358; Training Accuracy   : 57.398%\n",
      "\tValidation Loss : 1.2727; Validation Accuracy : 55.06%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.0491; Training Accuracy   : 63.284%\n",
      "\tValidation Loss : 1.0587; Validation Accuracy : 62.9%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_erasing; Optimizer: Adam; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.6705; Training Accuracy   : 51.242%\n",
      "\tValidation Loss : 1.4068; Validation Accuracy : 53.73%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.9756; Training Accuracy   : 64.828%\n",
      "\tValidation Loss : 1.2056; Validation Accuracy : 59.71%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.7491; Training Accuracy   : 69.438%\n",
      "\tValidation Loss : 1.0937; Validation Accuracy : 63.46%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.7366; Training Accuracy   : 69.516%\n",
      "\tValidation Loss : 1.2208; Validation Accuracy : 61.65%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.7538; Training Accuracy   : 69.298%\n",
      "\tValidation Loss : 1.0435; Validation Accuracy : 64.62%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_erasing; Optimizer: Adamax; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 2.6991; Training Accuracy   : 51.02%\n",
      "\tValidation Loss : 1.0855; Validation Accuracy : 61.15%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 1.8826; Training Accuracy   : 66.334%\n",
      "\tValidation Loss : 0.9477; Validation Accuracy : 67.82%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 1.5913; Training Accuracy   : 71.992%\n",
      "\tValidation Loss : 0.9066; Validation Accuracy : 69.0%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 1.4713; Training Accuracy   : 74.064%\n",
      "\tValidation Loss : 0.7965; Validation Accuracy : 73.46%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 1.4493; Training Accuracy   : 74.776%\n",
      "\tValidation Loss : 0.8019; Validation Accuracy : 72.8%\n",
      "=========================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=========================================================================================================\n",
      "Batch Size: 128; Augmentation: random_erasing; Optimizer: Adadelta; Num Params: 4903242\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss   : 4.2305; Training Accuracy   : 20.892%\n",
      "\tValidation Loss : 1.8215; Validation Accuracy : 34.19%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss   : 3.3723; Training Accuracy   : 39.538%\n",
      "\tValidation Loss : 1.5118; Validation Accuracy : 45.09%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss   : 2.8973; Training Accuracy   : 48.192%\n",
      "\tValidation Loss : 1.3581; Validation Accuracy : 50.85%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss   : 2.5692; Training Accuracy   : 54.332%\n",
      "\tValidation Loss : 1.4124; Validation Accuracy : 49.04%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss   : 2.3159; Training Accuracy   : 58.94%\n",
      "\tValidation Loss : 1.1613; Validation Accuracy : 57.78%\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "batch_sizes    = [32, 64, 128]\n",
    "augmentations  = ['no', 'random_crop', 'random_horizontal_flip', 'random_rotate', \n",
    "                  'random_resized_crop', 'random_affine', 'random_erasing']\n",
    "optimizers     = ['SGD', 'SGD with Nesterov', 'ASGD', 'Adam', 'Adamax', 'Adadelta']\n",
    "\n",
    "metrics_dict = {}\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    metrics_dict[batch_size] = {}\n",
    "    for augmentation in augmentations:\n",
    "        metrics_dict[batch_size][augmentation] = {}\n",
    "        for optimizer_id in optimizers:\n",
    "            metrics_dict[batch_size][augmentation][optimizer_id] = {}\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "            num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "            model.to(device)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            print(\"\\n\\n\")\n",
    "            print(\"=========================================================================================================\")\n",
    "            print(f\"Batch Size: {batch_size}; Augmentation: {augmentation}; Optimizer: {optimizer_id}; Num Params: {num_params}\\n\")\n",
    "\n",
    "            train_losses = []\n",
    "            val_losses = []\n",
    "            train_accuracies = []\n",
    "            val_accuracies = []\n",
    "\n",
    "            try:\n",
    "                if augmentation == 'no':\n",
    "                    transform_train = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "                elif augmentation == 'random_crop':\n",
    "                    transform_train = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "                elif augmentation == 'random_horizontal_flip':\n",
    "                    transform_train = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.RandomHorizontalFlip(),\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "                elif augmentation == 'random_rotate':\n",
    "                    transform_train = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.RandomRotation(15),\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "                elif augmentation == 'random_resized_crop':\n",
    "                    transform_train = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "                elif augmentation == 'random_affine':\n",
    "                    transform_train = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "                elif augmentation == 'random_erasing':\n",
    "                    transform_train = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                        torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))])\n",
    "\n",
    "                transform_test = torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.ToTensor(), \n",
    "                                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "                trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "                trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "                testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "                testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "                lr_min = 1e-4\n",
    "                lr_max = 1e-1\n",
    "\n",
    "                if optimizer_id == 'SGD':\n",
    "                    optimizer = torch.optim.SGD(model.parameters(), lr_min, momentum=0.9, weight_decay=0.0001)\n",
    "                    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, lr_min, lr_max, step_size_up=10000, gamma=0.85, cycle_momentum=True)\n",
    "                elif optimizer_id == 'SGD with Nesterov':\n",
    "                    optimizer = torch.optim.SGD(model.parameters(), lr_min, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "                    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, lr_min, lr_max, step_size_up=10000, gamma=0.85, cycle_momentum=True)\n",
    "                else:\n",
    "                    if optimizer_id == 'ASGD':\n",
    "                        optimizer = torch.optim.ASGD(model.parameters(), lr_min, weight_decay=0.0001)\n",
    "                    elif optimizer_id == 'Adam':\n",
    "                        optimizer = torch.optim.Adam(model.parameters(), lr_min, weight_decay=0.0001)\n",
    "                    elif optimizer_id == 'Adamax':\n",
    "                        optimizer = torch.optim.Adamax(model.parameters(), lr_min, weight_decay=0.0001)\n",
    "                    elif optimizer_id == 'Adadelta':\n",
    "                        optimizer = torch.optim.Adadelta(model.parameters(), lr_min, weight_decay=0.0001)\n",
    "                    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, lr_min, lr_max, step_size_up=10000, gamma=0.85, cycle_momentum=False)\n",
    "\n",
    "                epochs = 5\n",
    "                for epoch in range(epochs):\n",
    "                    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, scheduler, True, batch_size = batch_size)\n",
    "                    train_losses.append(train_loss)\n",
    "                    train_accuracies.append(train_accuracy)\n",
    "                    val_loss, val_accuracy = test(model, criterion, testloader, device, batch_size = batch_size)\n",
    "                    val_losses.append(val_loss)\n",
    "                    val_accuracies.append(val_accuracy)\n",
    "                    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "                    print(f\"\\tTraining Loss   : {round(train_loss, 4)}; Training Accuracy   : {round(train_accuracy*100, 4)}%\")\n",
    "                    print(f\"\\tValidation Loss : {round(val_loss, 4)}; Validation Accuracy : {round(val_accuracy*100, 4)}%\")\n",
    "            except Exception as e:\n",
    "                metrics_dict[batch_size][augmentation][optimizer_id]['error'] = str(e)\n",
    "                print(f\"\\tError: {str(e)}\")\n",
    "            metrics_dict[batch_size][augmentation][optimizer_id]['train_loss'] = train_losses\n",
    "            metrics_dict[batch_size][augmentation][optimizer_id]['train_acc'] = train_accuracies\n",
    "            metrics_dict[batch_size][augmentation][optimizer_id]['valid_loss'] = val_losses\n",
    "            metrics_dict[batch_size][augmentation][optimizer_id]['valid_acc'] = val_accuracies\n",
    "            print(\"=========================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3220ef9-44e3-4b2c-8ef1-1e32de9ee7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_obj = json.dumps(metrics_dict, indent = 4)\n",
    "\n",
    "with open(\"metrics.json\", \"w\") as outfile:\n",
    "    json.dump(json_obj, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3d0ab6d-3bd4-417d-a1a5-b7818dabf3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for b_s in list(metrics_dict.keys()):\n",
    "    for aug in list(metrics_dict[b_s].keys()):\n",
    "        for opt in list(metrics_dict[b_s][aug].keys()):\n",
    "            train_loss = metrics_dict[b_s][aug][opt]['train_loss'][-1]\n",
    "            train_acc = metrics_dict[b_s][aug][opt]['train_acc'][-1]*100\n",
    "            valid_loss = metrics_dict[b_s][aug][opt]['valid_loss'][-1]\n",
    "            valid_acc = metrics_dict[b_s][aug][opt]['valid_acc'][-1]*100\n",
    "            row = [b_s, aug, opt, train_loss, valid_loss, train_acc, valid_acc]\n",
    "            rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2bd8d92-ceb3-4c29-832c-52d6bfc6a5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>no</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.856368</td>\n",
       "      <td>0.552547</td>\n",
       "      <td>85.174</td>\n",
       "      <td>81.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>no</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>0.824306</td>\n",
       "      <td>0.551144</td>\n",
       "      <td>85.348</td>\n",
       "      <td>81.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>no</td>\n",
       "      <td>ASGD</td>\n",
       "      <td>1.049168</td>\n",
       "      <td>0.810727</td>\n",
       "      <td>81.768</td>\n",
       "      <td>73.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>no</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2.585961</td>\n",
       "      <td>1.659058</td>\n",
       "      <td>54.276</td>\n",
       "      <td>40.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>no</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>1.840848</td>\n",
       "      <td>1.019998</td>\n",
       "      <td>67.942</td>\n",
       "      <td>64.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>128</td>\n",
       "      <td>random_erasing</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.218360</td>\n",
       "      <td>1.266651</td>\n",
       "      <td>78.466</td>\n",
       "      <td>63.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>128</td>\n",
       "      <td>random_erasing</td>\n",
       "      <td>ASGD</td>\n",
       "      <td>2.049126</td>\n",
       "      <td>1.058681</td>\n",
       "      <td>63.284</td>\n",
       "      <td>62.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>128</td>\n",
       "      <td>random_erasing</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1.753814</td>\n",
       "      <td>1.043496</td>\n",
       "      <td>69.298</td>\n",
       "      <td>64.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>128</td>\n",
       "      <td>random_erasing</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>1.449330</td>\n",
       "      <td>0.801869</td>\n",
       "      <td>74.776</td>\n",
       "      <td>72.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>128</td>\n",
       "      <td>random_erasing</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>2.315948</td>\n",
       "      <td>1.161275</td>\n",
       "      <td>58.940</td>\n",
       "      <td>57.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_size    augmentation          optimizer  train_loss  valid_loss  \\\n",
       "0            32              no                SGD    0.856368    0.552547   \n",
       "1            32              no  SGD with Nesterov    0.824306    0.551144   \n",
       "2            32              no               ASGD    1.049168    0.810727   \n",
       "3            32              no               Adam    2.585961    1.659058   \n",
       "4            32              no             Adamax    1.840848    1.019998   \n",
       "..          ...             ...                ...         ...         ...   \n",
       "121         128  random_erasing  SGD with Nesterov    1.218360    1.266651   \n",
       "122         128  random_erasing               ASGD    2.049126    1.058681   \n",
       "123         128  random_erasing               Adam    1.753814    1.043496   \n",
       "124         128  random_erasing             Adamax    1.449330    0.801869   \n",
       "125         128  random_erasing           Adadelta    2.315948    1.161275   \n",
       "\n",
       "     train_acc  valid_acc  \n",
       "0       85.174      81.19  \n",
       "1       85.348      81.77  \n",
       "2       81.768      73.52  \n",
       "3       54.276      40.51  \n",
       "4       67.942      64.22  \n",
       "..         ...        ...  \n",
       "121     78.466      63.24  \n",
       "122     63.284      62.90  \n",
       "123     69.298      64.62  \n",
       "124     74.776      72.80  \n",
       "125     58.940      57.78  \n",
       "\n",
       "[126 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['batch_size', 'augmentation', 'optimizer', 'train_loss', 'valid_loss', 'train_acc', 'valid_acc']\n",
    "df = pd.DataFrame(rows, columns = columns)\n",
    "df.to_csv('metrics.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7295044f-ca83-4dfe-91c6-d438c1df4785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suriy\\AppData\\Local\\Temp\\ipykernel_8772\\1658992418.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df['batch_size'] == 32][df['optimizer'] == 'SGD with Nesterov']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>no</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>0.824306</td>\n",
       "      <td>0.551144</td>\n",
       "      <td>85.348</td>\n",
       "      <td>81.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>random_crop</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.147717</td>\n",
       "      <td>0.578310</td>\n",
       "      <td>80.240</td>\n",
       "      <td>80.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>random_horizontal_flip</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>0.946680</td>\n",
       "      <td>0.597674</td>\n",
       "      <td>83.478</td>\n",
       "      <td>79.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32</td>\n",
       "      <td>random_rotate</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.161062</td>\n",
       "      <td>0.609516</td>\n",
       "      <td>79.840</td>\n",
       "      <td>78.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>32</td>\n",
       "      <td>random_resized_crop</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.084598</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>81.040</td>\n",
       "      <td>80.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>random_affine</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.375324</td>\n",
       "      <td>0.630698</td>\n",
       "      <td>76.018</td>\n",
       "      <td>78.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>32</td>\n",
       "      <td>random_erasing</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.077594</td>\n",
       "      <td>0.710151</td>\n",
       "      <td>81.130</td>\n",
       "      <td>76.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_size            augmentation          optimizer  train_loss  \\\n",
       "1           32                      no  SGD with Nesterov    0.824306   \n",
       "7           32             random_crop  SGD with Nesterov    1.147717   \n",
       "13          32  random_horizontal_flip  SGD with Nesterov    0.946680   \n",
       "19          32           random_rotate  SGD with Nesterov    1.161062   \n",
       "25          32     random_resized_crop  SGD with Nesterov    1.084598   \n",
       "31          32           random_affine  SGD with Nesterov    1.375324   \n",
       "37          32          random_erasing  SGD with Nesterov    1.077594   \n",
       "\n",
       "    valid_loss  train_acc  valid_acc  \n",
       "1     0.551144     85.348      81.77  \n",
       "7     0.578310     80.240      80.63  \n",
       "13    0.597674     83.478      79.60  \n",
       "19    0.609516     79.840      78.65  \n",
       "25    0.552147     81.040      80.83  \n",
       "31    0.630698     76.018      78.55  \n",
       "37    0.710151     81.130      76.79  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['batch_size'] == 32][df['optimizer'] == 'SGD with Nesterov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e5a591e-8b56-4473-8a95-0c46da0c31de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suriy\\AppData\\Local\\Temp\\ipykernel_8772\\83037611.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df['batch_size'] == 64][df['optimizer'] == 'SGD with Nesterov']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>64</td>\n",
       "      <td>no</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>0.866554</td>\n",
       "      <td>0.615567</td>\n",
       "      <td>84.870</td>\n",
       "      <td>79.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>64</td>\n",
       "      <td>random_crop</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.211746</td>\n",
       "      <td>0.650072</td>\n",
       "      <td>79.008</td>\n",
       "      <td>78.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>64</td>\n",
       "      <td>random_horizontal_flip</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>0.995144</td>\n",
       "      <td>0.824317</td>\n",
       "      <td>82.616</td>\n",
       "      <td>73.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>64</td>\n",
       "      <td>random_rotate</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.214871</td>\n",
       "      <td>0.661693</td>\n",
       "      <td>78.810</td>\n",
       "      <td>77.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>64</td>\n",
       "      <td>random_resized_crop</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.155625</td>\n",
       "      <td>0.871453</td>\n",
       "      <td>79.786</td>\n",
       "      <td>72.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>64</td>\n",
       "      <td>random_affine</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.452721</td>\n",
       "      <td>0.714894</td>\n",
       "      <td>74.678</td>\n",
       "      <td>75.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>64</td>\n",
       "      <td>random_erasing</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.131242</td>\n",
       "      <td>0.658130</td>\n",
       "      <td>80.066</td>\n",
       "      <td>77.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_size            augmentation          optimizer  train_loss  \\\n",
       "43          64                      no  SGD with Nesterov    0.866554   \n",
       "49          64             random_crop  SGD with Nesterov    1.211746   \n",
       "55          64  random_horizontal_flip  SGD with Nesterov    0.995144   \n",
       "61          64           random_rotate  SGD with Nesterov    1.214871   \n",
       "67          64     random_resized_crop  SGD with Nesterov    1.155625   \n",
       "73          64           random_affine  SGD with Nesterov    1.452721   \n",
       "79          64          random_erasing  SGD with Nesterov    1.131242   \n",
       "\n",
       "    valid_loss  train_acc  valid_acc  \n",
       "43    0.615567     84.870      79.91  \n",
       "49    0.650072     79.008      78.16  \n",
       "55    0.824317     82.616      73.04  \n",
       "61    0.661693     78.810      77.58  \n",
       "67    0.871453     79.786      72.45  \n",
       "73    0.714894     74.678      75.17  \n",
       "79    0.658130     80.066      77.49  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['batch_size'] == 64][df['optimizer'] == 'SGD with Nesterov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "709861ef-a541-40ec-aee1-a23ca0e9aafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suriy\\AppData\\Local\\Temp\\ipykernel_8772\\2440078975.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df['batch_size'] == 128][df['optimizer'] == 'SGD with Nesterov']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>128</td>\n",
       "      <td>no</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>0.969546</td>\n",
       "      <td>0.703783</td>\n",
       "      <td>83.028</td>\n",
       "      <td>76.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>128</td>\n",
       "      <td>random_crop</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.304945</td>\n",
       "      <td>0.718166</td>\n",
       "      <td>77.264</td>\n",
       "      <td>76.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>128</td>\n",
       "      <td>random_horizontal_flip</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.059241</td>\n",
       "      <td>0.692874</td>\n",
       "      <td>81.560</td>\n",
       "      <td>76.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>128</td>\n",
       "      <td>random_rotate</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.319997</td>\n",
       "      <td>0.682015</td>\n",
       "      <td>76.828</td>\n",
       "      <td>77.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>128</td>\n",
       "      <td>random_resized_crop</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.247956</td>\n",
       "      <td>0.750942</td>\n",
       "      <td>78.176</td>\n",
       "      <td>74.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>128</td>\n",
       "      <td>random_affine</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.574058</td>\n",
       "      <td>0.715928</td>\n",
       "      <td>72.208</td>\n",
       "      <td>75.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>128</td>\n",
       "      <td>random_erasing</td>\n",
       "      <td>SGD with Nesterov</td>\n",
       "      <td>1.218360</td>\n",
       "      <td>1.266651</td>\n",
       "      <td>78.466</td>\n",
       "      <td>63.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_size            augmentation          optimizer  train_loss  \\\n",
       "85          128                      no  SGD with Nesterov    0.969546   \n",
       "91          128             random_crop  SGD with Nesterov    1.304945   \n",
       "97          128  random_horizontal_flip  SGD with Nesterov    1.059241   \n",
       "103         128           random_rotate  SGD with Nesterov    1.319997   \n",
       "109         128     random_resized_crop  SGD with Nesterov    1.247956   \n",
       "115         128           random_affine  SGD with Nesterov    1.574058   \n",
       "121         128          random_erasing  SGD with Nesterov    1.218360   \n",
       "\n",
       "     valid_loss  train_acc  valid_acc  \n",
       "85     0.703783     83.028      76.15  \n",
       "91     0.718166     77.264      76.63  \n",
       "97     0.692874     81.560      76.17  \n",
       "103    0.682015     76.828      77.00  \n",
       "109    0.750942     78.176      74.21  \n",
       "115    0.715928     72.208      75.37  \n",
       "121    1.266651     78.466      63.24  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['batch_size'] == 128][df['optimizer'] == 'SGD with Nesterov']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e0235a-a7f5-4475-a26b-b7de24b4040e",
   "metadata": {},
   "source": [
    "### 32-Batch Best Model Test : 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d8645038-b25f-4af5-8da5-967f2c860647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.7754; Training Accuracy: 31.19%\n",
      "\tTesting Loss: 1.6541; Testing Accuracy: 39.56%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 3.2455; Training Accuracy: 40.714%\n",
      "\tTesting Loss: 1.4607; Testing Accuracy: 46.2%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 3.0015; Training Accuracy: 45.488%\n",
      "\tTesting Loss: 1.3887; Testing Accuracy: 49.12%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 2.8038; Training Accuracy: 49.496%\n",
      "\tTesting Loss: 1.3523; Testing Accuracy: 51.33%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 2.6495; Training Accuracy: 52.486%\n",
      "\tTesting Loss: 1.2799; Testing Accuracy: 53.91%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 2.5078; Training Accuracy: 55.354%\n",
      "\tTesting Loss: 1.2978; Testing Accuracy: 53.41%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 2.3791; Training Accuracy: 57.43%\n",
      "\tTesting Loss: 1.201; Testing Accuracy: 57.81%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 2.2689; Training Accuracy: 59.72%\n",
      "\tTesting Loss: 1.1018; Testing Accuracy: 60.34%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 2.1777; Training Accuracy: 61.464%\n",
      "\tTesting Loss: 1.0354; Testing Accuracy: 63.27%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 2.103; Training Accuracy: 62.744%\n",
      "\tTesting Loss: 1.0446; Testing Accuracy: 63.14%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 2.0182; Training Accuracy: 64.492%\n",
      "\tTesting Loss: 1.0024; Testing Accuracy: 64.96%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 1.9568; Training Accuracy: 65.542%\n",
      "\tTesting Loss: 0.9578; Testing Accuracy: 65.89%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 1.8984; Training Accuracy: 66.64%\n",
      "\tTesting Loss: 0.9412; Testing Accuracy: 66.44%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 1.8352; Training Accuracy: 67.926%\n",
      "\tTesting Loss: 0.9011; Testing Accuracy: 68.21%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 1.7816; Training Accuracy: 68.866%\n",
      "\tTesting Loss: 0.8769; Testing Accuracy: 68.96%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 1.7389; Training Accuracy: 69.496%\n",
      "\tTesting Loss: 0.867; Testing Accuracy: 69.64%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 1.6872; Training Accuracy: 70.47%\n",
      "\tTesting Loss: 0.8779; Testing Accuracy: 69.63%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 1.6489; Training Accuracy: 71.39%\n",
      "\tTesting Loss: 0.8456; Testing Accuracy: 71.16%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 1.6043; Training Accuracy: 72.03%\n",
      "\tTesting Loss: 0.7834; Testing Accuracy: 72.66%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 1.5625; Training Accuracy: 72.7%\n",
      "\tTesting Loss: 0.7625; Testing Accuracy: 73.68%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 1.5219; Training Accuracy: 73.4%\n",
      "\tTesting Loss: 0.7688; Testing Accuracy: 73.78%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 1.4781; Training Accuracy: 74.228%\n",
      "\tTesting Loss: 0.7487; Testing Accuracy: 74.33%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 1.448; Training Accuracy: 74.728%\n",
      "\tTesting Loss: 0.7346; Testing Accuracy: 75.19%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 1.4143; Training Accuracy: 75.47%\n",
      "\tTesting Loss: 0.7533; Testing Accuracy: 74.66%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 1.3883; Training Accuracy: 75.946%\n",
      "\tTesting Loss: 0.7439; Testing Accuracy: 75.16%\n",
      "\n",
      "\tEpoch: 25\n",
      "\tTraining Loss: 1.3518; Training Accuracy: 76.438%\n",
      "\tTesting Loss: 0.7686; Testing Accuracy: 74.09%\n",
      "\n",
      "\tEpoch: 26\n",
      "\tTraining Loss: 1.3263; Training Accuracy: 76.832%\n",
      "\tTesting Loss: 0.7043; Testing Accuracy: 75.83%\n",
      "\n",
      "\tEpoch: 27\n",
      "\tTraining Loss: 1.2935; Training Accuracy: 77.578%\n",
      "\tTesting Loss: 0.6571; Testing Accuracy: 77.53%\n",
      "\n",
      "\tEpoch: 28\n",
      "\tTraining Loss: 1.2756; Training Accuracy: 77.824%\n",
      "\tTesting Loss: 0.6836; Testing Accuracy: 76.59%\n",
      "\n",
      "\tEpoch: 29\n",
      "\tTraining Loss: 1.2469; Training Accuracy: 78.398%\n",
      "\tTesting Loss: 0.6354; Testing Accuracy: 78.14%\n",
      "\n",
      "\tEpoch: 30\n",
      "\tTraining Loss: 1.2224; Training Accuracy: 78.728%\n",
      "\tTesting Loss: 0.6372; Testing Accuracy: 78.44%\n",
      "\n",
      "\tEpoch: 31\n",
      "\tTraining Loss: 1.2018; Training Accuracy: 79.268%\n",
      "\tTesting Loss: 0.6098; Testing Accuracy: 79.49%\n",
      "\n",
      "\tEpoch: 32\n",
      "\tTraining Loss: 1.1678; Training Accuracy: 79.744%\n",
      "\tTesting Loss: 0.6565; Testing Accuracy: 77.99%\n",
      "\n",
      "\tEpoch: 33\n",
      "\tTraining Loss: 1.1558; Training Accuracy: 80.12%\n",
      "\tTesting Loss: 0.6542; Testing Accuracy: 78.28%\n",
      "\n",
      "\tEpoch: 34\n",
      "\tTraining Loss: 1.1337; Training Accuracy: 80.362%\n",
      "\tTesting Loss: 0.6096; Testing Accuracy: 79.27%\n",
      "\n",
      "\tEpoch: 35\n",
      "\tTraining Loss: 1.1203; Training Accuracy: 80.462%\n",
      "\tTesting Loss: 0.6186; Testing Accuracy: 79.59%\n",
      "\n",
      "\tEpoch: 36\n",
      "\tTraining Loss: 1.0931; Training Accuracy: 81.044%\n",
      "\tTesting Loss: 0.593; Testing Accuracy: 79.89%\n",
      "\n",
      "\tEpoch: 37\n",
      "\tTraining Loss: 1.0779; Training Accuracy: 81.406%\n",
      "\tTesting Loss: 0.5626; Testing Accuracy: 81.13%\n",
      "\n",
      "\tEpoch: 38\n",
      "\tTraining Loss: 1.0597; Training Accuracy: 81.716%\n",
      "\tTesting Loss: 0.6024; Testing Accuracy: 79.83%\n",
      "\n",
      "\tEpoch: 39\n",
      "\tTraining Loss: 1.0432; Training Accuracy: 82.044%\n",
      "\tTesting Loss: 0.5594; Testing Accuracy: 81.29%\n",
      "\n",
      "\tEpoch: 40\n",
      "\tTraining Loss: 1.0209; Training Accuracy: 82.252%\n",
      "\tTesting Loss: 0.5591; Testing Accuracy: 81.11%\n",
      "\n",
      "\tEpoch: 41\n",
      "\tTraining Loss: 1.0184; Training Accuracy: 82.314%\n",
      "\tTesting Loss: 0.5647; Testing Accuracy: 81.17%\n",
      "\n",
      "\tEpoch: 42\n",
      "\tTraining Loss: 0.9987; Training Accuracy: 82.78%\n",
      "\tTesting Loss: 0.6103; Testing Accuracy: 80.11%\n",
      "\n",
      "\tEpoch: 43\n",
      "\tTraining Loss: 0.9828; Training Accuracy: 82.92%\n",
      "\tTesting Loss: 0.5465; Testing Accuracy: 81.7%\n",
      "\n",
      "\tEpoch: 44\n",
      "\tTraining Loss: 0.9693; Training Accuracy: 83.198%\n",
      "\tTesting Loss: 0.5511; Testing Accuracy: 81.81%\n",
      "\n",
      "\tEpoch: 45\n",
      "\tTraining Loss: 0.9569; Training Accuracy: 83.44%\n",
      "\tTesting Loss: 0.508; Testing Accuracy: 82.87%\n",
      "\n",
      "\tEpoch: 46\n",
      "\tTraining Loss: 0.9415; Training Accuracy: 83.852%\n",
      "\tTesting Loss: 0.5578; Testing Accuracy: 81.75%\n",
      "\n",
      "\tEpoch: 47\n",
      "\tTraining Loss: 0.9219; Training Accuracy: 84.272%\n",
      "\tTesting Loss: 0.5205; Testing Accuracy: 82.08%\n",
      "\n",
      "\tEpoch: 48\n",
      "\tTraining Loss: 0.914; Training Accuracy: 84.296%\n",
      "\tTesting Loss: 0.5437; Testing Accuracy: 81.87%\n",
      "\n",
      "\tEpoch: 49\n",
      "\tTraining Loss: 0.8967; Training Accuracy: 84.498%\n",
      "\tTesting Loss: 0.5259; Testing Accuracy: 82.67%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr_min = 1e-4\n",
    "lr_max = 1e-1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr_min, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, lr_min, lr_max, step_size_up=10, gamma=0.85, cycle_momentum=True)\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = batch_size)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = batch_size)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "651affbc-42aa-403b-abfb-982b5a1a87f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.8838; Training Accuracy: 47.548%\n",
      "\tTesting Loss: 1.4132; Testing Accuracy: 52.52%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.0007; Training Accuracy: 64.462%\n",
      "\tTesting Loss: 0.9203; Testing Accuracy: 69.2%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.6315; Training Accuracy: 71.716%\n",
      "\tTesting Loss: 0.8155; Testing Accuracy: 73.1%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.4254; Training Accuracy: 75.178%\n",
      "\tTesting Loss: 0.6703; Testing Accuracy: 77.32%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.2814; Training Accuracy: 77.87%\n",
      "\tTesting Loss: 0.6159; Testing Accuracy: 79.04%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 1.169; Training Accuracy: 79.848%\n",
      "\tTesting Loss: 0.6443; Testing Accuracy: 78.62%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 1.0691; Training Accuracy: 81.342%\n",
      "\tTesting Loss: 0.6004; Testing Accuracy: 80.16%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 0.9985; Training Accuracy: 82.642%\n",
      "\tTesting Loss: 0.5193; Testing Accuracy: 82.84%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 0.9381; Training Accuracy: 83.722%\n",
      "\tTesting Loss: 0.4991; Testing Accuracy: 83.4%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 0.8713; Training Accuracy: 85.008%\n",
      "\tTesting Loss: 0.4716; Testing Accuracy: 84.73%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 0.8212; Training Accuracy: 85.654%\n",
      "\tTesting Loss: 0.4536; Testing Accuracy: 84.78%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 0.7785; Training Accuracy: 86.282%\n",
      "\tTesting Loss: 0.5683; Testing Accuracy: 82.28%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 0.745; Training Accuracy: 86.914%\n",
      "\tTesting Loss: 0.4323; Testing Accuracy: 85.9%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.6992; Training Accuracy: 87.978%\n",
      "\tTesting Loss: 0.4663; Testing Accuracy: 85.03%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.6732; Training Accuracy: 88.276%\n",
      "\tTesting Loss: 0.4143; Testing Accuracy: 86.12%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.6371; Training Accuracy: 89.002%\n",
      "\tTesting Loss: 0.4898; Testing Accuracy: 84.49%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.6144; Training Accuracy: 89.25%\n",
      "\tTesting Loss: 0.4307; Testing Accuracy: 86.18%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.5909; Training Accuracy: 89.828%\n",
      "\tTesting Loss: 0.4259; Testing Accuracy: 86.37%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.557; Training Accuracy: 90.324%\n",
      "\tTesting Loss: 0.4328; Testing Accuracy: 86.15%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.5466; Training Accuracy: 90.552%\n",
      "\tTesting Loss: 0.3731; Testing Accuracy: 87.87%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.5208; Training Accuracy: 90.916%\n",
      "\tTesting Loss: 0.3884; Testing Accuracy: 87.88%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.51; Training Accuracy: 91.108%\n",
      "\tTesting Loss: 0.3394; Testing Accuracy: 89.26%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.4867; Training Accuracy: 91.632%\n",
      "\tTesting Loss: 0.3911; Testing Accuracy: 87.82%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.4649; Training Accuracy: 91.914%\n",
      "\tTesting Loss: 0.3447; Testing Accuracy: 88.78%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.4565; Training Accuracy: 91.994%\n",
      "\tTesting Loss: 0.3617; Testing Accuracy: 88.55%\n",
      "\n",
      "\tEpoch: 25\n",
      "\tTraining Loss: 0.4384; Training Accuracy: 92.394%\n",
      "\tTesting Loss: 0.3606; Testing Accuracy: 88.59%\n",
      "\n",
      "\tEpoch: 26\n",
      "\tTraining Loss: 0.4208; Training Accuracy: 92.668%\n",
      "\tTesting Loss: 0.381; Testing Accuracy: 88.47%\n",
      "\n",
      "\tEpoch: 27\n",
      "\tTraining Loss: 0.4059; Training Accuracy: 92.908%\n",
      "\tTesting Loss: 0.3562; Testing Accuracy: 88.8%\n",
      "\n",
      "\tEpoch: 28\n",
      "\tTraining Loss: 0.4039; Training Accuracy: 93.024%\n",
      "\tTesting Loss: 0.3494; Testing Accuracy: 88.79%\n",
      "\n",
      "\tEpoch: 29\n",
      "\tTraining Loss: 0.3919; Training Accuracy: 93.126%\n",
      "\tTesting Loss: 0.356; Testing Accuracy: 89.03%\n",
      "\n",
      "\tEpoch: 30\n",
      "\tTraining Loss: 0.3888; Training Accuracy: 93.212%\n",
      "\tTesting Loss: 0.3235; Testing Accuracy: 89.92%\n",
      "\n",
      "\tEpoch: 31\n",
      "\tTraining Loss: 0.3652; Training Accuracy: 93.504%\n",
      "\tTesting Loss: 0.3571; Testing Accuracy: 89.42%\n",
      "\n",
      "\tEpoch: 32\n",
      "\tTraining Loss: 0.3626; Training Accuracy: 93.648%\n",
      "\tTesting Loss: 0.3596; Testing Accuracy: 88.97%\n",
      "\n",
      "\tEpoch: 33\n",
      "\tTraining Loss: 0.3485; Training Accuracy: 93.976%\n",
      "\tTesting Loss: 0.332; Testing Accuracy: 89.55%\n",
      "\n",
      "\tEpoch: 34\n",
      "\tTraining Loss: 0.3425; Training Accuracy: 94.078%\n",
      "\tTesting Loss: 0.3404; Testing Accuracy: 89.53%\n",
      "\n",
      "\tEpoch: 35\n",
      "\tTraining Loss: 0.3246; Training Accuracy: 94.398%\n",
      "\tTesting Loss: 0.3604; Testing Accuracy: 89.04%\n",
      "\n",
      "\tEpoch: 36\n",
      "\tTraining Loss: 0.33; Training Accuracy: 94.216%\n",
      "\tTesting Loss: 0.3606; Testing Accuracy: 89.05%\n",
      "\n",
      "\tEpoch: 37\n",
      "\tTraining Loss: 0.3153; Training Accuracy: 94.508%\n",
      "\tTesting Loss: 0.4026; Testing Accuracy: 87.87%\n",
      "\n",
      "\tEpoch: 38\n",
      "\tTraining Loss: 0.3182; Training Accuracy: 94.438%\n",
      "\tTesting Loss: 0.3377; Testing Accuracy: 89.56%\n",
      "\n",
      "\tEpoch: 39\n",
      "\tTraining Loss: 0.2954; Training Accuracy: 94.894%\n",
      "\tTesting Loss: 0.3605; Testing Accuracy: 89.24%\n",
      "\n",
      "\tEpoch: 40\n",
      "\tTraining Loss: 0.2974; Training Accuracy: 94.832%\n",
      "\tTesting Loss: 0.3543; Testing Accuracy: 89.3%\n",
      "\n",
      "\tEpoch: 41\n",
      "\tTraining Loss: 0.2891; Training Accuracy: 94.97%\n",
      "\tTesting Loss: 0.3369; Testing Accuracy: 89.97%\n",
      "\n",
      "\tEpoch: 42\n",
      "\tTraining Loss: 0.286; Training Accuracy: 95.102%\n",
      "\tTesting Loss: 0.3216; Testing Accuracy: 90.22%\n",
      "\n",
      "\tEpoch: 43\n",
      "\tTraining Loss: 0.2699; Training Accuracy: 95.224%\n",
      "\tTesting Loss: 0.3441; Testing Accuracy: 90.04%\n",
      "\n",
      "\tEpoch: 44\n",
      "\tTraining Loss: 0.2856; Training Accuracy: 95.028%\n",
      "\tTesting Loss: 0.331; Testing Accuracy: 90.31%\n",
      "\n",
      "\tEpoch: 45\n",
      "\tTraining Loss: 0.2704; Training Accuracy: 95.304%\n",
      "\tTesting Loss: 0.3655; Testing Accuracy: 89.29%\n",
      "\n",
      "\tEpoch: 46\n",
      "\tTraining Loss: 0.262; Training Accuracy: 95.518%\n",
      "\tTesting Loss: 0.3456; Testing Accuracy: 89.64%\n",
      "\n",
      "\tEpoch: 47\n",
      "\tTraining Loss: 0.2615; Training Accuracy: 95.388%\n",
      "\tTesting Loss: 0.3737; Testing Accuracy: 89.37%\n",
      "\n",
      "\tEpoch: 48\n",
      "\tTraining Loss: 0.2601; Training Accuracy: 95.518%\n",
      "\tTesting Loss: 0.3609; Testing Accuracy: 89.51%\n",
      "\n",
      "\tEpoch: 49\n",
      "\tTraining Loss: 0.2535; Training Accuracy: 95.65%\n",
      "\tTesting Loss: 0.3784; Testing Accuracy: 89.58%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = batch_size)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = batch_size)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "424d0a75-6a84-405a-b925-c5e958c50b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.2705; Training Accuracy: 39.896%\n",
      "\tTesting Loss: 1.2401; Testing Accuracy: 55.04%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.3197; Training Accuracy: 58.602%\n",
      "\tTesting Loss: 1.1184; Testing Accuracy: 60.96%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.9093; Training Accuracy: 66.428%\n",
      "\tTesting Loss: 0.8954; Testing Accuracy: 68.66%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.6293; Training Accuracy: 71.382%\n",
      "\tTesting Loss: 0.8284; Testing Accuracy: 72.17%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.4244; Training Accuracy: 75.22%\n",
      "\tTesting Loss: 0.6908; Testing Accuracy: 76.36%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 1.3082; Training Accuracy: 77.316%\n",
      "\tTesting Loss: 0.6786; Testing Accuracy: 77.65%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 1.2148; Training Accuracy: 79.052%\n",
      "\tTesting Loss: 0.6042; Testing Accuracy: 79.79%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 1.1519; Training Accuracy: 80.142%\n",
      "\tTesting Loss: 0.6133; Testing Accuracy: 79.58%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 1.0897; Training Accuracy: 81.27%\n",
      "\tTesting Loss: 0.5494; Testing Accuracy: 81.19%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 1.0471; Training Accuracy: 81.832%\n",
      "\tTesting Loss: 0.6101; Testing Accuracy: 80.5%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 1.0123; Training Accuracy: 82.47%\n",
      "\tTesting Loss: 0.6924; Testing Accuracy: 78.15%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 0.9823; Training Accuracy: 83.17%\n",
      "\tTesting Loss: 0.6692; Testing Accuracy: 79.37%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 0.9588; Training Accuracy: 83.404%\n",
      "\tTesting Loss: 0.5612; Testing Accuracy: 82.35%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.9443; Training Accuracy: 83.942%\n",
      "\tTesting Loss: 0.649; Testing Accuracy: 78.2%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.9221; Training Accuracy: 84.36%\n",
      "\tTesting Loss: 0.5544; Testing Accuracy: 82.25%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.8993; Training Accuracy: 84.61%\n",
      "\tTesting Loss: 0.6229; Testing Accuracy: 79.91%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.8776; Training Accuracy: 84.824%\n",
      "\tTesting Loss: 0.5436; Testing Accuracy: 82.12%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.8742; Training Accuracy: 84.81%\n",
      "\tTesting Loss: 0.5616; Testing Accuracy: 81.99%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.8589; Training Accuracy: 85.164%\n",
      "\tTesting Loss: 0.5065; Testing Accuracy: 83.44%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.8574; Training Accuracy: 85.172%\n",
      "\tTesting Loss: 0.5845; Testing Accuracy: 80.97%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.8491; Training Accuracy: 85.342%\n",
      "\tTesting Loss: 0.5082; Testing Accuracy: 83.46%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.8431; Training Accuracy: 85.496%\n",
      "\tTesting Loss: 0.4669; Testing Accuracy: 84.14%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.8268; Training Accuracy: 85.702%\n",
      "\tTesting Loss: 0.5417; Testing Accuracy: 82.69%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.8291; Training Accuracy: 85.626%\n",
      "\tTesting Loss: 0.4411; Testing Accuracy: 84.99%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.8069; Training Accuracy: 86.154%\n",
      "\tTesting Loss: 0.4966; Testing Accuracy: 83.97%\n",
      "\n",
      "\tEpoch: 25\n",
      "\tTraining Loss: 0.802; Training Accuracy: 86.376%\n",
      "\tTesting Loss: 0.5212; Testing Accuracy: 82.96%\n",
      "\n",
      "\tEpoch: 26\n",
      "\tTraining Loss: 0.7999; Training Accuracy: 86.25%\n",
      "\tTesting Loss: 0.4983; Testing Accuracy: 84.06%\n",
      "\n",
      "\tEpoch: 27\n",
      "\tTraining Loss: 0.798; Training Accuracy: 86.358%\n",
      "\tTesting Loss: 0.4576; Testing Accuracy: 84.78%\n",
      "\n",
      "\tEpoch: 28\n",
      "\tTraining Loss: 0.793; Training Accuracy: 86.456%\n",
      "\tTesting Loss: 0.5127; Testing Accuracy: 83.4%\n",
      "\n",
      "\tEpoch: 29\n",
      "\tTraining Loss: 0.7867; Training Accuracy: 86.5%\n",
      "\tTesting Loss: 0.461; Testing Accuracy: 84.72%\n",
      "\n",
      "\tEpoch: 30\n",
      "\tTraining Loss: 0.7953; Training Accuracy: 86.318%\n",
      "\tTesting Loss: 0.505; Testing Accuracy: 83.4%\n",
      "\n",
      "\tEpoch: 31\n",
      "\tTraining Loss: 0.779; Training Accuracy: 86.68%\n",
      "\tTesting Loss: 0.5026; Testing Accuracy: 83.57%\n",
      "\n",
      "\tEpoch: 32\n",
      "\tTraining Loss: 0.7766; Training Accuracy: 86.688%\n",
      "\tTesting Loss: 0.4738; Testing Accuracy: 83.92%\n",
      "\n",
      "\tEpoch: 33\n",
      "\tTraining Loss: 0.7746; Training Accuracy: 86.702%\n",
      "\tTesting Loss: 0.5199; Testing Accuracy: 83.96%\n",
      "\n",
      "\tEpoch: 34\n",
      "\tTraining Loss: 0.7705; Training Accuracy: 86.772%\n",
      "\tTesting Loss: 0.4444; Testing Accuracy: 84.94%\n",
      "\n",
      "\tEpoch: 35\n",
      "\tTraining Loss: 0.7711; Training Accuracy: 86.58%\n",
      "\tTesting Loss: 0.4787; Testing Accuracy: 84.64%\n",
      "\n",
      "\tEpoch: 36\n",
      "\tTraining Loss: 0.772; Training Accuracy: 86.692%\n",
      "\tTesting Loss: 0.4663; Testing Accuracy: 84.37%\n",
      "\n",
      "\tEpoch: 37\n",
      "\tTraining Loss: 0.7587; Training Accuracy: 86.86%\n",
      "\tTesting Loss: 0.4965; Testing Accuracy: 83.52%\n",
      "\n",
      "\tEpoch: 38\n",
      "\tTraining Loss: 0.764; Training Accuracy: 86.838%\n",
      "\tTesting Loss: 0.4437; Testing Accuracy: 85.05%\n",
      "\n",
      "\tEpoch: 39\n",
      "\tTraining Loss: 0.7484; Training Accuracy: 87.164%\n",
      "\tTesting Loss: 0.413; Testing Accuracy: 85.91%\n",
      "\n",
      "\tEpoch: 40\n",
      "\tTraining Loss: 0.7581; Training Accuracy: 87.122%\n",
      "\tTesting Loss: 0.4419; Testing Accuracy: 85.68%\n",
      "\n",
      "\tEpoch: 41\n",
      "\tTraining Loss: 0.74; Training Accuracy: 87.262%\n",
      "\tTesting Loss: 0.492; Testing Accuracy: 84.06%\n",
      "\n",
      "\tEpoch: 42\n",
      "\tTraining Loss: 0.7457; Training Accuracy: 87.188%\n",
      "\tTesting Loss: 0.4761; Testing Accuracy: 84.97%\n",
      "\n",
      "\tEpoch: 43\n",
      "\tTraining Loss: 0.75; Training Accuracy: 87.206%\n",
      "\tTesting Loss: 0.381; Testing Accuracy: 87.37%\n",
      "\n",
      "\tEpoch: 44\n",
      "\tTraining Loss: 0.745; Training Accuracy: 87.222%\n",
      "\tTesting Loss: 0.3718; Testing Accuracy: 87.31%\n",
      "\n",
      "\tEpoch: 45\n",
      "\tTraining Loss: 0.734; Training Accuracy: 87.36%\n",
      "\tTesting Loss: 0.4609; Testing Accuracy: 85.55%\n",
      "\n",
      "\tEpoch: 46\n",
      "\tTraining Loss: 0.7327; Training Accuracy: 87.502%\n",
      "\tTesting Loss: 0.4543; Testing Accuracy: 85.25%\n",
      "\n",
      "\tEpoch: 47\n",
      "\tTraining Loss: 0.7358; Training Accuracy: 87.418%\n",
      "\tTesting Loss: 0.6084; Testing Accuracy: 81.66%\n",
      "\n",
      "\tEpoch: 48\n",
      "\tTraining Loss: 0.7396; Training Accuracy: 87.302%\n",
      "\tTesting Loss: 0.4919; Testing Accuracy: 84.22%\n",
      "\n",
      "\tEpoch: 49\n",
      "\tTraining Loss: 0.7364; Training Accuracy: 87.34%\n",
      "\tTesting Loss: 0.4653; Testing Accuracy: 84.78%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.1, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=2)\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = batch_size)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = batch_size)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c8708-7ad4-45cc-8189-2283828cb4af",
   "metadata": {},
   "source": [
    "### 64-Batch Best Model Test : 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e7faaeb5-f5fe-4d0c-a3b0-1f9878b88c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.9136; Training Accuracy: 46.844%\n",
      "\tTesting Loss: 1.4071; Testing Accuracy: 54.03%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.2236; Training Accuracy: 59.944%\n",
      "\tTesting Loss: 1.1614; Testing Accuracy: 60.14%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.9215; Training Accuracy: 65.992%\n",
      "\tTesting Loss: 1.0184; Testing Accuracy: 65.37%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.7158; Training Accuracy: 69.748%\n",
      "\tTesting Loss: 0.7368; Testing Accuracy: 75.07%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.5727; Training Accuracy: 72.308%\n",
      "\tTesting Loss: 0.6939; Testing Accuracy: 76.44%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 1.4431; Training Accuracy: 74.894%\n",
      "\tTesting Loss: 0.6965; Testing Accuracy: 76.58%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 1.3471; Training Accuracy: 76.314%\n",
      "\tTesting Loss: 0.6145; Testing Accuracy: 79.31%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 1.2848; Training Accuracy: 77.416%\n",
      "\tTesting Loss: 0.6696; Testing Accuracy: 78.26%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 1.2057; Training Accuracy: 78.904%\n",
      "\tTesting Loss: 0.5651; Testing Accuracy: 80.66%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 1.1395; Training Accuracy: 80.1%\n",
      "\tTesting Loss: 0.5474; Testing Accuracy: 81.87%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 1.0993; Training Accuracy: 80.776%\n",
      "\tTesting Loss: 0.5144; Testing Accuracy: 83.1%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 1.0583; Training Accuracy: 81.754%\n",
      "\tTesting Loss: 0.5355; Testing Accuracy: 82.2%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 1.012; Training Accuracy: 82.102%\n",
      "\tTesting Loss: 0.4436; Testing Accuracy: 85.3%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.9836; Training Accuracy: 82.884%\n",
      "\tTesting Loss: 0.643; Testing Accuracy: 80.22%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.9364; Training Accuracy: 83.628%\n",
      "\tTesting Loss: 0.4981; Testing Accuracy: 83.78%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.9111; Training Accuracy: 84.112%\n",
      "\tTesting Loss: 0.491; Testing Accuracy: 84.44%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.8895; Training Accuracy: 84.62%\n",
      "\tTesting Loss: 0.4396; Testing Accuracy: 85.45%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.8582; Training Accuracy: 84.99%\n",
      "\tTesting Loss: 0.4314; Testing Accuracy: 85.65%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.8346; Training Accuracy: 85.434%\n",
      "\tTesting Loss: 0.4046; Testing Accuracy: 86.63%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.8122; Training Accuracy: 85.66%\n",
      "\tTesting Loss: 0.4475; Testing Accuracy: 85.3%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.8009; Training Accuracy: 86.156%\n",
      "\tTesting Loss: 0.4081; Testing Accuracy: 86.83%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.7623; Training Accuracy: 86.714%\n",
      "\tTesting Loss: 0.4435; Testing Accuracy: 85.28%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.7508; Training Accuracy: 86.88%\n",
      "\tTesting Loss: 0.4555; Testing Accuracy: 85.78%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.7362; Training Accuracy: 87.156%\n",
      "\tTesting Loss: 0.4287; Testing Accuracy: 86.0%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.7196; Training Accuracy: 87.33%\n",
      "\tTesting Loss: 0.4265; Testing Accuracy: 85.68%\n",
      "\n",
      "\tEpoch: 25\n",
      "\tTraining Loss: 0.7011; Training Accuracy: 87.696%\n",
      "\tTesting Loss: 0.4376; Testing Accuracy: 86.38%\n",
      "\n",
      "\tEpoch: 26\n",
      "\tTraining Loss: 0.6896; Training Accuracy: 88.106%\n",
      "\tTesting Loss: 0.3613; Testing Accuracy: 88.05%\n",
      "\n",
      "\tEpoch: 27\n",
      "\tTraining Loss: 0.676; Training Accuracy: 88.164%\n",
      "\tTesting Loss: 0.3993; Testing Accuracy: 87.18%\n",
      "\n",
      "\tEpoch: 28\n",
      "\tTraining Loss: 0.6684; Training Accuracy: 88.372%\n",
      "\tTesting Loss: 0.3558; Testing Accuracy: 88.36%\n",
      "\n",
      "\tEpoch: 29\n",
      "\tTraining Loss: 0.6537; Training Accuracy: 88.548%\n",
      "\tTesting Loss: 0.3713; Testing Accuracy: 88.09%\n",
      "\n",
      "\tEpoch: 30\n",
      "\tTraining Loss: 0.6512; Training Accuracy: 88.584%\n",
      "\tTesting Loss: 0.4202; Testing Accuracy: 86.57%\n",
      "\n",
      "\tEpoch: 31\n",
      "\tTraining Loss: 0.6402; Training Accuracy: 88.784%\n",
      "\tTesting Loss: 0.3489; Testing Accuracy: 88.64%\n",
      "\n",
      "\tEpoch: 32\n",
      "\tTraining Loss: 0.63; Training Accuracy: 88.916%\n",
      "\tTesting Loss: 0.3871; Testing Accuracy: 88.06%\n",
      "\n",
      "\tEpoch: 33\n",
      "\tTraining Loss: 0.6247; Training Accuracy: 89.072%\n",
      "\tTesting Loss: 0.3959; Testing Accuracy: 87.21%\n",
      "\n",
      "\tEpoch: 34\n",
      "\tTraining Loss: 0.6188; Training Accuracy: 88.968%\n",
      "\tTesting Loss: 0.3355; Testing Accuracy: 89.4%\n",
      "\n",
      "\tEpoch: 35\n",
      "\tTraining Loss: 0.6179; Training Accuracy: 89.14%\n",
      "\tTesting Loss: 0.4116; Testing Accuracy: 87.37%\n",
      "\n",
      "\tEpoch: 36\n",
      "\tTraining Loss: 0.6094; Training Accuracy: 89.194%\n",
      "\tTesting Loss: 0.3692; Testing Accuracy: 88.63%\n",
      "\n",
      "\tEpoch: 37\n",
      "\tTraining Loss: 0.5972; Training Accuracy: 89.592%\n",
      "\tTesting Loss: 0.348; Testing Accuracy: 89.1%\n",
      "\n",
      "\tEpoch: 38\n",
      "\tTraining Loss: 0.6002; Training Accuracy: 89.578%\n",
      "\tTesting Loss: 0.375; Testing Accuracy: 88.15%\n",
      "\n",
      "\tEpoch: 39\n",
      "\tTraining Loss: 0.5839; Training Accuracy: 89.826%\n",
      "\tTesting Loss: 0.3722; Testing Accuracy: 88.37%\n",
      "\n",
      "\tEpoch: 40\n",
      "\tTraining Loss: 0.5863; Training Accuracy: 89.924%\n",
      "\tTesting Loss: 0.3423; Testing Accuracy: 89.0%\n",
      "\n",
      "\tEpoch: 41\n",
      "\tTraining Loss: 0.5686; Training Accuracy: 90.174%\n",
      "\tTesting Loss: 0.4151; Testing Accuracy: 87.0%\n",
      "\n",
      "\tEpoch: 42\n",
      "\tTraining Loss: 0.5725; Training Accuracy: 89.976%\n",
      "\tTesting Loss: 0.3956; Testing Accuracy: 87.51%\n",
      "\n",
      "\tEpoch: 43\n",
      "\tTraining Loss: 0.5636; Training Accuracy: 90.07%\n",
      "\tTesting Loss: 0.3648; Testing Accuracy: 88.44%\n",
      "\n",
      "\tEpoch: 44\n",
      "\tTraining Loss: 0.5639; Training Accuracy: 90.15%\n",
      "\tTesting Loss: 0.3579; Testing Accuracy: 88.63%\n",
      "\n",
      "\tEpoch: 45\n",
      "\tTraining Loss: 0.559; Training Accuracy: 90.244%\n",
      "\tTesting Loss: 0.4075; Testing Accuracy: 87.52%\n",
      "\n",
      "\tEpoch: 46\n",
      "\tTraining Loss: 0.5514; Training Accuracy: 90.378%\n",
      "\tTesting Loss: 0.3677; Testing Accuracy: 88.54%\n",
      "\n",
      "\tEpoch: 47\n",
      "\tTraining Loss: 0.5561; Training Accuracy: 90.246%\n",
      "\tTesting Loss: 0.4218; Testing Accuracy: 86.66%\n",
      "\n",
      "\tEpoch: 48\n",
      "\tTraining Loss: 0.5522; Training Accuracy: 90.482%\n",
      "\tTesting Loss: 0.3635; Testing Accuracy: 88.53%\n",
      "\n",
      "\tEpoch: 49\n",
      "\tTraining Loss: 0.5411; Training Accuracy: 90.718%\n",
      "\tTesting Loss: 0.4039; Testing Accuracy: 87.58%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, verbose = True)\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = batch_size)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = batch_size)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c25cc04-82e9-44d3-8673-84164faa593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(model, criterion, optimizer, train_loader, val_loader, device, scheduler = None, use_scheduler = False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        cur_correct = (pred == label).sum().item()\n",
    "        cur_loss = loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        train_loss += cur_loss\n",
    "\n",
    "    train_accuracy = correct/total\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "                \n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        cur_correct = (pred == label).sum().item()\n",
    "        cur_loss = loss.item()\n",
    "            \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        valid_loss += cur_loss\n",
    "\n",
    "    valid_accuracy = correct/total\n",
    "    valid_loss = valid_loss/len(val_loader)\n",
    "    \n",
    "    if use_scheduler:\n",
    "        scheduler.step(valid_accuracy)\n",
    "\n",
    "    return train_loss, train_accuracy, valid_loss, valid_accuracy\n",
    "\n",
    "def test(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "                \n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        cur_correct = (pred == label).sum().item()\n",
    "        cur_loss = loss.item()\n",
    "            \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        test_loss += cur_loss\n",
    "\n",
    "    accuracy = correct/total\n",
    "    test_loss = test_loss/len(dataloader)\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf5a1117-17e8-45f2-ad32-c12125232d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4995754\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.3507; Training Accuracy: 38.165%\n",
      "\tValidation Loss: 1.4942; Validation Accuracy: 45.93%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.5894; Training Accuracy: 53.0275%\n",
      "\tValidation Loss: 1.1336; Validation Accuracy: 59.2%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.1222; Training Accuracy: 62.2975%\n",
      "\tValidation Loss: 1.1009; Validation Accuracy: 61.96%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.8115; Training Accuracy: 68.4075%\n",
      "\tValidation Loss: 0.917; Validation Accuracy: 67.44%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.6177; Training Accuracy: 71.5925%\n",
      "\tValidation Loss: 0.8766; Validation Accuracy: 69.67%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 1.4715; Training Accuracy: 74.395%\n",
      "\tValidation Loss: 0.7432; Validation Accuracy: 74.06%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 1.3528; Training Accuracy: 76.4025%\n",
      "\tValidation Loss: 0.7266; Validation Accuracy: 74.87%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 1.2559; Training Accuracy: 78.1475%\n",
      "\tValidation Loss: 0.6883; Validation Accuracy: 75.63%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 1.1633; Training Accuracy: 79.8525%\n",
      "\tValidation Loss: 0.6355; Validation Accuracy: 78.24%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 1.1093; Training Accuracy: 80.795%\n",
      "\tValidation Loss: 0.6797; Validation Accuracy: 76.05%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 1.0452; Training Accuracy: 81.805%\n",
      "\tValidation Loss: 0.6893; Validation Accuracy: 76.27%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 0.9895; Training Accuracy: 83.0125%\n",
      "\tValidation Loss: 0.626; Validation Accuracy: 78.31%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 0.9479; Training Accuracy: 83.615%\n",
      "\tValidation Loss: 0.6099; Validation Accuracy: 78.88%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.9159; Training Accuracy: 84.07%\n",
      "\tValidation Loss: 0.581; Validation Accuracy: 80.38%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.8692; Training Accuracy: 85.035%\n",
      "\tValidation Loss: 0.5501; Validation Accuracy: 81.12%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.837; Training Accuracy: 85.4875%\n",
      "\tValidation Loss: 0.5047; Validation Accuracy: 82.67%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.7903; Training Accuracy: 86.2375%\n",
      "\tValidation Loss: 0.5265; Validation Accuracy: 82.43%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.7726; Training Accuracy: 86.5125%\n",
      "\tValidation Loss: 0.5697; Validation Accuracy: 81.1%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.7502; Training Accuracy: 86.9825%\n",
      "\tValidation Loss: 0.6011; Validation Accuracy: 80.27%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.712; Training Accuracy: 87.5525%\n",
      "\tValidation Loss: 0.5404; Validation Accuracy: 81.52%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.6909; Training Accuracy: 88.28%\n",
      "\tValidation Loss: 0.5141; Validation Accuracy: 82.13%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.6689; Training Accuracy: 88.25%\n",
      "\tValidation Loss: 0.4911; Validation Accuracy: 83.65%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.6407; Training Accuracy: 88.7275%\n",
      "\tValidation Loss: 0.511; Validation Accuracy: 82.81%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.6217; Training Accuracy: 89.1325%\n",
      "\tValidation Loss: 0.5438; Validation Accuracy: 82.04%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.6101; Training Accuracy: 89.38%\n",
      "\tValidation Loss: 0.5482; Validation Accuracy: 81.88%\n",
      "\n",
      "\tTesting Loss: 0.4985; Testing Accuracy: 84.43%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "\n",
    "# Split the train data into train and validation sets\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "val_loader   = torch.utils.data.DataLoader(valset, batch_size = batch_size, shuffle = True)\n",
    "test_loader  = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [13, 9, 3, 1])\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'max', factor=0.1, verbose = True)\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "valid_losses_ = []\n",
    "valid_accuracies_ = []\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy, val_loss, val_accuracy = train_val(model, criterion, optimizer, \n",
    "                                                                   train_loader, val_loader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    valid_losses_.append(val_loss)\n",
    "    valid_accuracies_.append(val_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    print(f\"\\tValidation Loss: {round(val_loss, 4)}; Validation Accuracy: {round(val_accuracy*100, 4)}%\")\n",
    "    \n",
    "test_loss, test_accuracy = test(model, criterion, test_loader, device)\n",
    "print(f\"\\n\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a1d6af-dc81-42e2-a23e-4c56bb92f1f6",
   "metadata": {},
   "source": [
    "### 128-Batch Best Model Test : 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52ec5c10-13bf-43fa-98a2-aa048e7d9408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4995754\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.5703; Training Accuracy: 33.6025%\n",
      "\tValidation Loss: 1.5959; Validation Accuracy: 41.63%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.9106; Training Accuracy: 47.065%\n",
      "\tValidation Loss: 1.4449; Validation Accuracy: 47.88%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.5629; Training Accuracy: 53.7725%\n",
      "\tValidation Loss: 1.5744; Validation Accuracy: 46.37%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 2.3204; Training Accuracy: 58.505%\n",
      "\tValidation Loss: 1.2219; Validation Accuracy: 56.48%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 2.1304; Training Accuracy: 62.11%\n",
      "\tValidation Loss: 1.1345; Validation Accuracy: 60.74%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 1.9824; Training Accuracy: 64.895%\n",
      "\tValidation Loss: 1.0045; Validation Accuracy: 64.68%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 1.8727; Training Accuracy: 66.8975%\n",
      "\tValidation Loss: 0.9952; Validation Accuracy: 64.2%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 1.7666; Training Accuracy: 69.0125%\n",
      "\tValidation Loss: 0.9745; Validation Accuracy: 65.92%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 1.6857; Training Accuracy: 70.4975%\n",
      "\tValidation Loss: 0.9444; Validation Accuracy: 66.76%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 1.6119; Training Accuracy: 71.88%\n",
      "\tValidation Loss: 0.9294; Validation Accuracy: 68.07%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 1.5418; Training Accuracy: 72.9625%\n",
      "\tValidation Loss: 0.932; Validation Accuracy: 68.85%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 1.4944; Training Accuracy: 73.8325%\n",
      "\tValidation Loss: 0.8644; Validation Accuracy: 69.63%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 1.445; Training Accuracy: 74.895%\n",
      "\tValidation Loss: 0.9236; Validation Accuracy: 69.13%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 1.4026; Training Accuracy: 75.6025%\n",
      "\tValidation Loss: 0.7796; Validation Accuracy: 73.04%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 1.3634; Training Accuracy: 76.1325%\n",
      "\tValidation Loss: 0.8371; Validation Accuracy: 71.45%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 1.3255; Training Accuracy: 77.025%\n",
      "\tValidation Loss: 0.7543; Validation Accuracy: 73.88%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 1.2914; Training Accuracy: 77.475%\n",
      "\tValidation Loss: 0.7873; Validation Accuracy: 73.22%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 1.2641; Training Accuracy: 78.13%\n",
      "\tValidation Loss: 0.7607; Validation Accuracy: 73.79%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 1.2309; Training Accuracy: 78.5725%\n",
      "\tValidation Loss: 0.732; Validation Accuracy: 74.61%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 1.1975; Training Accuracy: 78.9725%\n",
      "\tValidation Loss: 0.7367; Validation Accuracy: 74.85%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 1.1731; Training Accuracy: 79.5875%\n",
      "\tValidation Loss: 0.7339; Validation Accuracy: 74.74%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 1.1455; Training Accuracy: 79.895%\n",
      "\tValidation Loss: 0.7587; Validation Accuracy: 74.57%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 1.1182; Training Accuracy: 80.605%\n",
      "\tValidation Loss: 0.6651; Validation Accuracy: 77.12%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 1.1077; Training Accuracy: 80.8175%\n",
      "\tValidation Loss: 0.6722; Validation Accuracy: 77.21%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 1.0841; Training Accuracy: 80.9525%\n",
      "\tValidation Loss: 0.6884; Validation Accuracy: 76.66%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "    torchvision.transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "\n",
    "# Split the train data into train and validation sets\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "val_loader   = torch.utils.data.DataLoader(valset, batch_size = batch_size, shuffle = True)\n",
    "test_loader  = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [13, 9, 3, 1])\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'max', factor=0.1, verbose = True)\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "valid_losses_ = []\n",
    "valid_accuracies_ = []\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy, val_loss, val_accuracy = train_val(model, criterion, optimizer, \n",
    "                                                                   train_loader, val_loader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    valid_losses_.append(val_loss)\n",
    "    valid_accuracies_.append(val_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    print(f\"\\tValidation Loss: {round(val_loss, 4)}; Validation Accuracy: {round(val_accuracy*100, 4)}%\")\n",
    "    \n",
    "test_loss, test_accuracy = test(model, criterion, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c0eccda-bed3-4497-8377-0e995951fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4995754\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.5145; Training Accuracy: 35.37%\n",
      "\tValidation Loss: 1.5966; Validation Accuracy: 41.17%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.7155; Training Accuracy: 50.79%\n",
      "\tValidation Loss: 1.1834; Validation Accuracy: 57.79%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.1133; Training Accuracy: 62.64%\n",
      "\tValidation Loss: 0.9748; Validation Accuracy: 65.5%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.7739; Training Accuracy: 69.0225%\n",
      "\tValidation Loss: 0.8479; Validation Accuracy: 70.14%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.5581; Training Accuracy: 73.15%\n",
      "\tValidation Loss: 0.7715; Validation Accuracy: 73.13%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 1.4186; Training Accuracy: 75.465%\n",
      "\tValidation Loss: 0.7456; Validation Accuracy: 74.53%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 1.3079; Training Accuracy: 77.5175%\n",
      "\tValidation Loss: 0.6303; Validation Accuracy: 78.1%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 1.2202; Training Accuracy: 78.8425%\n",
      "\tValidation Loss: 0.6088; Validation Accuracy: 78.61%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 1.1566; Training Accuracy: 79.96%\n",
      "\tValidation Loss: 0.6016; Validation Accuracy: 79.44%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 1.0883; Training Accuracy: 81.2725%\n",
      "\tValidation Loss: 0.567; Validation Accuracy: 79.91%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 1.044; Training Accuracy: 81.8875%\n",
      "\tValidation Loss: 0.6027; Validation Accuracy: 79.45%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 1.0023; Training Accuracy: 82.7275%\n",
      "\tValidation Loss: 0.5513; Validation Accuracy: 81.38%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 0.9535; Training Accuracy: 83.6725%\n",
      "\tValidation Loss: 0.4979; Validation Accuracy: 82.86%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.9281; Training Accuracy: 83.9775%\n",
      "\tValidation Loss: 0.5242; Validation Accuracy: 81.59%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.8822; Training Accuracy: 84.7075%\n",
      "\tValidation Loss: 0.4685; Validation Accuracy: 84.32%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.8692; Training Accuracy: 85.06%\n",
      "\tValidation Loss: 0.5293; Validation Accuracy: 81.88%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.8398; Training Accuracy: 85.655%\n",
      "\tValidation Loss: 0.5343; Validation Accuracy: 82.1%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.8253; Training Accuracy: 85.7225%\n",
      "\tValidation Loss: 0.4884; Validation Accuracy: 83.7%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.803; Training Accuracy: 86.1125%\n",
      "\tValidation Loss: 0.5; Validation Accuracy: 83.47%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.7859; Training Accuracy: 86.4975%\n",
      "\tValidation Loss: 0.4393; Validation Accuracy: 84.91%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.7764; Training Accuracy: 86.4875%\n",
      "\tValidation Loss: 0.4663; Validation Accuracy: 83.89%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.7546; Training Accuracy: 86.91%\n",
      "\tValidation Loss: 0.4395; Validation Accuracy: 84.95%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.7396; Training Accuracy: 87.3%\n",
      "\tValidation Loss: 0.4572; Validation Accuracy: 84.51%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.7385; Training Accuracy: 87.34%\n",
      "\tValidation Loss: 0.4281; Validation Accuracy: 85.63%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.712; Training Accuracy: 87.7%\n",
      "\tValidation Loss: 0.4271; Validation Accuracy: 85.8%\n",
      "\n",
      "\tTesting Loss: 0.4234; Testing Accuracy: 86.12%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "\n",
    "# Split the train data into train and validation sets\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "val_loader   = torch.utils.data.DataLoader(valset, batch_size = batch_size, shuffle = True)\n",
    "test_loader  = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [13, 9, 3, 1])\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'max', factor=0.1, verbose = True)\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "valid_losses_ = []\n",
    "valid_accuracies_ = []\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy, val_loss, val_accuracy = train_val(model, criterion, optimizer, \n",
    "                                                                   train_loader, val_loader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    valid_losses_.append(val_loss)\n",
    "    valid_accuracies_.append(val_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    print(f\"\\tValidation Loss: {round(val_loss, 4)}; Validation Accuracy: {round(val_accuracy*100, 4)}%\")\n",
    "    \n",
    "test_loss, test_accuracy = test(model, criterion, test_loader, device)\n",
    "print(f\"\\n\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3390e2-85f8-4d39-abfc-006a1ea1d430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2374b609-6010-4a6c-846c-7cbb9ac13bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4903242\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.4431; Training Accuracy: 36.506%\n",
      "\tTesting Loss: 1.3897; Testing Accuracy: 49.3%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.8815; Training Accuracy: 48.006%\n",
      "\tTesting Loss: 1.1536; Testing Accuracy: 58.68%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.5818; Training Accuracy: 53.81%\n",
      "\tTesting Loss: 1.0249; Testing Accuracy: 63.46%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 2.3971; Training Accuracy: 57.468%\n",
      "\tTesting Loss: 1.0749; Testing Accuracy: 63.07%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 2.2375; Training Accuracy: 60.842%\n",
      "\tTesting Loss: 1.0195; Testing Accuracy: 65.91%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "    torchvision.transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.25), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9fa4a-8b7a-4a6f-b383-21d6a935b361",
   "metadata": {},
   "source": [
    "### Experiment 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "889be415-8b82-49e0-bda0-04759a3a2845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.0695; Training Accuracy: 44.138%\n",
      "\tTesting Loss: 1.1521; Testing Accuracy: 59.37%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.0188; Training Accuracy: 64.102%\n",
      "\tTesting Loss: 0.8863; Testing Accuracy: 69.66%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.5569; Training Accuracy: 72.766%\n",
      "\tTesting Loss: 0.7497; Testing Accuracy: 74.66%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.2934; Training Accuracy: 77.598%\n",
      "\tTesting Loss: 0.7004; Testing Accuracy: 76.84%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.1314; Training Accuracy: 80.576%\n",
      "\tTesting Loss: 0.6563; Testing Accuracy: 77.86%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c701e-8aca-48b4-84ee-966c68442aff",
   "metadata": {},
   "source": [
    "### Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b990446-fe66-4696-ae02-70ba6181ed1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 4.0831; Training Accuracy: 25.416%\n",
      "\tTesting Loss: 1.7573; Testing Accuracy: 36.93%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 3.0747; Training Accuracy: 43.314%\n",
      "\tTesting Loss: 1.3138; Testing Accuracy: 53.16%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.3891; Training Accuracy: 57.44%\n",
      "\tTesting Loss: 0.9893; Testing Accuracy: 64.71%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.8712; Training Accuracy: 67.124%\n",
      "\tTesting Loss: 0.9075; Testing Accuracy: 69.66%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.5071; Training Accuracy: 73.58%\n",
      "\tTesting Loss: 0.7263; Testing Accuracy: 75.88%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83c400-966f-45a4-b4cf-5a17b02ed4e7",
   "metadata": {},
   "source": [
    "### Experiment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6da323a-d29d-4ed8-b553-cc7eebe676ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.8098; Training Accuracy: 48.56%\n",
      "\tTesting Loss: 1.0293; Testing Accuracy: 62.74%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.8649; Training Accuracy: 66.91%\n",
      "\tTesting Loss: 0.8283; Testing Accuracy: 71.45%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.464; Training Accuracy: 74.628%\n",
      "\tTesting Loss: 0.6756; Testing Accuracy: 76.84%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.2396; Training Accuracy: 78.24%\n",
      "\tTesting Loss: 0.5828; Testing Accuracy: 79.73%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.092; Training Accuracy: 81.114%\n",
      "\tTesting Loss: 0.5457; Testing Accuracy: 81.31%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bdeda9-4598-4eb3-9c09-7c8c276dc5bc",
   "metadata": {},
   "source": [
    "### Experiment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef165f5d-560e-4aab-ae81-6e9aae035b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.9954; Training Accuracy: 45.102%\n",
      "\tTesting Loss: 1.2489; Testing Accuracy: 56.77%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.0779; Training Accuracy: 63.1%\n",
      "\tTesting Loss: 1.0681; Testing Accuracy: 64.61%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.6596; Training Accuracy: 71.018%\n",
      "\tTesting Loss: 0.8558; Testing Accuracy: 71.83%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.4053; Training Accuracy: 75.928%\n",
      "\tTesting Loss: 0.7706; Testing Accuracy: 74.29%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.2425; Training Accuracy: 78.668%\n",
      "\tTesting Loss: 0.6392; Testing Accuracy: 78.47%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef31a2-3b2a-4cb4-bb0d-7793110b5477",
   "metadata": {},
   "source": [
    "### Experiment 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "086e8ed6-f78e-4257-a669-d4da0f685213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.6369; Training Accuracy: 52.344%\n",
      "\tTesting Loss: 1.0153; Testing Accuracy: 63.82%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.8463; Training Accuracy: 67.354%\n",
      "\tTesting Loss: 0.8102; Testing Accuracy: 71.3%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.5579; Training Accuracy: 72.572%\n",
      "\tTesting Loss: 0.7208; Testing Accuracy: 75.06%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.3769; Training Accuracy: 75.914%\n",
      "\tTesting Loss: 0.6677; Testing Accuracy: 76.91%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.249; Training Accuracy: 78.262%\n",
      "\tTesting Loss: 0.6503; Testing Accuracy: 77.46%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bae423-3400-4a86-ab80-db63190d75a5",
   "metadata": {},
   "source": [
    "### Experiment 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "119b4778-c1c1-4491-b172-360e42fe93f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.9072; Training Accuracy: 27.728%\n",
      "\tTesting Loss: 1.6921; Testing Accuracy: 37.86%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 3.3217; Training Accuracy: 39.254%\n",
      "\tTesting Loss: 1.5291; Testing Accuracy: 43.78%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 3.0834; Training Accuracy: 43.614%\n",
      "\tTesting Loss: 1.4312; Testing Accuracy: 46.77%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 2.9362; Training Accuracy: 46.198%\n",
      "\tTesting Loss: 1.3586; Testing Accuracy: 49.49%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 2.8134; Training Accuracy: 48.944%\n",
      "\tTesting Loss: 1.3126; Testing Accuracy: 52.6%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec152e7-6638-4daf-8720-84e6b0e7abff",
   "metadata": {},
   "source": [
    "### Experiment 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "732409f5-8d94-4394-848d-ead6ccba29f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.9782; Training Accuracy: 45.238%\n",
      "\tTesting Loss: 1.2115; Testing Accuracy: 55.69%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.0646; Training Accuracy: 63.354%\n",
      "\tTesting Loss: 0.907; Testing Accuracy: 68.15%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.6231; Training Accuracy: 71.274%\n",
      "\tTesting Loss: 0.7754; Testing Accuracy: 73.4%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.3706; Training Accuracy: 75.896%\n",
      "\tTesting Loss: 0.6829; Testing Accuracy: 76.34%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.2008; Training Accuracy: 79.018%\n",
      "\tTesting Loss: 0.6093; Testing Accuracy: 79.54%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = 64)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = 64)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356331e7-8b88-4167-8564-fd4be53e0661",
   "metadata": {},
   "source": [
    "### Experiment 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c80c505c-6b11-4fa7-a9aa-0529fe20320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.9506; Training Accuracy: 45.832%\n",
      "\tTesting Loss: 1.1447; Testing Accuracy: 59.1%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.0538; Training Accuracy: 63.166%\n",
      "\tTesting Loss: 0.9469; Testing Accuracy: 66.62%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.6601; Training Accuracy: 70.54%\n",
      "\tTesting Loss: 0.7957; Testing Accuracy: 72.57%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.4186; Training Accuracy: 75.384%\n",
      "\tTesting Loss: 0.7268; Testing Accuracy: 74.97%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.2425; Training Accuracy: 78.384%\n",
      "\tTesting Loss: 0.6675; Testing Accuracy: 77.2%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 1.111; Training Accuracy: 80.596%\n",
      "\tTesting Loss: 0.5735; Testing Accuracy: 80.82%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 1.0006; Training Accuracy: 82.746%\n",
      "\tTesting Loss: 0.6144; Testing Accuracy: 79.93%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 0.9319; Training Accuracy: 83.926%\n",
      "\tTesting Loss: 0.5296; Testing Accuracy: 81.96%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 0.8593; Training Accuracy: 85.192%\n",
      "\tTesting Loss: 0.5024; Testing Accuracy: 83.04%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 0.809; Training Accuracy: 85.878%\n",
      "\tTesting Loss: 0.6002; Testing Accuracy: 80.15%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 0.741; Training Accuracy: 87.13%\n",
      "\tTesting Loss: 0.4872; Testing Accuracy: 83.81%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 0.704; Training Accuracy: 87.76%\n",
      "\tTesting Loss: 0.4396; Testing Accuracy: 85.2%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 0.6544; Training Accuracy: 88.804%\n",
      "\tTesting Loss: 0.3988; Testing Accuracy: 86.62%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.624; Training Accuracy: 89.132%\n",
      "\tTesting Loss: 0.4385; Testing Accuracy: 85.58%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.5844; Training Accuracy: 89.768%\n",
      "\tTesting Loss: 0.4475; Testing Accuracy: 85.98%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.5531; Training Accuracy: 90.408%\n",
      "\tTesting Loss: 0.3946; Testing Accuracy: 87.51%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.5308; Training Accuracy: 90.732%\n",
      "\tTesting Loss: 0.403; Testing Accuracy: 86.99%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.4902; Training Accuracy: 91.398%\n",
      "\tTesting Loss: 0.3865; Testing Accuracy: 87.87%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.4692; Training Accuracy: 91.774%\n",
      "\tTesting Loss: 0.4647; Testing Accuracy: 85.87%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.449; Training Accuracy: 92.14%\n",
      "\tTesting Loss: 0.3835; Testing Accuracy: 87.67%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.4252; Training Accuracy: 92.602%\n",
      "\tTesting Loss: 0.3932; Testing Accuracy: 87.54%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.4047; Training Accuracy: 92.874%\n",
      "\tTesting Loss: 0.3755; Testing Accuracy: 88.54%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.3786; Training Accuracy: 93.294%\n",
      "\tTesting Loss: 0.399; Testing Accuracy: 87.69%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.3682; Training Accuracy: 93.602%\n",
      "\tTesting Loss: 0.4171; Testing Accuracy: 87.11%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.3407; Training Accuracy: 93.97%\n",
      "\tTesting Loss: 0.3717; Testing Accuracy: 88.92%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = 64)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = 64)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ca6d6-67b8-43f6-a9ba-a5eb8928aa27",
   "metadata": {},
   "source": [
    "### Experiment 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fe13ea5-6daf-49ba-9cb0-1e6eff35adb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.8182; Training Accuracy: 48.626%\n",
      "\tTesting Loss: 1.0154; Testing Accuracy: 63.65%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.8735; Training Accuracy: 66.82%\n",
      "\tTesting Loss: 0.8157; Testing Accuracy: 71.64%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.4811; Training Accuracy: 74.1%\n",
      "\tTesting Loss: 0.7774; Testing Accuracy: 73.24%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.2552; Training Accuracy: 78.01%\n",
      "\tTesting Loss: 0.6007; Testing Accuracy: 79.32%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.1042; Training Accuracy: 80.826%\n",
      "\tTesting Loss: 0.5966; Testing Accuracy: 79.53%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 0.9851; Training Accuracy: 83.006%\n",
      "\tTesting Loss: 0.5544; Testing Accuracy: 81.94%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 0.9019; Training Accuracy: 84.374%\n",
      "\tTesting Loss: 0.5175; Testing Accuracy: 82.48%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 0.8294; Training Accuracy: 85.738%\n",
      "\tTesting Loss: 0.4715; Testing Accuracy: 83.76%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 0.7653; Training Accuracy: 86.616%\n",
      "\tTesting Loss: 0.4452; Testing Accuracy: 85.08%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 0.7013; Training Accuracy: 87.972%\n",
      "\tTesting Loss: 0.4197; Testing Accuracy: 86.3%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 0.6603; Training Accuracy: 88.504%\n",
      "\tTesting Loss: 0.3642; Testing Accuracy: 87.78%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 0.6164; Training Accuracy: 89.414%\n",
      "\tTesting Loss: 0.4115; Testing Accuracy: 86.86%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 0.5732; Training Accuracy: 89.996%\n",
      "\tTesting Loss: 0.4109; Testing Accuracy: 86.56%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.5493; Training Accuracy: 90.394%\n",
      "\tTesting Loss: 0.3823; Testing Accuracy: 87.75%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.5113; Training Accuracy: 91.14%\n",
      "\tTesting Loss: 0.3706; Testing Accuracy: 87.72%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.4783; Training Accuracy: 91.626%\n",
      "\tTesting Loss: 0.3735; Testing Accuracy: 88.08%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.4623; Training Accuracy: 92.064%\n",
      "\tTesting Loss: 0.3797; Testing Accuracy: 88.21%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.428; Training Accuracy: 92.578%\n",
      "\tTesting Loss: 0.3373; Testing Accuracy: 89.15%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.4153; Training Accuracy: 92.682%\n",
      "\tTesting Loss: 0.344; Testing Accuracy: 88.95%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.3872; Training Accuracy: 93.282%\n",
      "\tTesting Loss: 0.3464; Testing Accuracy: 89.18%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.3657; Training Accuracy: 93.696%\n",
      "\tTesting Loss: 0.3411; Testing Accuracy: 89.37%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.3474; Training Accuracy: 93.986%\n",
      "\tTesting Loss: 0.335; Testing Accuracy: 89.77%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.3294; Training Accuracy: 94.12%\n",
      "\tTesting Loss: 0.3265; Testing Accuracy: 89.67%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.3162; Training Accuracy: 94.344%\n",
      "\tTesting Loss: 0.3371; Testing Accuracy: 89.78%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.3018; Training Accuracy: 94.704%\n",
      "\tTesting Loss: 0.3303; Testing Accuracy: 90.3%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = 32)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = 32)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dc3e0f-2a85-4238-9a24-e46d6d01edca",
   "metadata": {},
   "source": [
    "### Experiment 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb735e6b-202f-4175-b7fb-97f3277363bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.8845; Training Accuracy: 47.072%\n",
      "\tTesting Loss: 1.0529; Testing Accuracy: 62.12%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.9713; Training Accuracy: 64.99%\n",
      "\tTesting Loss: 0.875; Testing Accuracy: 69.99%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.5457; Training Accuracy: 72.974%\n",
      "\tTesting Loss: 0.6873; Testing Accuracy: 75.81%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.2962; Training Accuracy: 77.468%\n",
      "\tTesting Loss: 0.7704; Testing Accuracy: 75.19%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.1413; Training Accuracy: 80.47%\n",
      "\tTesting Loss: 0.5555; Testing Accuracy: 80.76%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 1.0165; Training Accuracy: 82.35%\n",
      "\tTesting Loss: 0.5385; Testing Accuracy: 81.41%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 0.9295; Training Accuracy: 83.906%\n",
      "\tTesting Loss: 0.4685; Testing Accuracy: 84.07%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 0.8357; Training Accuracy: 85.664%\n",
      "\tTesting Loss: 0.4521; Testing Accuracy: 84.77%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 0.7855; Training Accuracy: 86.434%\n",
      "\tTesting Loss: 0.4363; Testing Accuracy: 85.68%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 0.7169; Training Accuracy: 87.672%\n",
      "\tTesting Loss: 0.4286; Testing Accuracy: 86.1%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 0.6719; Training Accuracy: 88.38%\n",
      "\tTesting Loss: 0.4011; Testing Accuracy: 86.33%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 0.6391; Training Accuracy: 88.91%\n",
      "\tTesting Loss: 0.4183; Testing Accuracy: 86.44%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 0.5933; Training Accuracy: 89.65%\n",
      "\tTesting Loss: 0.4378; Testing Accuracy: 85.85%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.5512; Training Accuracy: 90.558%\n",
      "\tTesting Loss: 0.3737; Testing Accuracy: 87.52%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.5185; Training Accuracy: 91.024%\n",
      "\tTesting Loss: 0.3731; Testing Accuracy: 87.98%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.4884; Training Accuracy: 91.468%\n",
      "\tTesting Loss: 0.3525; Testing Accuracy: 89.02%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.4669; Training Accuracy: 91.912%\n",
      "\tTesting Loss: 0.3618; Testing Accuracy: 88.65%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.4373; Training Accuracy: 92.386%\n",
      "\tTesting Loss: 0.3687; Testing Accuracy: 88.4%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.4166; Training Accuracy: 92.704%\n",
      "\tTesting Loss: 0.3686; Testing Accuracy: 88.64%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.3903; Training Accuracy: 93.166%\n",
      "\tTesting Loss: 0.3439; Testing Accuracy: 89.35%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.3732; Training Accuracy: 93.478%\n",
      "\tTesting Loss: 0.3651; Testing Accuracy: 89.01%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.3541; Training Accuracy: 93.73%\n",
      "\tTesting Loss: 0.3708; Testing Accuracy: 88.88%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.3467; Training Accuracy: 93.914%\n",
      "\tTesting Loss: 0.3367; Testing Accuracy: 89.77%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.3213; Training Accuracy: 94.448%\n",
      "\tTesting Loss: 0.3591; Testing Accuracy: 89.19%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.3015; Training Accuracy: 94.732%\n",
      "\tTesting Loss: 0.3435; Testing Accuracy: 89.98%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = 32)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = 32)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1be17-ca06-43d8-9bfe-3214e5db7ae4",
   "metadata": {},
   "source": [
    "### Experiment 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5f3a08c-98aa-4892-bd84-3498df4c79e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.1043; Training Accuracy: 43.454%\n",
      "\tTesting Loss: 1.2535; Testing Accuracy: 55.07%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.9813; Training Accuracy: 64.834%\n",
      "\tTesting Loss: 0.885; Testing Accuracy: 69.36%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.5217; Training Accuracy: 73.414%\n",
      "\tTesting Loss: 0.8014; Testing Accuracy: 73.12%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.2719; Training Accuracy: 77.956%\n",
      "\tTesting Loss: 0.5813; Testing Accuracy: 80.06%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.1106; Training Accuracy: 80.854%\n",
      "\tTesting Loss: 0.5861; Testing Accuracy: 80.28%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 0.9904; Training Accuracy: 82.72%\n",
      "\tTesting Loss: 0.5355; Testing Accuracy: 81.97%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 0.8874; Training Accuracy: 84.78%\n",
      "\tTesting Loss: 0.5227; Testing Accuracy: 82.47%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 0.8065; Training Accuracy: 86.124%\n",
      "\tTesting Loss: 0.4773; Testing Accuracy: 84.06%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 0.7527; Training Accuracy: 86.884%\n",
      "\tTesting Loss: 0.3829; Testing Accuracy: 87.03%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 0.6943; Training Accuracy: 87.944%\n",
      "\tTesting Loss: 0.4191; Testing Accuracy: 85.99%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 0.6465; Training Accuracy: 88.884%\n",
      "\tTesting Loss: 0.3658; Testing Accuracy: 87.56%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 0.6031; Training Accuracy: 89.484%\n",
      "\tTesting Loss: 0.3554; Testing Accuracy: 88.26%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 0.5598; Training Accuracy: 90.336%\n",
      "\tTesting Loss: 0.3646; Testing Accuracy: 87.75%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.5309; Training Accuracy: 90.866%\n",
      "\tTesting Loss: 0.3531; Testing Accuracy: 88.61%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.4997; Training Accuracy: 91.304%\n",
      "\tTesting Loss: 0.313; Testing Accuracy: 89.68%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.4675; Training Accuracy: 91.958%\n",
      "\tTesting Loss: 0.3571; Testing Accuracy: 88.59%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.4468; Training Accuracy: 92.196%\n",
      "\tTesting Loss: 0.3519; Testing Accuracy: 88.59%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.412; Training Accuracy: 92.83%\n",
      "\tTesting Loss: 0.3676; Testing Accuracy: 88.44%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.3905; Training Accuracy: 93.192%\n",
      "\tTesting Loss: 0.3355; Testing Accuracy: 89.22%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.3765; Training Accuracy: 93.486%\n",
      "\tTesting Loss: 0.3222; Testing Accuracy: 89.79%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.3482; Training Accuracy: 93.884%\n",
      "\tTesting Loss: 0.34; Testing Accuracy: 89.02%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.3427; Training Accuracy: 94.088%\n",
      "\tTesting Loss: 0.3356; Testing Accuracy: 89.5%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.3219; Training Accuracy: 94.34%\n",
      "\tTesting Loss: 0.3576; Testing Accuracy: 89.3%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.3036; Training Accuracy: 94.606%\n",
      "\tTesting Loss: 0.2973; Testing Accuracy: 90.71%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.2929; Training Accuracy: 94.93%\n",
      "\tTesting Loss: 0.3206; Testing Accuracy: 90.26%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = 32)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = 32)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "180709f0-8e78-4528-8be9-a24ced83747f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed975bf1-5d1b-4e4a-b07e-953752f2d518",
   "metadata": {},
   "source": [
    "### Experiment 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "16383291-55b6-4f39-bea9-4a89b961708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.0979; Training Accuracy: 43.474%\n",
      "\tTesting Loss: 1.6336; Testing Accuracy: 48.3%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.9974; Training Accuracy: 64.442%\n",
      "\tTesting Loss: 0.7966; Testing Accuracy: 71.92%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.5179; Training Accuracy: 73.536%\n",
      "\tTesting Loss: 0.7326; Testing Accuracy: 75.39%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.2711; Training Accuracy: 78.002%\n",
      "\tTesting Loss: 0.6211; Testing Accuracy: 79.11%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.107; Training Accuracy: 80.898%\n",
      "\tTesting Loss: 0.519; Testing Accuracy: 82.51%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 0.9796; Training Accuracy: 83.05%\n",
      "\tTesting Loss: 0.5409; Testing Accuracy: 82.09%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 0.887; Training Accuracy: 84.758%\n",
      "\tTesting Loss: 0.4434; Testing Accuracy: 84.98%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 0.8071; Training Accuracy: 86.118%\n",
      "\tTesting Loss: 0.4536; Testing Accuracy: 85.52%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 0.7435; Training Accuracy: 87.158%\n",
      "\tTesting Loss: 0.4289; Testing Accuracy: 86.05%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 0.6903; Training Accuracy: 88.072%\n",
      "\tTesting Loss: 0.4372; Testing Accuracy: 85.73%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 0.6388; Training Accuracy: 89.06%\n",
      "\tTesting Loss: 0.3611; Testing Accuracy: 87.38%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 0.601; Training Accuracy: 89.56%\n",
      "\tTesting Loss: 0.4176; Testing Accuracy: 86.22%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 0.5585; Training Accuracy: 90.306%\n",
      "\tTesting Loss: 0.3443; Testing Accuracy: 88.71%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.529; Training Accuracy: 90.962%\n",
      "\tTesting Loss: 0.3906; Testing Accuracy: 87.55%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.495; Training Accuracy: 91.396%\n",
      "\tTesting Loss: 0.345; Testing Accuracy: 88.41%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.462; Training Accuracy: 91.898%\n",
      "\tTesting Loss: 0.355; Testing Accuracy: 88.42%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.4416; Training Accuracy: 92.27%\n",
      "\tTesting Loss: 0.319; Testing Accuracy: 89.79%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.4189; Training Accuracy: 92.766%\n",
      "\tTesting Loss: 0.3433; Testing Accuracy: 88.86%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.3949; Training Accuracy: 93.166%\n",
      "\tTesting Loss: 0.3122; Testing Accuracy: 89.89%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.3761; Training Accuracy: 93.364%\n",
      "\tTesting Loss: 0.3233; Testing Accuracy: 90.02%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.3535; Training Accuracy: 93.776%\n",
      "\tTesting Loss: 0.3365; Testing Accuracy: 89.41%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.3426; Training Accuracy: 93.984%\n",
      "\tTesting Loss: 0.3482; Testing Accuracy: 89.22%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.3201; Training Accuracy: 94.402%\n",
      "\tTesting Loss: 0.3239; Testing Accuracy: 90.06%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.3008; Training Accuracy: 94.806%\n",
      "\tTesting Loss: 0.3283; Testing Accuracy: 90.33%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.2935; Training Accuracy: 94.796%\n",
      "\tTesting Loss: 0.299; Testing Accuracy: 91.02%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = 32)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = 32)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3dbb40d-d25b-4e81-a048-fd37f2568d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11173962"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5e1dfb4-8954-47ab-97c5-a9b9aace8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a2105e-f5f2-4045-9096-3b9f207201f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
