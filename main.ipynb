{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5247ddf3-4e56-42d3-8112-54fb9e627965",
   "metadata": {},
   "source": [
    "### References:\n",
    "    https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=cifar\n",
    "    https://github.com/kuangliu/pytorch-cifar/blob/master/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1fa0cc9-4b2c-489b-8894-5cf425bdac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "de0c46db-3f2d-4c89-94e0-081441925e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "815eb49b-306d-4207-8242-834f24f88607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4903242"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [1, 1, 1, 1])\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c3ec7b57-8c70-4dbd-997e-cda708fede01",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_BATCH_SIZE_LIMIT = 512\n",
    "\n",
    "def train(model, criterion, optimizer, dataloader, device, scheduler = None, use_scheduler = False, batch_size = 32):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        if batch_size >= GPU_BATCH_SIZE_LIMIT:\n",
    "            if(count == 0):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                count = batch_size/32\n",
    "\n",
    "            output = model(image)\n",
    "\n",
    "            loss = criterion(output, label)*32/batch_size\n",
    "            loss.backward()\n",
    "            count = count - 1\n",
    "\n",
    "            pred = torch.max(output.data, 1)[1]\n",
    "            \n",
    "            cur_correct = (pred == label).sum().item()\n",
    "            cur_loss = loss.item()\n",
    "        \n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(image)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            pred = torch.max(output.data, 1)[1]\n",
    "            cur_correct = (pred == label).sum().item()\n",
    "            cur_loss = loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        train_loss += cur_loss\n",
    "\n",
    "        if use_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "    accuracy = correct/total\n",
    "    train_loss = train_loss/len(dataloader)\n",
    "\n",
    "    return train_loss, accuracy\n",
    "\n",
    "def test(model, criterion, dataloader, device, batch_size = 32):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "                \n",
    "        if batch_size >= GPU_BATCH_SIZE_LIMIT:\n",
    "            if(count == 0):\n",
    "                count = batch_size/32\n",
    "\n",
    "            output = model(image)\n",
    "\n",
    "            loss = criterion(output, label)*32/batch_size\n",
    "            count = count - 1\n",
    "\n",
    "            pred = torch.max(output.data, 1)[1]\n",
    "            \n",
    "            cur_correct = (pred == label).sum().item()\n",
    "            cur_loss = loss.item()\n",
    "        \n",
    "        else:\n",
    "            output = model(image)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            pred = torch.max(output.data, 1)[1]\n",
    "            cur_correct = (pred == label).sum().item()\n",
    "            cur_loss = loss.item()\n",
    "            \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        test_loss += cur_loss\n",
    "\n",
    "    accuracy = correct/total\n",
    "    test_loss = test_loss/len(dataloader)\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8dba1f3b-279e-4343-887c-83b99ac4170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d37bb1-65d6-450b-9a15-5116596818b8",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba2f7acc-6063-4a83-8c72-ef8994b8ca5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.5645; Training Accuracy: 53.516%\n",
      "\tTesting Loss: 0.9553; Testing Accuracy: 65.75%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.5774; Training Accuracy: 72.306%\n",
      "\tTesting Loss: 0.7048; Testing Accuracy: 75.13%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.1238; Training Accuracy: 80.514%\n",
      "\tTesting Loss: 0.6602; Testing Accuracy: 77.31%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 0.7937; Training Accuracy: 86.16%\n",
      "\tTesting Loss: 0.7947; Testing Accuracy: 75.13%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 0.5269; Training Accuracy: 91.118%\n",
      "\tTesting Loss: 0.7802; Testing Accuracy: 75.85%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0108be6-851d-44b3-a43d-d1de666a3a7c",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb550f5c-2075-4dbe-8456-ce27f5c57ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.8569; Training Accuracy: 47.698%\n",
      "\tTesting Loss: 1.2013; Testing Accuracy: 57.86%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.9058; Training Accuracy: 66.156%\n",
      "\tTesting Loss: 0.8083; Testing Accuracy: 71.94%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.5045; Training Accuracy: 73.854%\n",
      "\tTesting Loss: 0.7316; Testing Accuracy: 75.75%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.274; Training Accuracy: 77.948%\n",
      "\tTesting Loss: 0.5878; Testing Accuracy: 80.14%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.1059; Training Accuracy: 80.852%\n",
      "\tTesting Loss: 0.577; Testing Accuracy: 80.62%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b3922-c460-445c-8ee6-8686a61ab07b",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "889be415-8b82-49e0-bda0-04759a3a2845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.07; Training Accuracy: 43.998%\n",
      "\tTesting Loss: 1.2807; Testing Accuracy: 54.54%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.9856; Training Accuracy: 64.784%\n",
      "\tTesting Loss: 0.8322; Testing Accuracy: 71.09%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.5254; Training Accuracy: 73.45%\n",
      "\tTesting Loss: 0.6997; Testing Accuracy: 75.74%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.2786; Training Accuracy: 77.93%\n",
      "\tTesting Loss: 0.6192; Testing Accuracy: 79.22%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.1156; Training Accuracy: 80.71%\n",
      "\tTesting Loss: 0.5351; Testing Accuracy: 82.01%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c701e-8aca-48b4-84ee-966c68442aff",
   "metadata": {},
   "source": [
    "### Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef165f5d-560e-4aab-ae81-6e9aae035b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 4.0013; Training Accuracy: 27.402%\n",
      "\tTesting Loss: 1.6766; Testing Accuracy: 35.77%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 3.0418; Training Accuracy: 44.444%\n",
      "\tTesting Loss: 1.265; Testing Accuracy: 54.06%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.4568; Training Accuracy: 56.274%\n",
      "\tTesting Loss: 1.1245; Testing Accuracy: 61.08%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 2.0156; Training Accuracy: 64.484%\n",
      "\tTesting Loss: 0.9501; Testing Accuracy: 67.33%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.6487; Training Accuracy: 71.168%\n",
      "\tTesting Loss: 0.7452; Testing Accuracy: 73.77%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef31a2-3b2a-4cb4-bb0d-7793110b5477",
   "metadata": {},
   "source": [
    "### Experiment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "086e8ed6-f78e-4257-a669-d4da0f685213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.7236; Training Accuracy: 30.386%\n",
      "\tTesting Loss: 1.6455; Testing Accuracy: 39.45%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.8793; Training Accuracy: 46.78%\n",
      "\tTesting Loss: 1.3395; Testing Accuracy: 52.06%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.4247; Training Accuracy: 56.208%\n",
      "\tTesting Loss: 1.24; Testing Accuracy: 57.35%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 2.221; Training Accuracy: 60.128%\n",
      "\tTesting Loss: 1.288; Testing Accuracy: 55.65%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 2.1067; Training Accuracy: 62.324%\n",
      "\tTesting Loss: 1.1168; Testing Accuracy: 60.53%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bae423-3400-4a86-ab80-db63190d75a5",
   "metadata": {},
   "source": [
    "### Experiment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "119b4778-c1c1-4491-b172-360e42fe93f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.1805; Training Accuracy: 41.224%\n",
      "\tTesting Loss: 1.259; Testing Accuracy: 53.73%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.128; Training Accuracy: 62.156%\n",
      "\tTesting Loss: 0.913; Testing Accuracy: 67.99%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.7074; Training Accuracy: 69.984%\n",
      "\tTesting Loss: 0.854; Testing Accuracy: 69.78%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.4342; Training Accuracy: 74.932%\n",
      "\tTesting Loss: 0.632; Testing Accuracy: 78.26%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.2349; Training Accuracy: 78.432%\n",
      "\tTesting Loss: 0.6437; Testing Accuracy: 78.13%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec152e7-6638-4daf-8720-84e6b0e7abff",
   "metadata": {},
   "source": [
    "### Experiment 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c80c505c-6b11-4fa7-a9aa-0529fe20320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.0538; Training Accuracy: 43.89%\n",
      "\tTesting Loss: 1.23; Testing Accuracy: 55.69%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.2977; Training Accuracy: 58.824%\n",
      "\tTesting Loss: 1.0106; Testing Accuracy: 63.25%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.9435; Training Accuracy: 65.47%\n",
      "\tTesting Loss: 0.9031; Testing Accuracy: 68.61%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.6834; Training Accuracy: 70.346%\n",
      "\tTesting Loss: 0.7526; Testing Accuracy: 73.84%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.4895; Training Accuracy: 73.938%\n",
      "\tTesting Loss: 0.8041; Testing Accuracy: 73.3%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ca6d6-67b8-43f6-a9ba-a5eb8928aa27",
   "metadata": {},
   "source": [
    "### Experiment 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fe13ea5-6daf-49ba-9cb0-1e6eff35adb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.9855; Training Accuracy: 45.576%\n",
      "\tTesting Loss: 1.3195; Testing Accuracy: 55.37%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.9414; Training Accuracy: 65.68%\n",
      "\tTesting Loss: 0.9677; Testing Accuracy: 67.38%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.4932; Training Accuracy: 74.058%\n",
      "\tTesting Loss: 0.8003; Testing Accuracy: 73.01%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.2477; Training Accuracy: 78.316%\n",
      "\tTesting Loss: 0.6142; Testing Accuracy: 79.1%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.083; Training Accuracy: 81.192%\n",
      "\tTesting Loss: 0.6038; Testing Accuracy: 80.0%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = 64)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = 64)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dc3e0f-2a85-4238-9a24-e46d6d01edca",
   "metadata": {},
   "source": [
    "### Experiment 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb735e6b-202f-4175-b7fb-97f3277363bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.886; Training Accuracy: 47.34%\n",
      "\tTesting Loss: 1.2649; Testing Accuracy: 55.76%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.886; Training Accuracy: 66.504%\n",
      "\tTesting Loss: 0.9538; Testing Accuracy: 69.04%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.4315; Training Accuracy: 74.934%\n",
      "\tTesting Loss: 0.6605; Testing Accuracy: 77.32%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.19; Training Accuracy: 79.278%\n",
      "\tTesting Loss: 0.6034; Testing Accuracy: 79.86%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.0344; Training Accuracy: 82.042%\n",
      "\tTesting Loss: 0.6107; Testing Accuracy: 80.27%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = 128)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = 128)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1be17-ca06-43d8-9bfe-3214e5db7ae4",
   "metadata": {},
   "source": [
    "### Experiment 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5f3a08c-98aa-4892-bd84-3498df4c79e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.0066; Training Accuracy: 44.648%\n",
      "\tTesting Loss: 1.3332; Testing Accuracy: 52.62%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.0033; Training Accuracy: 64.266%\n",
      "\tTesting Loss: 0.9643; Testing Accuracy: 67.22%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.5359; Training Accuracy: 72.85%\n",
      "\tTesting Loss: 0.8235; Testing Accuracy: 72.64%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.2628; Training Accuracy: 77.83%\n",
      "\tTesting Loss: 0.7223; Testing Accuracy: 76.31%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.0916; Training Accuracy: 80.866%\n",
      "\tTesting Loss: 0.6643; Testing Accuracy: 77.08%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = 256)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = 256)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "180709f0-8e78-4528-8be9-a24ced83747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed975bf1-5d1b-4e4a-b07e-953752f2d518",
   "metadata": {},
   "source": [
    "### Experiment 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16383291-55b6-4f39-bea9-4a89b961708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.0979; Training Accuracy: 43.474%\n",
      "\tTesting Loss: 1.6336; Testing Accuracy: 48.3%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.9974; Training Accuracy: 64.442%\n",
      "\tTesting Loss: 0.7966; Testing Accuracy: 71.92%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.5179; Training Accuracy: 73.536%\n",
      "\tTesting Loss: 0.7326; Testing Accuracy: 75.39%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.2711; Training Accuracy: 78.002%\n",
      "\tTesting Loss: 0.6211; Testing Accuracy: 79.11%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.107; Training Accuracy: 80.898%\n",
      "\tTesting Loss: 0.519; Testing Accuracy: 82.51%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 0.9796; Training Accuracy: 83.05%\n",
      "\tTesting Loss: 0.5409; Testing Accuracy: 82.09%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 0.887; Training Accuracy: 84.758%\n",
      "\tTesting Loss: 0.4434; Testing Accuracy: 84.98%\n",
      "\n",
      "\tEpoch: 7\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device, batch_size = 32)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device, batch_size = 32)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3dbb40d-d25b-4e81-a048-fd37f2568d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11173962"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1dfb4-8954-47ab-97c5-a9b9aace8008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
