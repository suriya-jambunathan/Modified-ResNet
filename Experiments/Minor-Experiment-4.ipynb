{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96a69e9-2edc-4419-b6e7-6a9948b03a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ec3e25-0bfe-4adf-8dc0-65045c3b35eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff98de5-2ca4-464e-9f59-203fcc7c53ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Params: 4891338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ZigZag_ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ZigZag_ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 128, num_blocks[3], stride=2)\n",
    "        self.layer5 = self._make_layer(block, 64, num_blocks[4], stride=2)\n",
    "        self.layer6 = self._make_layer(block, 128, num_blocks[5], stride=2)\n",
    "        self.layer7 = self._make_layer(block, 256, num_blocks[6], stride=2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "zz_model = ZigZag_ResNet(BasicBlock, [2, 2, 2, 2, 2, 1, 1])\n",
    "num_params = sum(p.numel() for p in zz_model.parameters() if p.requires_grad)\n",
    "print(f\"Num Params: {num_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5206df38-668d-4acb-b6dd-ff4a492027a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_val(model, criterion, optimizer, train_loader, val_loader, device, scheduler = None, use_scheduler = True):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        cur_correct = (pred == label).sum().item()\n",
    "        cur_loss = loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        train_loss += cur_loss\n",
    "\n",
    "    train_accuracy = correct/total\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "                \n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        cur_correct = (pred == label).sum().item()\n",
    "        cur_loss = loss.item()\n",
    "            \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        valid_loss += cur_loss\n",
    "\n",
    "    valid_accuracy = correct/total\n",
    "    valid_loss = valid_loss/len(val_loader)\n",
    "    \n",
    "    if use_scheduler:\n",
    "        scheduler.step(valid_accuracy)\n",
    "\n",
    "    return train_loss, train_accuracy, valid_loss, valid_accuracy\n",
    "\n",
    "def test(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "                \n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        cur_correct = (pred == label).sum().item()\n",
    "        cur_loss = loss.item()\n",
    "            \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        test_loss += cur_loss\n",
    "\n",
    "    accuracy = correct/total\n",
    "    test_loss = test_loss/len(dataloader)\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d50fb17-d004-4bd5-88ea-45d216e32b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ZigZagLROnPlateauRestarts:\n",
    "    def __init__(self, optimizer, mode='min', lr=0.01, up_factor=1.1, down_factor=0.8, up_patience=10, down_patience=10, restart_after=30, verbose=False):\n",
    "        self.optimizer = optimizer\n",
    "        self.mode = mode\n",
    "        self.lr = lr\n",
    "        self.up_factor = up_factor\n",
    "        self.down_factor = down_factor\n",
    "        self.up_patience = up_patience\n",
    "        self.down_patience = down_patience\n",
    "        self.restart_after = restart_after\n",
    "        self.verbose = verbose\n",
    "        self.best_metric = np.inf if mode == 'min' else -np.inf\n",
    "        self.local_best_metric = self.best_metric\n",
    "        self.best_lr = lr\n",
    "        self.num_bad_epochs = 0\n",
    "        self.num_good_epochs = 0\n",
    "        self.local_best_epoch = 0\n",
    "        self.num_epochs = 0\n",
    "        \n",
    "    def step(self, metric):\n",
    "        if self.mode == 'min':\n",
    "            is_best = metric < self.best_metric\n",
    "        else:\n",
    "            is_best = metric > self.best_metric\n",
    "            \n",
    "        # If current metric is better than best metric, update best metric and learning rate\n",
    "        if is_best:\n",
    "            self.best_metric = metric\n",
    "            self.best_lr = self.lr\n",
    "            self.local_best_metric = metric\n",
    "            self.local_best_lr = self.lr\n",
    "            self.local_best_epoch = self.num_epochs\n",
    "            self.num_good_epochs = 0\n",
    "        else:\n",
    "            self.num_good_epochs += 1\n",
    "            \n",
    "        # If current metric is worse than best metric, increment bad epochs counter\n",
    "        if not is_best:\n",
    "            self.num_bad_epochs += 1\n",
    "        \n",
    "        # If bad epochs exceed up_patience, increase learning rate\n",
    "        if self.num_bad_epochs > self.up_patience:\n",
    "            self.lr *= self.up_factor\n",
    "            self.num_bad_epochs = 0\n",
    "            self.num_good_epochs = 0\n",
    "        \n",
    "        # If good epochs exceed down_patience, decrease learning rate\n",
    "        if self.num_good_epochs > self.down_patience:\n",
    "            self.lr *= self.down_factor\n",
    "            self.num_bad_epochs = 0\n",
    "            self.num_good_epochs = 0\n",
    "        \n",
    "        # Restart learning rate after a certain number of epochs\n",
    "        if self.num_epochs % self.restart_after == 0:\n",
    "            self.optimizer.param_groups[0]['lr'] = self.best_lr\n",
    "            if self.verbose:\n",
    "                print(f\"Restarting learning rate of group 0 to {self.best_lr:.4e}.\")\n",
    "            self.local_best_lr = self.best_lr\n",
    "            self.num_bad_epochs = 0\n",
    "            self.num_good_epochs = 0\n",
    "        \n",
    "        self.num_epochs += 1\n",
    "        \n",
    "        # If local best epoch is more than 10 epochs ago, update learning rate to local best learning rate\n",
    "        if self.num_epochs - self.local_best_epoch > 10:\n",
    "            self.optimizer.param_groups[0]['lr'] = self.local_best_lr\n",
    "        \n",
    "        return self.optimizer.param_groups[0]['lr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8060a3f-aa25-4fcb-9e2e-3b5b23258047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 4891338\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "Restarting learning rate of group 0 to 1.0000e-02.\n",
      "\tTraining Loss: 3.5444; Training Accuracy: 34.3275%\n",
      "\tValidation Loss: 1.5409; Validation Accuracy: 42.1%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.8075; Training Accuracy: 48.9475%\n",
      "\tValidation Loss: 1.338; Validation Accuracy: 52.09%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 2.3219; Training Accuracy: 58.825%\n",
      "\tValidation Loss: 1.0754; Validation Accuracy: 62.18%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.9578; Training Accuracy: 65.4675%\n",
      "\tValidation Loss: 0.8788; Validation Accuracy: 69.3%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.7204; Training Accuracy: 70.085%\n",
      "\tValidation Loss: 0.7922; Validation Accuracy: 72.37%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 1.5575; Training Accuracy: 73.07%\n",
      "\tValidation Loss: 0.7392; Validation Accuracy: 74.5%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 1.4351; Training Accuracy: 75.34%\n",
      "\tValidation Loss: 0.7501; Validation Accuracy: 73.89%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 1.3287; Training Accuracy: 76.9675%\n",
      "\tValidation Loss: 0.6313; Validation Accuracy: 78.61%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 1.2415; Training Accuracy: 78.6375%\n",
      "\tValidation Loss: 0.6019; Validation Accuracy: 79.35%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 1.166; Training Accuracy: 80.185%\n",
      "\tValidation Loss: 0.5497; Validation Accuracy: 81.34%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 1.0969; Training Accuracy: 81.3675%\n",
      "\tValidation Loss: 0.555; Validation Accuracy: 81.31%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 1.0419; Training Accuracy: 82.28%\n",
      "\tValidation Loss: 0.5111; Validation Accuracy: 82.17%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 0.9984; Training Accuracy: 82.9675%\n",
      "\tValidation Loss: 0.5196; Validation Accuracy: 82.51%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.953; Training Accuracy: 83.7175%\n",
      "\tValidation Loss: 0.5305; Validation Accuracy: 81.93%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.9118; Training Accuracy: 84.3475%\n",
      "\tValidation Loss: 0.4802; Validation Accuracy: 83.22%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.8779; Training Accuracy: 85.1025%\n",
      "\tValidation Loss: 0.4746; Validation Accuracy: 83.85%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.843; Training Accuracy: 85.595%\n",
      "\tValidation Loss: 0.4778; Validation Accuracy: 84.1%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.8083; Training Accuracy: 86.2975%\n",
      "\tValidation Loss: 0.4503; Validation Accuracy: 85.16%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.7762; Training Accuracy: 86.9525%\n",
      "\tValidation Loss: 0.4199; Validation Accuracy: 85.75%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.7448; Training Accuracy: 87.3675%\n",
      "\tValidation Loss: 0.4457; Validation Accuracy: 84.83%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.7259; Training Accuracy: 87.645%\n",
      "\tValidation Loss: 0.453; Validation Accuracy: 84.4%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.7065; Training Accuracy: 88.0975%\n",
      "\tValidation Loss: 0.4109; Validation Accuracy: 85.6%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.683; Training Accuracy: 88.3125%\n",
      "\tValidation Loss: 0.4201; Validation Accuracy: 85.51%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.6601; Training Accuracy: 88.7725%\n",
      "\tValidation Loss: 0.4038; Validation Accuracy: 86.49%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.6441; Training Accuracy: 89.0425%\n",
      "\tValidation Loss: 0.3877; Validation Accuracy: 86.9%\n",
      "\n",
      "\tEpoch: 25\n",
      "\tTraining Loss: 0.6238; Training Accuracy: 89.3775%\n",
      "\tValidation Loss: 0.4085; Validation Accuracy: 86.41%\n",
      "\n",
      "\tEpoch: 26\n",
      "\tTraining Loss: 0.6118; Training Accuracy: 89.5125%\n",
      "\tValidation Loss: 0.4077; Validation Accuracy: 86.28%\n",
      "\n",
      "\tEpoch: 27\n",
      "\tTraining Loss: 0.6003; Training Accuracy: 89.9275%\n",
      "\tValidation Loss: 0.4012; Validation Accuracy: 86.31%\n",
      "\n",
      "\tEpoch: 28\n",
      "\tTraining Loss: 0.5836; Training Accuracy: 90.1375%\n",
      "\tValidation Loss: 0.3612; Validation Accuracy: 87.96%\n",
      "\n",
      "\tEpoch: 29\n",
      "\tTraining Loss: 0.5707; Training Accuracy: 90.2375%\n",
      "\tValidation Loss: 0.4092; Validation Accuracy: 86.06%\n",
      "\n",
      "\tEpoch: 30\n",
      "Restarting learning rate of group 0 to 2.4300e-05.\n",
      "\tTraining Loss: 0.552; Training Accuracy: 90.6925%\n",
      "\tValidation Loss: 0.3495; Validation Accuracy: 88.18%\n",
      "\n",
      "\tEpoch: 31\n",
      "\tTraining Loss: 0.4527; Training Accuracy: 92.245%\n",
      "\tValidation Loss: 0.3338; Validation Accuracy: 88.58%\n",
      "\n",
      "\tEpoch: 32\n",
      "\tTraining Loss: 0.4355; Training Accuracy: 92.72%\n",
      "\tValidation Loss: 0.3163; Validation Accuracy: 89.1%\n",
      "\n",
      "\tEpoch: 33\n",
      "\tTraining Loss: 0.4034; Training Accuracy: 93.1375%\n",
      "\tValidation Loss: 0.309; Validation Accuracy: 89.66%\n",
      "\n",
      "\tEpoch: 34\n",
      "\tTraining Loss: 0.3962; Training Accuracy: 93.335%\n",
      "\tValidation Loss: 0.3077; Validation Accuracy: 89.48%\n",
      "\n",
      "\tEpoch: 35\n",
      "\tTraining Loss: 0.3862; Training Accuracy: 93.495%\n",
      "\tValidation Loss: 0.2999; Validation Accuracy: 89.88%\n",
      "\n",
      "\tEpoch: 36\n",
      "\tTraining Loss: 0.3851; Training Accuracy: 93.5225%\n",
      "\tValidation Loss: 0.2987; Validation Accuracy: 90.03%\n",
      "\n",
      "\tEpoch: 37\n",
      "\tTraining Loss: 0.3744; Training Accuracy: 93.6775%\n",
      "\tValidation Loss: 0.2954; Validation Accuracy: 89.61%\n",
      "\n",
      "\tEpoch: 38\n",
      "\tTraining Loss: 0.3706; Training Accuracy: 93.825%\n",
      "\tValidation Loss: 0.2866; Validation Accuracy: 90.16%\n",
      "\n",
      "\tEpoch: 39\n",
      "\tTraining Loss: 0.3595; Training Accuracy: 93.9675%\n",
      "\tValidation Loss: 0.2964; Validation Accuracy: 89.96%\n",
      "\n",
      "\tEpoch: 40\n",
      "\tTraining Loss: 0.3611; Training Accuracy: 93.83%\n",
      "\tValidation Loss: 0.2903; Validation Accuracy: 90.13%\n",
      "\n",
      "\tEpoch: 41\n",
      "\tTraining Loss: 0.3483; Training Accuracy: 94.075%\n",
      "\tValidation Loss: 0.3; Validation Accuracy: 89.72%\n",
      "\n",
      "\tEpoch: 42\n",
      "\tTraining Loss: 0.3398; Training Accuracy: 94.255%\n",
      "\tValidation Loss: 0.2818; Validation Accuracy: 90.43%\n",
      "\n",
      "\tEpoch: 43\n",
      "\tTraining Loss: 0.3451; Training Accuracy: 94.175%\n",
      "\tValidation Loss: 0.285; Validation Accuracy: 90.14%\n",
      "\n",
      "\tEpoch: 44\n",
      "\tTraining Loss: 0.3382; Training Accuracy: 94.345%\n",
      "\tValidation Loss: 0.2897; Validation Accuracy: 90.24%\n",
      "\n",
      "\tEpoch: 45\n",
      "\tTraining Loss: 0.3347; Training Accuracy: 94.4375%\n",
      "\tValidation Loss: 0.279; Validation Accuracy: 90.5%\n",
      "\n",
      "\tEpoch: 46\n",
      "\tTraining Loss: 0.3372; Training Accuracy: 94.4175%\n",
      "\tValidation Loss: 0.28; Validation Accuracy: 90.48%\n",
      "\n",
      "\tEpoch: 47\n",
      "\tTraining Loss: 0.329; Training Accuracy: 94.5675%\n",
      "\tValidation Loss: 0.2789; Validation Accuracy: 90.28%\n",
      "\n",
      "\tEpoch: 48\n",
      "\tTraining Loss: 0.3311; Training Accuracy: 94.48%\n",
      "\tValidation Loss: 0.287; Validation Accuracy: 90.14%\n",
      "\n",
      "\tEpoch: 49\n",
      "\tTraining Loss: 0.3299; Training Accuracy: 94.465%\n",
      "\tValidation Loss: 0.275; Validation Accuracy: 90.82%\n",
      "\n",
      "\tEpoch: 50\n",
      "\tTraining Loss: 0.3178; Training Accuracy: 94.6675%\n",
      "\tValidation Loss: 0.277; Validation Accuracy: 90.91%\n",
      "\n",
      "\tEpoch: 51\n",
      "\tTraining Loss: 0.3167; Training Accuracy: 94.73%\n",
      "\tValidation Loss: 0.2751; Validation Accuracy: 90.77%\n",
      "\n",
      "\tEpoch: 52\n",
      "\tTraining Loss: 0.3232; Training Accuracy: 94.625%\n",
      "\tValidation Loss: 0.2739; Validation Accuracy: 90.95%\n",
      "\n",
      "\tEpoch: 53\n",
      "\tTraining Loss: 0.3124; Training Accuracy: 94.7975%\n",
      "\tValidation Loss: 0.2752; Validation Accuracy: 90.99%\n",
      "\n",
      "\tEpoch: 54\n",
      "\tTraining Loss: 0.318; Training Accuracy: 94.6575%\n",
      "\tValidation Loss: 0.2741; Validation Accuracy: 90.93%\n",
      "\n",
      "\tEpoch: 55\n",
      "\tTraining Loss: 0.3106; Training Accuracy: 94.8325%\n",
      "\tValidation Loss: 0.278; Validation Accuracy: 90.66%\n",
      "\n",
      "\tEpoch: 56\n",
      "\tTraining Loss: 0.3023; Training Accuracy: 94.89%\n",
      "\tValidation Loss: 0.2708; Validation Accuracy: 90.9%\n",
      "\n",
      "\tEpoch: 57\n",
      "\tTraining Loss: 0.3146; Training Accuracy: 94.7475%\n",
      "\tValidation Loss: 0.2742; Validation Accuracy: 90.76%\n",
      "\n",
      "\tEpoch: 58\n",
      "\tTraining Loss: 0.3042; Training Accuracy: 94.915%\n",
      "\tValidation Loss: 0.2766; Validation Accuracy: 90.78%\n",
      "\n",
      "\tEpoch: 59\n",
      "\tTraining Loss: 0.307; Training Accuracy: 94.855%\n",
      "\tValidation Loss: 0.2663; Validation Accuracy: 90.96%\n",
      "\n",
      "\tEpoch: 60\n",
      "Restarting learning rate of group 0 to 5.9049e-08.\n",
      "\tTraining Loss: 0.2998; Training Accuracy: 94.995%\n",
      "\tValidation Loss: 0.2744; Validation Accuracy: 90.82%\n",
      "\n",
      "\tEpoch: 61\n",
      "\tTraining Loss: 0.3032; Training Accuracy: 95.0675%\n",
      "\tValidation Loss: 0.2652; Validation Accuracy: 91.05%\n",
      "\n",
      "\tEpoch: 62\n",
      "\tTraining Loss: 0.3045; Training Accuracy: 94.855%\n",
      "\tValidation Loss: 0.2724; Validation Accuracy: 90.79%\n",
      "\n",
      "\tEpoch: 63\n",
      "\tTraining Loss: 0.2998; Training Accuracy: 94.9975%\n",
      "\tValidation Loss: 0.2757; Validation Accuracy: 90.92%\n",
      "\n",
      "\tEpoch: 64\n",
      "\tTraining Loss: 0.3064; Training Accuracy: 94.9575%\n",
      "\tValidation Loss: 0.2735; Validation Accuracy: 90.85%\n",
      "\n",
      "\tEpoch: 65\n",
      "\tTraining Loss: 0.3069; Training Accuracy: 94.93%\n",
      "\tValidation Loss: 0.2712; Validation Accuracy: 90.89%\n",
      "\n",
      "\tEpoch: 66\n",
      "\tTraining Loss: 0.2983; Training Accuracy: 95.1525%\n",
      "\tValidation Loss: 0.2749; Validation Accuracy: 90.83%\n",
      "\n",
      "\tEpoch: 67\n",
      "\tTraining Loss: 0.2937; Training Accuracy: 95.0975%\n",
      "\tValidation Loss: 0.2767; Validation Accuracy: 90.77%\n",
      "\n",
      "\tEpoch: 68\n",
      "\tTraining Loss: 0.3013; Training Accuracy: 94.9775%\n",
      "\tValidation Loss: 0.2767; Validation Accuracy: 90.5%\n",
      "\n",
      "\tEpoch: 69\n",
      "\tTraining Loss: 0.3061; Training Accuracy: 94.83%\n",
      "\tValidation Loss: 0.2699; Validation Accuracy: 90.91%\n",
      "\n",
      "\tEpoch: 70\n",
      "\tTraining Loss: 0.3039; Training Accuracy: 94.975%\n",
      "\tValidation Loss: 0.2709; Validation Accuracy: 90.77%\n",
      "\n",
      "\tEpoch: 71\n",
      "\tTraining Loss: 0.3022; Training Accuracy: 94.87%\n",
      "\tValidation Loss: 0.2703; Validation Accuracy: 91.18%\n",
      "\n",
      "\tEpoch: 72\n",
      "\tTraining Loss: 0.3062; Training Accuracy: 94.8775%\n",
      "\tValidation Loss: 0.2703; Validation Accuracy: 90.88%\n",
      "\n",
      "\tEpoch: 73\n",
      "\tTraining Loss: 0.299; Training Accuracy: 95.1075%\n",
      "\tValidation Loss: 0.2802; Validation Accuracy: 90.69%\n",
      "\n",
      "\tEpoch: 74\n",
      "\tTraining Loss: 0.304; Training Accuracy: 94.9075%\n",
      "\tValidation Loss: 0.269; Validation Accuracy: 90.95%\n",
      "\n",
      "\tEpoch: 75\n",
      "\tTraining Loss: 0.3083; Training Accuracy: 94.7975%\n",
      "\tValidation Loss: 0.2753; Validation Accuracy: 90.56%\n",
      "\n",
      "\tEpoch: 76\n",
      "\tTraining Loss: 0.3044; Training Accuracy: 94.89%\n",
      "\tValidation Loss: 0.2722; Validation Accuracy: 90.85%\n",
      "\n",
      "\tEpoch: 77\n",
      "\tTraining Loss: 0.2987; Training Accuracy: 94.96%\n",
      "\tValidation Loss: 0.2702; Validation Accuracy: 90.98%\n",
      "\n",
      "\tEpoch: 78\n",
      "\tTraining Loss: 0.3027; Training Accuracy: 94.925%\n",
      "\tValidation Loss: 0.2711; Validation Accuracy: 90.78%\n",
      "\n",
      "\tEpoch: 79\n",
      "\tTraining Loss: 0.3103; Training Accuracy: 94.8425%\n",
      "\tValidation Loss: 0.2699; Validation Accuracy: 91.04%\n",
      "\n",
      "\tEpoch: 80\n",
      "\tTraining Loss: 0.3005; Training Accuracy: 94.93%\n",
      "\tValidation Loss: 0.2707; Validation Accuracy: 90.89%\n",
      "\n",
      "\tEpoch: 81\n",
      "\tTraining Loss: 0.3004; Training Accuracy: 94.8775%\n",
      "\tValidation Loss: 0.2675; Validation Accuracy: 91.07%\n",
      "\n",
      "\tEpoch: 82\n",
      "\tTraining Loss: 0.3056; Training Accuracy: 95.01%\n",
      "\tValidation Loss: 0.2764; Validation Accuracy: 90.6%\n",
      "\n",
      "\tEpoch: 83\n",
      "\tTraining Loss: 0.3033; Training Accuracy: 95.0125%\n",
      "\tValidation Loss: 0.2731; Validation Accuracy: 90.88%\n",
      "\n",
      "\tEpoch: 84\n",
      "\tTraining Loss: 0.3041; Training Accuracy: 94.8025%\n",
      "\tValidation Loss: 0.2702; Validation Accuracy: 90.75%\n",
      "\n",
      "\tEpoch: 85\n",
      "\tTraining Loss: 0.3008; Training Accuracy: 95.095%\n",
      "\tValidation Loss: 0.2691; Validation Accuracy: 91.12%\n",
      "\n",
      "\tEpoch: 86\n",
      "\tTraining Loss: 0.3016; Training Accuracy: 95.08%\n",
      "\tValidation Loss: 0.2793; Validation Accuracy: 90.55%\n",
      "\n",
      "\tEpoch: 87\n",
      "\tTraining Loss: 0.3037; Training Accuracy: 94.87%\n",
      "\tValidation Loss: 0.2725; Validation Accuracy: 90.77%\n",
      "\n",
      "\tEpoch: 88\n",
      "\tTraining Loss: 0.3056; Training Accuracy: 94.7825%\n",
      "\tValidation Loss: 0.2765; Validation Accuracy: 90.72%\n",
      "\n",
      "\tEpoch: 89\n",
      "\tTraining Loss: 0.2997; Training Accuracy: 94.99%\n",
      "\tValidation Loss: 0.2734; Validation Accuracy: 90.81%\n",
      "\n",
      "\tEpoch: 90\n",
      "Restarting learning rate of group 0 to 3.8742e-12.\n",
      "\tTraining Loss: 0.302; Training Accuracy: 94.94%\n",
      "\tValidation Loss: 0.2645; Validation Accuracy: 90.9%\n",
      "\n",
      "\tEpoch: 91\n",
      "\tTraining Loss: 0.3004; Training Accuracy: 95.0025%\n",
      "\tValidation Loss: 0.2629; Validation Accuracy: 91.09%\n",
      "\n",
      "\tEpoch: 92\n",
      "\tTraining Loss: 0.3082; Training Accuracy: 94.775%\n",
      "\tValidation Loss: 0.2731; Validation Accuracy: 90.93%\n",
      "\n",
      "\tEpoch: 93\n",
      "\tTraining Loss: 0.3013; Training Accuracy: 94.935%\n",
      "\tValidation Loss: 0.2765; Validation Accuracy: 90.64%\n",
      "\n",
      "\tEpoch: 94\n",
      "\tTraining Loss: 0.3066; Training Accuracy: 94.8825%\n",
      "\tValidation Loss: 0.262; Validation Accuracy: 91.34%\n",
      "\n",
      "\tEpoch: 95\n",
      "\tTraining Loss: 0.303; Training Accuracy: 94.8375%\n",
      "\tValidation Loss: 0.2679; Validation Accuracy: 90.93%\n",
      "\n",
      "\tEpoch: 96\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m     train_loss, train_accuracy, val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_scheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     train_losses_\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     62\u001b[0m     train_accuracies_\u001b[38;5;241m.\u001b[39mappend(train_accuracy)\n",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m, in \u001b[0;36mtrain_val\u001b[1;34m(model, criterion, optimizer, train_loader, val_loader, device, scheduler, use_scheduler)\u001b[0m\n\u001b[0;32m      5\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      8\u001b[0m     image, label \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m      9\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataset.py:295\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[1;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\datasets\\cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    115\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:673\u001b[0m, in \u001b[0;36mRandomCrop.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    670\u001b[0m     padding \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m height]\n\u001b[0;32m    671\u001b[0m     img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(img, padding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode)\n\u001b[1;32m--> 673\u001b[0m i, j, h, w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcrop(img, i, j, h, w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:637\u001b[0m, in \u001b[0;36mRandomCrop.get_params\u001b[1;34m(img, output_size)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;241m==\u001b[39m tw \u001b[38;5;129;01mand\u001b[39;00m h \u001b[38;5;241m==\u001b[39m th:\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, h, w\n\u001b[1;32m--> 637\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    638\u001b[0m j \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, w \u001b[38;5;241m-\u001b[39m tw \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m i, j, th, tw\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "    \n",
    "transform_train = torchvision.transforms.Compose([\n",
    "  torchvision.transforms.RandomCrop(32, padding=4),\n",
    "  torchvision.transforms.RandomHorizontalFlip(),\n",
    "  torchvision.transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "  torchvision.transforms.ToTensor(),\n",
    "  torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                  torchvision.transforms.ToTensor(), \n",
    "                  torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "\n",
    "# Split the train data into train and validation sets\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "# train_size = int(0.2 * len(trainset))\n",
    "# val_size = int(0.2 * len(valset))\n",
    "# trainset, _ = torch.utils.data.random_split(trainset, [train_size, len(trainset) - train_size])\n",
    "# valset, _ = torch.utils.data.random_split(valset, [val_size, len(valset) - val_size])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "val_loader   = torch.utils.data.DataLoader(valset, batch_size = batch_size, shuffle = True)\n",
    "test_loader  = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    \n",
    "best_test_acc = 0\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = ZigZag_ResNet(BasicBlock, [2, 2, 2, 2, 2, 1, 1])\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01, momentum = 0.8, weight_decay = 0.0005 , nesterov=True)\n",
    "\n",
    "scheduler = ZigZagLROnPlateauRestarts(optimizer, mode='max', lr=0.01,\n",
    "                                      up_factor=0.3, down_factor=0.5, \n",
    "                                      up_patience=1, down_patience=1, \n",
    "                                      restart_after=30, verbose = True)\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "valid_losses_ = []\n",
    "valid_accuracies_ = []\n",
    "\n",
    "epochs = 250\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "\n",
    "    train_loss, train_accuracy, val_loss, val_accuracy = train_val(model, criterion, optimizer, \n",
    "                                                                train_loader, val_loader, device,\n",
    "                                                                scheduler = scheduler, use_scheduler = True)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    valid_losses_.append(val_loss)\n",
    "    valid_accuracies_.append(val_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    print(f\"\\tValidation Loss: {round(val_loss, 4)}; Validation Accuracy: {round(val_accuracy*100, 4)}%\")\n",
    "\n",
    "test_loss, test_accuracy = test(model, criterion, test_loader, device)\n",
    "print(f\"\\n\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")\n",
    "\n",
    "if test_accuracy > best_test_acc:\n",
    "    best_test_acc = test_accuracy\n",
    "\n",
    "    metrics_dict = {'train_loss': train_losses_, 'train_accuracy': train_accuracies_, \n",
    "                  'valid_loss': valid_losses_, 'valid_accuracy': valid_accuracies_,\n",
    "                  'test_loss': test_loss, 'test_accuracy': test_accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38843cb9-6787-4ce3-b252-1042a8c9a8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
