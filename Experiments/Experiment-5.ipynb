{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ef8497-1d9f-440e-b565-9afbb8072007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc67bec-be62-462a-8679-53f4c2a43e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 128, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e78880b6-9603-4afc-b16b-3ebd46c5bbb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5369162"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [1, 2, 2, 2])\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef31f93-8f31-4c5d-aa91-c21d0d55de5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GPU_BATCH_SIZE_LIMIT = 512\n",
    "\n",
    "def train(model, criterion, optimizer, dataloader, device, scheduler = None, use_scheduler = False, batch_size = 32):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        if batch_size >= GPU_BATCH_SIZE_LIMIT:\n",
    "            if(count == 0):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                count = batch_size/32\n",
    "\n",
    "            output = model(image)\n",
    "\n",
    "            loss = criterion(output, label)*32/batch_size\n",
    "            loss.backward()\n",
    "            count = count - 1\n",
    "\n",
    "            pred = torch.max(output.data, 1)[1]\n",
    "            \n",
    "            cur_correct = (pred == label).sum().item()\n",
    "            cur_loss = loss.item()\n",
    "        \n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(image)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            pred = torch.max(output.data, 1)[1]\n",
    "            cur_correct = (pred == label).sum().item()\n",
    "            cur_loss = loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        train_loss += cur_loss\n",
    "\n",
    "        if use_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "    accuracy = correct/total\n",
    "    train_loss = train_loss/len(dataloader)\n",
    "\n",
    "    return train_loss, accuracy\n",
    "\n",
    "def test(model, criterion, dataloader, device, batch_size = 32):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "                \n",
    "        if batch_size >= GPU_BATCH_SIZE_LIMIT:\n",
    "            if(count == 0):\n",
    "                count = batch_size/32\n",
    "\n",
    "            output = model(image)\n",
    "\n",
    "            loss = criterion(output, label)*32/batch_size\n",
    "            count = count - 1\n",
    "\n",
    "            pred = torch.max(output.data, 1)[1]\n",
    "            \n",
    "            cur_correct = (pred == label).sum().item()\n",
    "            cur_loss = loss.item()\n",
    "        \n",
    "        else:\n",
    "            output = model(image)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            pred = torch.max(output.data, 1)[1]\n",
    "            cur_correct = (pred == label).sum().item()\n",
    "            cur_loss = loss.item()\n",
    "            \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        test_loss += cur_loss\n",
    "\n",
    "    accuracy = correct/total\n",
    "    test_loss = test_loss/len(dataloader)\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc101754-2201-4ca9-91be-acc59fe34973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81569673-1d70-473f-b120-79da0ffbf9df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "686026"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the BasicBlock class\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.stride != 1 or identity.size(1) != x.size(1):\n",
    "            identity = F.avg_pool2d(identity, 2, self.stride)\n",
    "            identity = torch.cat((identity, torch.zeros(identity.size(0), x.size(1) - identity.size(1), identity.size(2), identity.size(3)).to(x.device)), dim=1)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Define the ResNet-14 model for CIFAR-10\n",
    "class ResNet14(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet14, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(32, 32, 2)\n",
    "        self.layer2 = self._make_layer(32, 64, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(64, 128, 2, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(BasicBlock(in_channels, out_channels, stride))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(BasicBlock(out_channels, out_channels, stride=1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of ResNet-14 model for CIFAR-10\n",
    "model = ResNet14(num_classes=10)\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc35d6cd-64cb-47d9-835e-48d38e762a39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5198666"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [1, 2, 1, 2])\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c14280a-941f-43ff-bd3f-9d0db0e362bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_val(model, criterion, optimizer, train_loader, val_loader, device, scheduler = None, use_scheduler = False):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        cur_correct = (pred == label).sum().item()\n",
    "        cur_loss = loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        train_loss += cur_loss\n",
    "\n",
    "    train_accuracy = correct/total\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "                \n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        cur_correct = (pred == label).sum().item()\n",
    "        cur_loss = loss.item()\n",
    "            \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        valid_loss += cur_loss\n",
    "\n",
    "    valid_accuracy = correct/total\n",
    "    valid_loss = valid_loss/len(val_loader)\n",
    "    \n",
    "    if use_scheduler:\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "    return train_loss, train_accuracy, valid_loss, valid_accuracy\n",
    "\n",
    "def test(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        image, label = data\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "                \n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        cur_correct = (pred == label).sum().item()\n",
    "        cur_loss = loss.item()\n",
    "            \n",
    "        total += label.size(0)\n",
    "        correct += cur_correct\n",
    "        test_loss += cur_loss\n",
    "\n",
    "    accuracy = correct/total\n",
    "    test_loss = test_loss/len(dataloader)\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfc761b-9043-48ca-a666-1fdde625ea4a",
   "metadata": {},
   "source": [
    "EXPERIMENT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "916634e0-8eff-4006-bd78-71f38ea9345f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Params: 686026\n",
      "\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.3281; Training Accuracy: 38.775%\n",
      "\tValidation Loss: 1.285; Validation Accuracy: 52.05%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.307; Training Accuracy: 59.015%\n",
      "\tValidation Loss: 1.2103; Validation Accuracy: 57.3%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.8299; Training Accuracy: 68.195%\n",
      "\tValidation Loss: 0.8918; Validation Accuracy: 68.68%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 1.5868; Training Accuracy: 72.385%\n",
      "\tValidation Loss: 1.0391; Validation Accuracy: 66.25%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 1.4649; Training Accuracy: 74.67%\n",
      "\tValidation Loss: 0.8468; Validation Accuracy: 70.08%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 1.3877; Training Accuracy: 76.135%\n",
      "\tValidation Loss: 0.8316; Validation Accuracy: 71.57%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 1.3475; Training Accuracy: 76.855%\n",
      "\tValidation Loss: 0.9354; Validation Accuracy: 68.56%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 1.318; Training Accuracy: 77.3425%\n",
      "\tValidation Loss: 0.8045; Validation Accuracy: 72.5%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 1.2918; Training Accuracy: 78.08%\n",
      "\tValidation Loss: 0.8485; Validation Accuracy: 71.17%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 1.2616; Training Accuracy: 78.4525%\n",
      "\tValidation Loss: 0.7406; Validation Accuracy: 74.84%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 1.2364; Training Accuracy: 78.605%\n",
      "\tValidation Loss: 0.8365; Validation Accuracy: 71.47%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 1.2328; Training Accuracy: 78.76%\n",
      "\tValidation Loss: 0.8948; Validation Accuracy: 70.17%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 1.2205; Training Accuracy: 79.0475%\n",
      "\tValidation Loss: 0.7708; Validation Accuracy: 74.46%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 1.2066; Training Accuracy: 79.17%\n",
      "\tValidation Loss: 1.2294; Validation Accuracy: 63.65%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 1.2152; Training Accuracy: 79.1675%\n",
      "\tValidation Loss: 0.8018; Validation Accuracy: 72.89%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 1.2058; Training Accuracy: 79.2075%\n",
      "\tValidation Loss: 1.015; Validation Accuracy: 67.1%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 1.2064; Training Accuracy: 79.68%\n",
      "\tValidation Loss: 0.7088; Validation Accuracy: 75.64%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 1.2013; Training Accuracy: 79.605%\n",
      "\tValidation Loss: 0.9648; Validation Accuracy: 70.66%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 1.1938; Training Accuracy: 79.475%\n",
      "\tValidation Loss: 0.9005; Validation Accuracy: 70.9%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 1.1822; Training Accuracy: 79.7675%\n",
      "\tValidation Loss: 0.7837; Validation Accuracy: 74.35%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 1.186; Training Accuracy: 79.8925%\n",
      "\tValidation Loss: 0.8525; Validation Accuracy: 70.94%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 1.1895; Training Accuracy: 79.67%\n",
      "\tValidation Loss: 0.7628; Validation Accuracy: 74.59%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 1.1841; Training Accuracy: 79.955%\n",
      "\tValidation Loss: 0.8792; Validation Accuracy: 69.59%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 1.181; Training Accuracy: 79.8775%\n",
      "\tValidation Loss: 0.9101; Validation Accuracy: 68.45%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 1.1804; Training Accuracy: 79.7675%\n",
      "\tValidation Loss: 0.7459; Validation Accuracy: 75.38%\n",
      "\n",
      "\tEpoch: 25\n",
      "\tTraining Loss: 1.1831; Training Accuracy: 79.5875%\n",
      "\tValidation Loss: 0.743; Validation Accuracy: 75.28%\n",
      "\n",
      "\tEpoch: 26\n",
      "\tTraining Loss: 1.1738; Training Accuracy: 79.995%\n",
      "\tValidation Loss: 0.7778; Validation Accuracy: 74.08%\n",
      "\n",
      "\tEpoch: 27\n",
      "\tTraining Loss: 1.1634; Training Accuracy: 80.0025%\n",
      "\tValidation Loss: 0.7602; Validation Accuracy: 74.49%\n",
      "\n",
      "\tEpoch: 28\n",
      "\tTraining Loss: 1.1691; Training Accuracy: 79.8475%\n",
      "\tValidation Loss: 0.6737; Validation Accuracy: 76.94%\n",
      "\n",
      "\tEpoch: 29\n",
      "\tTraining Loss: 1.1636; Training Accuracy: 79.875%\n",
      "\tValidation Loss: 1.0044; Validation Accuracy: 68.33%\n",
      "\n",
      "\tEpoch: 30\n",
      "\tTraining Loss: 1.1681; Training Accuracy: 80.075%\n",
      "\tValidation Loss: 0.7367; Validation Accuracy: 75.76%\n",
      "\n",
      "\tEpoch: 31\n",
      "\tTraining Loss: 1.1662; Training Accuracy: 80.2725%\n",
      "\tValidation Loss: 0.7429; Validation Accuracy: 74.02%\n",
      "\n",
      "\tEpoch: 32\n",
      "\tTraining Loss: 1.165; Training Accuracy: 80.045%\n",
      "\tValidation Loss: 0.7169; Validation Accuracy: 75.61%\n",
      "\n",
      "\tEpoch: 33\n",
      "\tTraining Loss: 1.1543; Training Accuracy: 80.26%\n",
      "\tValidation Loss: 0.7405; Validation Accuracy: 74.51%\n",
      "\n",
      "\tEpoch: 34\n",
      "\tTraining Loss: 1.1597; Training Accuracy: 79.9075%\n",
      "\tValidation Loss: 0.8308; Validation Accuracy: 72.31%\n",
      "\n",
      "\tEpoch: 35\n",
      "\tTraining Loss: 1.1612; Training Accuracy: 80.1025%\n",
      "\tValidation Loss: 0.637; Validation Accuracy: 77.61%\n",
      "\n",
      "\tEpoch: 36\n",
      "\tTraining Loss: 1.1549; Training Accuracy: 80.325%\n",
      "\tValidation Loss: 0.9277; Validation Accuracy: 70.5%\n",
      "\n",
      "\tEpoch: 37\n",
      "\tTraining Loss: 1.1618; Training Accuracy: 80.2%\n",
      "\tValidation Loss: 0.7077; Validation Accuracy: 75.66%\n",
      "\n",
      "\tEpoch: 38\n",
      "\tTraining Loss: 1.1579; Training Accuracy: 80.07%\n",
      "\tValidation Loss: 0.683; Validation Accuracy: 76.77%\n",
      "\n",
      "\tEpoch: 39\n",
      "\tTraining Loss: 1.1525; Training Accuracy: 80.3675%\n",
      "\tValidation Loss: 0.9243; Validation Accuracy: 71.3%\n",
      "\n",
      "\tEpoch: 40\n",
      "\tTraining Loss: 1.1584; Training Accuracy: 80.3%\n",
      "\tValidation Loss: 0.7699; Validation Accuracy: 73.92%\n",
      "\n",
      "\tEpoch: 41\n",
      "\tTraining Loss: 1.1513; Training Accuracy: 80.29%\n",
      "\tValidation Loss: 0.7404; Validation Accuracy: 75.45%\n",
      "\n",
      "\tEpoch: 42\n",
      "\tTraining Loss: 1.159; Training Accuracy: 80.0375%\n",
      "\tValidation Loss: 0.8334; Validation Accuracy: 70.2%\n",
      "\n",
      "\tEpoch: 43\n",
      "\tTraining Loss: 1.1312; Training Accuracy: 80.62%\n",
      "\tValidation Loss: 0.7726; Validation Accuracy: 74.36%\n",
      "\n",
      "\tEpoch: 44\n",
      "\tTraining Loss: 1.154; Training Accuracy: 80.31%\n",
      "\tValidation Loss: 0.7602; Validation Accuracy: 73.81%\n",
      "\n",
      "\tEpoch: 45\n",
      "\tTraining Loss: 1.1458; Training Accuracy: 80.38%\n",
      "\tValidation Loss: 0.7614; Validation Accuracy: 73.55%\n",
      "\n",
      "\tEpoch: 46\n",
      "\tTraining Loss: 1.1588; Training Accuracy: 80.4325%\n",
      "\tValidation Loss: 0.6389; Validation Accuracy: 78.1%\n",
      "\n",
      "\tEpoch: 47\n",
      "\tTraining Loss: 1.1575; Training Accuracy: 80.01%\n",
      "\tValidation Loss: 0.8725; Validation Accuracy: 71.89%\n",
      "\n",
      "\tEpoch: 48\n",
      "\tTraining Loss: 1.1456; Training Accuracy: 80.5%\n",
      "\tValidation Loss: 0.8164; Validation Accuracy: 72.35%\n",
      "\n",
      "\tEpoch: 49\n",
      "\tTraining Loss: 1.1429; Training Accuracy: 80.56%\n",
      "\tValidation Loss: 0.7653; Validation Accuracy: 74.59%\n",
      "\n",
      "\tTesting Loss: 0.7922; Testing Accuracy: 73.43%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(), \n",
    "                    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
    "\n",
    "# Split the train data into train and validation sets\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "val_loader   = torch.utils.data.DataLoader(valset, batch_size = batch_size, shuffle = True)\n",
    "test_loader  = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet14(num_classes=10)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Num Params: {num_params}\\n\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor=0.1, verbose = True)\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "valid_losses_ = []\n",
    "valid_accuracies_ = []\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy, val_loss, val_accuracy = train_val(model, criterion, optimizer, \n",
    "                                                                   train_loader, val_loader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    valid_losses_.append(val_loss)\n",
    "    valid_accuracies_.append(val_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    print(f\"\\tValidation Loss: {round(val_loss, 4)}; Validation Accuracy: {round(val_accuracy*100, 4)}%\")\n",
    "    \n",
    "test_loss, test_accuracy = test(model, criterion, test_loader, device)\n",
    "print(f\"\\n\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2404582e-4d43-4f5c-b3c7-aeb394ff6e22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m classes \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplane\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbird\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mship\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruck\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet14(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n\u001b[0;32m     16\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     17\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m, nesterov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet14(num_classes=10)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay= 0.0001, nesterov = True)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204a54d-21bb-4442-a218-734655d0d4ab",
   "metadata": {},
   "source": [
    "EXPERIMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59bbfac1-c0ef-4651-9df2-4425b8d371ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.4646; Training Accuracy: 55.228%\n",
      "\tTesting Loss: 0.9236; Testing Accuracy: 67.7%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.5164; Training Accuracy: 73.222%\n",
      "\tTesting Loss: 0.8025; Testing Accuracy: 72.45%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.1271; Training Accuracy: 80.128%\n",
      "\tTesting Loss: 0.6234; Testing Accuracy: 78.53%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 0.8652; Training Accuracy: 84.866%\n",
      "\tTesting Loss: 0.5852; Testing Accuracy: 79.98%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 0.6492; Training Accuracy: 88.67%\n",
      "\tTesting Loss: 0.5992; Testing Accuracy: 79.68%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 0.4686; Training Accuracy: 91.952%\n",
      "\tTesting Loss: 0.6296; Testing Accuracy: 80.52%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 0.3313; Training Accuracy: 94.288%\n",
      "\tTesting Loss: 0.6194; Testing Accuracy: 81.73%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 0.2268; Training Accuracy: 96.092%\n",
      "\tTesting Loss: 0.6562; Testing Accuracy: 81.97%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 0.168; Training Accuracy: 97.23%\n",
      "\tTesting Loss: 0.6629; Testing Accuracy: 82.25%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 0.1149; Training Accuracy: 98.142%\n",
      "\tTesting Loss: 0.7226; Testing Accuracy: 81.76%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 0.0945; Training Accuracy: 98.562%\n",
      "\tTesting Loss: 0.6972; Testing Accuracy: 82.09%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 0.0786; Training Accuracy: 98.808%\n",
      "\tTesting Loss: 0.7332; Testing Accuracy: 82.38%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 0.0517; Training Accuracy: 99.29%\n",
      "\tTesting Loss: 0.6963; Testing Accuracy: 83.84%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.0428; Training Accuracy: 99.404%\n",
      "\tTesting Loss: 0.8108; Testing Accuracy: 82.12%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.0376; Training Accuracy: 99.456%\n",
      "\tTesting Loss: 0.6976; Testing Accuracy: 83.41%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 1, 1, 2])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay= 0.0001, nesterov = True)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e9ad0d7-1fff-4090-a82b-c494a585a818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4977226"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [2, 1, 1, 1])\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af084c-8426-45a1-b346-eec536cea111",
   "metadata": {},
   "source": [
    "EXPERIMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "490d8cdf-1e39-40d5-b81a-8984735fa1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 2.7886; Training Accuracy: 49.124%\n",
      "\tTesting Loss: 1.0763; Testing Accuracy: 61.07%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 1.6935; Training Accuracy: 70.008%\n",
      "\tTesting Loss: 0.7472; Testing Accuracy: 73.9%\n",
      "\n",
      "\tEpoch: 2\n",
      "\tTraining Loss: 1.2411; Training Accuracy: 78.266%\n",
      "\tTesting Loss: 0.6213; Testing Accuracy: 78.3%\n",
      "\n",
      "\tEpoch: 3\n",
      "\tTraining Loss: 0.9759; Training Accuracy: 82.936%\n",
      "\tTesting Loss: 0.571; Testing Accuracy: 80.48%\n",
      "\n",
      "\tEpoch: 4\n",
      "\tTraining Loss: 0.7756; Training Accuracy: 86.46%\n",
      "\tTesting Loss: 0.5698; Testing Accuracy: 81.09%\n",
      "\n",
      "\tEpoch: 5\n",
      "\tTraining Loss: 0.5975; Training Accuracy: 89.464%\n",
      "\tTesting Loss: 0.5472; Testing Accuracy: 81.65%\n",
      "\n",
      "\tEpoch: 6\n",
      "\tTraining Loss: 0.4597; Training Accuracy: 91.982%\n",
      "\tTesting Loss: 0.6241; Testing Accuracy: 80.55%\n",
      "\n",
      "\tEpoch: 7\n",
      "\tTraining Loss: 0.3635; Training Accuracy: 93.704%\n",
      "\tTesting Loss: 0.7156; Testing Accuracy: 79.21%\n",
      "\n",
      "\tEpoch: 8\n",
      "\tTraining Loss: 0.3018; Training Accuracy: 94.802%\n",
      "\tTesting Loss: 0.5615; Testing Accuracy: 82.88%\n",
      "\n",
      "\tEpoch: 9\n",
      "\tTraining Loss: 0.2546; Training Accuracy: 95.588%\n",
      "\tTesting Loss: 0.6262; Testing Accuracy: 81.96%\n",
      "\n",
      "\tEpoch: 10\n",
      "\tTraining Loss: 0.2284; Training Accuracy: 95.992%\n",
      "\tTesting Loss: 0.6596; Testing Accuracy: 81.72%\n",
      "\n",
      "\tEpoch: 11\n",
      "\tTraining Loss: 0.2129; Training Accuracy: 96.31%\n",
      "\tTesting Loss: 0.6552; Testing Accuracy: 81.86%\n",
      "\n",
      "\tEpoch: 12\n",
      "\tTraining Loss: 0.1858; Training Accuracy: 96.878%\n",
      "\tTesting Loss: 0.6213; Testing Accuracy: 82.84%\n",
      "\n",
      "\tEpoch: 13\n",
      "\tTraining Loss: 0.1738; Training Accuracy: 97.05%\n",
      "\tTesting Loss: 0.7059; Testing Accuracy: 81.26%\n",
      "\n",
      "\tEpoch: 14\n",
      "\tTraining Loss: 0.1855; Training Accuracy: 96.846%\n",
      "\tTesting Loss: 0.692; Testing Accuracy: 81.49%\n",
      "\n",
      "\tEpoch: 15\n",
      "\tTraining Loss: 0.1714; Training Accuracy: 97.098%\n",
      "\tTesting Loss: 0.672; Testing Accuracy: 81.27%\n",
      "\n",
      "\tEpoch: 16\n",
      "\tTraining Loss: 0.1642; Training Accuracy: 97.184%\n",
      "\tTesting Loss: 0.7471; Testing Accuracy: 81.33%\n",
      "\n",
      "\tEpoch: 17\n",
      "\tTraining Loss: 0.1572; Training Accuracy: 97.328%\n",
      "\tTesting Loss: 0.6739; Testing Accuracy: 81.53%\n",
      "\n",
      "\tEpoch: 18\n",
      "\tTraining Loss: 0.1597; Training Accuracy: 97.328%\n",
      "\tTesting Loss: 0.7049; Testing Accuracy: 81.46%\n",
      "\n",
      "\tEpoch: 19\n",
      "\tTraining Loss: 0.1574; Training Accuracy: 97.322%\n",
      "\tTesting Loss: 0.6484; Testing Accuracy: 82.36%\n",
      "\n",
      "\tEpoch: 20\n",
      "\tTraining Loss: 0.1634; Training Accuracy: 97.236%\n",
      "\tTesting Loss: 0.6692; Testing Accuracy: 81.73%\n",
      "\n",
      "\tEpoch: 21\n",
      "\tTraining Loss: 0.1516; Training Accuracy: 97.444%\n",
      "\tTesting Loss: 0.7386; Testing Accuracy: 80.86%\n",
      "\n",
      "\tEpoch: 22\n",
      "\tTraining Loss: 0.1397; Training Accuracy: 97.732%\n",
      "\tTesting Loss: 0.7247; Testing Accuracy: 80.74%\n",
      "\n",
      "\tEpoch: 23\n",
      "\tTraining Loss: 0.1519; Training Accuracy: 97.45%\n",
      "\tTesting Loss: 0.6793; Testing Accuracy: 81.09%\n",
      "\n",
      "\tEpoch: 24\n",
      "\tTraining Loss: 0.1539; Training Accuracy: 97.39%\n",
      "\tTesting Loss: 0.7338; Testing Accuracy: 81.75%\n",
      "\n",
      "\tEpoch: 25\n",
      "\tTraining Loss: 0.1534; Training Accuracy: 97.41%\n",
      "\tTesting Loss: 0.6818; Testing Accuracy: 82.19%\n",
      "\n",
      "\tEpoch: 26\n",
      "\tTraining Loss: 0.1466; Training Accuracy: 97.626%\n",
      "\tTesting Loss: 0.6889; Testing Accuracy: 82.12%\n",
      "\n",
      "\tEpoch: 27\n",
      "\tTraining Loss: 0.1509; Training Accuracy: 97.45%\n",
      "\tTesting Loss: 0.7463; Testing Accuracy: 81.0%\n",
      "\n",
      "\tEpoch: 28\n",
      "\tTraining Loss: 0.1518; Training Accuracy: 97.43%\n",
      "\tTesting Loss: 0.7028; Testing Accuracy: 81.99%\n",
      "\n",
      "\tEpoch: 29\n",
      "\tTraining Loss: 0.1573; Training Accuracy: 97.352%\n",
      "\tTesting Loss: 0.663; Testing Accuracy: 81.77%\n",
      "\n",
      "\tEpoch: 30\n",
      "\tTraining Loss: 0.1323; Training Accuracy: 97.826%\n",
      "\tTesting Loss: 0.6208; Testing Accuracy: 82.57%\n",
      "\n",
      "\tEpoch: 31\n",
      "\tTraining Loss: 0.1251; Training Accuracy: 97.898%\n",
      "\tTesting Loss: 0.7691; Testing Accuracy: 80.79%\n",
      "\n",
      "\tEpoch: 32\n",
      "\tTraining Loss: 0.1568; Training Accuracy: 97.356%\n",
      "\tTesting Loss: 0.7012; Testing Accuracy: 81.31%\n",
      "\n",
      "\tEpoch: 33\n",
      "\tTraining Loss: 0.1478; Training Accuracy: 97.55%\n",
      "\tTesting Loss: 0.687; Testing Accuracy: 82.17%\n",
      "\n",
      "\tEpoch: 34\n",
      "\tTraining Loss: 0.1471; Training Accuracy: 97.548%\n",
      "\tTesting Loss: 0.6566; Testing Accuracy: 81.68%\n",
      "\n",
      "\tEpoch: 35\n",
      "\tTraining Loss: 0.1354; Training Accuracy: 97.746%\n",
      "\tTesting Loss: 0.667; Testing Accuracy: 82.08%\n",
      "\n",
      "\tEpoch: 36\n",
      "\tTraining Loss: 0.1472; Training Accuracy: 97.488%\n",
      "\tTesting Loss: 0.6848; Testing Accuracy: 81.68%\n",
      "\n",
      "\tEpoch: 37\n",
      "\tTraining Loss: 0.1455; Training Accuracy: 97.534%\n",
      "\tTesting Loss: 0.6875; Testing Accuracy: 81.67%\n",
      "\n",
      "\tEpoch: 38\n",
      "\tTraining Loss: 0.1327; Training Accuracy: 97.79%\n",
      "\tTesting Loss: 0.7608; Testing Accuracy: 80.79%\n",
      "\n",
      "\tEpoch: 39\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     train_losses_\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     31\u001b[0m     train_accuracies_\u001b[38;5;241m.\u001b[39mappend(train_accuracy)\n",
      "Cell \u001b[1;32mIn[4], line 43\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, criterion, optimizer, dataloader, device, scheduler, use_scheduler, batch_size)\u001b[0m\n\u001b[0;32m     40\u001b[0m     cur_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     42\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 43\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     46\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m cur_correct\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\sgd.py:151\u001b[0m, in \u001b[0;36mSGD.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m             momentum_buffer_list\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum_buffer\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 151\u001b[0m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdampening\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnesterov\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\sgd.py:202\u001b[0m, in \u001b[0;36msgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_sgd\n\u001b[1;32m--> 202\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m     \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdampening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m     \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnesterov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\sgd.py:241\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[0;32m    238\u001b[0m     buf\u001b[38;5;241m.\u001b[39mmul_(momentum)\u001b[38;5;241m.\u001b[39madd_(d_p, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dampening)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nesterov:\n\u001b[1;32m--> 241\u001b[0m     d_p \u001b[38;5;241m=\u001b[39m \u001b[43md_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     d_p \u001b[38;5;241m=\u001b[39m buf\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 1, 1, 1])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9, weight_decay= 0.0001, nesterov = True)\n",
    "\n",
    "\n",
    "train_losses_ = []\n",
    "train_accuracies_ = []\n",
    "test_losses_ = []\n",
    "test_accuracies_ = []\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\tEpoch: {epoch}\")\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, trainloader, device)\n",
    "    train_losses_.append(train_loss)\n",
    "    train_accuracies_.append(train_accuracy)\n",
    "    print(f\"\\tTraining Loss: {round(train_loss, 4)}; Training Accuracy: {round(train_accuracy*100, 4)}%\")\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, criterion, testloader, device)\n",
    "    test_losses_.append(test_loss)\n",
    "    test_accuracies_.append(test_accuracy)\n",
    "    print(f\"\\tTesting Loss: {round(test_loss, 4)}; Testing Accuracy: {round(test_accuracy*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440cc652-824a-45bd-b806-5ef88c8ed4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
