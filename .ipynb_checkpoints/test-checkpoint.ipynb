{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Params: 4891338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = resnet.ResNet(resnet.BasicBlock, config['model']['zigzag'])\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Num Params: {num_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'ResNet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mdel \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mResNet(model\u001b[39m.\u001b[39mBasicBlock, config[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mdeep_narrow\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m num_params \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mnumel() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m mdel\u001b[39m.\u001b[39mparameters() \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mrequires_grad)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNum Params: \u001b[39m\u001b[39m{\u001b[39;00mnum_params\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'ResNet'"
     ]
    }
   ],
   "source": [
    "mdel = model.ResNet(model.BasicBlock, config['model']['deep_narrow'])\n",
    "num_params = sum(p.numel() for p in mdel.parameters() if p.requires_grad)\n",
    "print(f\"Num Params: {num_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Params: 4903242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mdel = model.ResNet(model.BasicBlock, config['model']['original'])\n",
    "num_params = sum(p.numel() for p in mdel.parameters() if p.requires_grad)\n",
    "print(f\"Num Params: {num_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import  BasicBlock, ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Params: 4891338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, config['model']['zigzag'])\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Num Params: {num_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = config['data']\n",
    "data = Data(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from data import Data\n",
    "from resnet import  BasicBlock, ResNet\n",
    "\n",
    "with open(\"config.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_config = config['data']\n",
    "\n",
    "model_config = config['model']\n",
    "model_config = model_config[model_config['use_model']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = Data(data_config)\n",
    "train_loader, val_loader, test_loader = data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Params: 4891338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, model_config)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Num Params: {num_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_test import TrainTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
      "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
      "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
      "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
      "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
      "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
      "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
      "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
      "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 4, 4]         294,912\n",
      "      BatchNorm2d-38            [-1, 128, 4, 4]             256\n",
      "           Conv2d-39            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-40            [-1, 128, 4, 4]             256\n",
      "           Conv2d-41            [-1, 128, 4, 4]          32,768\n",
      "      BatchNorm2d-42            [-1, 128, 4, 4]             256\n",
      "       BasicBlock-43            [-1, 128, 4, 4]               0\n",
      "           Conv2d-44            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-45            [-1, 128, 4, 4]             256\n",
      "           Conv2d-46            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-47            [-1, 128, 4, 4]             256\n",
      "       BasicBlock-48            [-1, 128, 4, 4]               0\n",
      "           Conv2d-49             [-1, 64, 2, 2]          73,728\n",
      "      BatchNorm2d-50             [-1, 64, 2, 2]             128\n",
      "           Conv2d-51             [-1, 64, 2, 2]          36,864\n",
      "      BatchNorm2d-52             [-1, 64, 2, 2]             128\n",
      "           Conv2d-53             [-1, 64, 2, 2]           8,192\n",
      "      BatchNorm2d-54             [-1, 64, 2, 2]             128\n",
      "       BasicBlock-55             [-1, 64, 2, 2]               0\n",
      "           Conv2d-56             [-1, 64, 2, 2]          36,864\n",
      "      BatchNorm2d-57             [-1, 64, 2, 2]             128\n",
      "           Conv2d-58             [-1, 64, 2, 2]          36,864\n",
      "      BatchNorm2d-59             [-1, 64, 2, 2]             128\n",
      "       BasicBlock-60             [-1, 64, 2, 2]               0\n",
      "           Conv2d-61            [-1, 128, 1, 1]          73,728\n",
      "      BatchNorm2d-62            [-1, 128, 1, 1]             256\n",
      "           Conv2d-63            [-1, 128, 1, 1]         147,456\n",
      "      BatchNorm2d-64            [-1, 128, 1, 1]             256\n",
      "           Conv2d-65            [-1, 128, 1, 1]           8,192\n",
      "      BatchNorm2d-66            [-1, 128, 1, 1]             256\n",
      "       BasicBlock-67            [-1, 128, 1, 1]               0\n",
      "           Conv2d-68            [-1, 256, 1, 1]         294,912\n",
      "      BatchNorm2d-69            [-1, 256, 1, 1]             512\n",
      "           Conv2d-70            [-1, 256, 1, 1]         589,824\n",
      "      BatchNorm2d-71            [-1, 256, 1, 1]             512\n",
      "           Conv2d-72            [-1, 256, 1, 1]          32,768\n",
      "      BatchNorm2d-73            [-1, 256, 1, 1]             512\n",
      "       BasicBlock-74            [-1, 256, 1, 1]               0\n",
      "           Linear-75                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 4,891,338\n",
      "Trainable params: 4,891,338\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 10.73\n",
      "Params size (MB): 18.66\n",
      "Estimated Total Size (MB): 29.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model.to('cuda'), (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = config['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_test import TrainTest\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_obj = TrainTest((train_loader, val_loader, test_loader), model, train_config, torch.device('cuda'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_obj.num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEpoch: 0\n",
      "\tTraining Loss: 3.4947; Training Accuracy: 35.6425%\n",
      "\tValidation Loss: 1.539; Validation Accuracy: 43.25%\n",
      "\n",
      "\tEpoch: 1\n",
      "\tTraining Loss: 2.7977; Training Accuracy: 49.4175%\n",
      "\tValidation Loss: 1.3593; Validation Accuracy: 50.6%\n"
     ]
    }
   ],
   "source": [
    "train_test_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest Loss: 1.282; Test Accuracy: 53.88%\n"
     ]
    }
   ],
   "source": [
    "train_test_obj.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader, \u001b[39m0\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(i)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\datasets\\cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    115\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img)\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:979\u001b[0m, in \u001b[0;36mRandomResizedCrop.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m    972\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[39m        img (PIL Image or Tensor): Image to be cropped and resized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[39m        PIL Image or Tensor: Randomly cropped and resized image.\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 979\u001b[0m     i, j, h, w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(img, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mratio)\n\u001b[0;32m    980\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mresized_crop(img, i, j, h, w, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterpolation, antialias\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mantialias)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:943\u001b[0m, in \u001b[0;36mRandomResizedCrop.get_params\u001b[1;34m(img, scale, ratio)\u001b[0m\n\u001b[0;32m    940\u001b[0m _, height, width \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mget_dimensions(img)\n\u001b[0;32m    941\u001b[0m area \u001b[39m=\u001b[39m height \u001b[39m*\u001b[39m width\n\u001b[1;32m--> 943\u001b[0m log_ratio \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog(torch\u001b[39m.\u001b[39;49mtensor(ratio))\n\u001b[0;32m    944\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m    945\u001b[0m     target_area \u001b[39m=\u001b[39m area \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mempty(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39muniform_(scale[\u001b[39m0\u001b[39m], scale[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mitem()\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader, 0):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"model_blocks.0.conv1.weight\", \"model_blocks.0.bn1.weight\", \"model_blocks.0.bn1.bias\", \"model_blocks.0.bn1.running_mean\", \"model_blocks.0.bn1.running_var\", \"model_blocks.0.conv2.weight\", \"model_blocks.0.bn2.weight\", \"model_blocks.0.bn2.bias\", \"model_blocks.0.bn2.running_mean\", \"model_blocks.0.bn2.running_var\", \"model_blocks.1.conv1.weight\", \"model_blocks.1.bn1.weight\", \"model_blocks.1.bn1.bias\", \"model_blocks.1.bn1.running_mean\", \"model_blocks.1.bn1.running_var\", \"model_blocks.1.conv2.weight\", \"model_blocks.1.bn2.weight\", \"model_blocks.1.bn2.bias\", \"model_blocks.1.bn2.running_mean\", \"model_blocks.1.bn2.running_var\", \"model_blocks.2.conv1.weight\", \"model_blocks.2.bn1.weight\", \"model_blocks.2.bn1.bias\", \"model_blocks.2.bn1.running_mean\", \"model_blocks.2.bn1.running_var\", \"model_blocks.2.conv2.weight\", \"model_blocks.2.bn2.weight\", \"model_blocks.2.bn2.bias\", \"model_blocks.2.bn2.running_mean\", \"model_blocks.2.bn2.running_var\", \"model_blocks.2.shortcut.0.weight\", \"model_blocks.2.shortcut.1.weight\", \"model_blocks.2.shortcut.1.bias\", \"model_blocks.2.shortcut.1.running_mean\", \"model_blocks.2.shortcut.1.running_var\", \"model_blocks.3.conv1.weight\", \"model_blocks.3.bn1.weight\", \"model_blocks.3.bn1.bias\", \"model_blocks.3.bn1.running_mean\", \"model_blocks.3.bn1.running_var\", \"model_blocks.3.conv2.weight\", \"model_blocks.3.bn2.weight\", \"model_blocks.3.bn2.bias\", \"model_blocks.3.bn2.running_mean\", \"model_blocks.3.bn2.running_var\", \"model_blocks.4.conv1.weight\", \"model_blocks.4.bn1.weight\", \"model_blocks.4.bn1.bias\", \"model_blocks.4.bn1.running_mean\", \"model_blocks.4.bn1.running_var\", \"model_blocks.4.conv2.weight\", \"model_blocks.4.bn2.weight\", \"model_blocks.4.bn2.bias\", \"model_blocks.4.bn2.running_mean\", \"model_blocks.4.bn2.running_var\", \"model_blocks.4.shortcut.0.weight\", \"model_blocks.4.shortcut.1.weight\", \"model_blocks.4.shortcut.1.bias\", \"model_blocks.4.shortcut.1.running_mean\", \"model_blocks.4.shortcut.1.running_var\", \"model_blocks.5.conv1.weight\", \"model_blocks.5.bn1.weight\", \"model_blocks.5.bn1.bias\", \"model_blocks.5.bn1.running_mean\", \"model_blocks.5.bn1.running_var\", \"model_blocks.5.conv2.weight\", \"model_blocks.5.bn2.weight\", \"model_blocks.5.bn2.bias\", \"model_blocks.5.bn2.running_mean\", \"model_blocks.5.bn2.running_var\", \"model_blocks.6.conv1.weight\", \"model_blocks.6.bn1.weight\", \"model_blocks.6.bn1.bias\", \"model_blocks.6.bn1.running_mean\", \"model_blocks.6.bn1.running_var\", \"model_blocks.6.conv2.weight\", \"model_blocks.6.bn2.weight\", \"model_blocks.6.bn2.bias\", \"model_blocks.6.bn2.running_mean\", \"model_blocks.6.bn2.running_var\", \"model_blocks.6.shortcut.0.weight\", \"model_blocks.6.shortcut.1.weight\", \"model_blocks.6.shortcut.1.bias\", \"model_blocks.6.shortcut.1.running_mean\", \"model_blocks.6.shortcut.1.running_var\", \"model_blocks.7.conv1.weight\", \"model_blocks.7.bn1.weight\", \"model_blocks.7.bn1.bias\", \"model_blocks.7.bn1.running_mean\", \"model_blocks.7.bn1.running_var\", \"model_blocks.7.conv2.weight\", \"model_blocks.7.bn2.weight\", \"model_blocks.7.bn2.bias\", \"model_blocks.7.bn2.running_mean\", \"model_blocks.7.bn2.running_var\", \"model_blocks.8.conv1.weight\", \"model_blocks.8.bn1.weight\", \"model_blocks.8.bn1.bias\", \"model_blocks.8.bn1.running_mean\", \"model_blocks.8.bn1.running_var\", \"model_blocks.8.conv2.weight\", \"model_blocks.8.bn2.weight\", \"model_blocks.8.bn2.bias\", \"model_blocks.8.bn2.running_mean\", \"model_blocks.8.bn2.running_var\", \"model_blocks.8.shortcut.0.weight\", \"model_blocks.8.shortcut.1.weight\", \"model_blocks.8.shortcut.1.bias\", \"model_blocks.8.shortcut.1.running_mean\", \"model_blocks.8.shortcut.1.running_var\", \"model_blocks.9.conv1.weight\", \"model_blocks.9.bn1.weight\", \"model_blocks.9.bn1.bias\", \"model_blocks.9.bn1.running_mean\", \"model_blocks.9.bn1.running_var\", \"model_blocks.9.conv2.weight\", \"model_blocks.9.bn2.weight\", \"model_blocks.9.bn2.bias\", \"model_blocks.9.bn2.running_mean\", \"model_blocks.9.bn2.running_var\", \"model_blocks.10.conv1.weight\", \"model_blocks.10.bn1.weight\", \"model_blocks.10.bn1.bias\", \"model_blocks.10.bn1.running_mean\", \"model_blocks.10.bn1.running_var\", \"model_blocks.10.conv2.weight\", \"model_blocks.10.bn2.weight\", \"model_blocks.10.bn2.bias\", \"model_blocks.10.bn2.running_mean\", \"model_blocks.10.bn2.running_var\", \"model_blocks.10.shortcut.0.weight\", \"model_blocks.10.shortcut.1.weight\", \"model_blocks.10.shortcut.1.bias\", \"model_blocks.10.shortcut.1.running_mean\", \"model_blocks.10.shortcut.1.running_var\", \"model_blocks.11.conv1.weight\", \"model_blocks.11.bn1.weight\", \"model_blocks.11.bn1.bias\", \"model_blocks.11.bn1.running_mean\", \"model_blocks.11.bn1.running_var\", \"model_blocks.11.conv2.weight\", \"model_blocks.11.bn2.weight\", \"model_blocks.11.bn2.bias\", \"model_blocks.11.bn2.running_mean\", \"model_blocks.11.bn2.running_var\", \"model_blocks.11.shortcut.0.weight\", \"model_blocks.11.shortcut.1.weight\", \"model_blocks.11.shortcut.1.bias\", \"model_blocks.11.shortcut.1.running_mean\", \"model_blocks.11.shortcut.1.running_var\". \n\tUnexpected key(s) in state_dict: \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.num_batches_tracked\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.num_batches_tracked\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.num_batches_tracked\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.num_batches_tracked\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.bn1.num_batches_tracked\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.bn2.num_batches_tracked\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.0.shortcut.1.num_batches_tracked\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.bn1.num_batches_tracked\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.bn2.num_batches_tracked\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.num_batches_tracked\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.num_batches_tracked\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.0.shortcut.1.num_batches_tracked\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.num_batches_tracked\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.num_batches_tracked\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.num_batches_tracked\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.num_batches_tracked\", \"layer4.0.shortcut.0.weight\", \"layer4.0.shortcut.1.weight\", \"layer4.0.shortcut.1.bias\", \"layer4.0.shortcut.1.running_mean\", \"layer4.0.shortcut.1.running_var\", \"layer4.0.shortcut.1.num_batches_tracked\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.num_batches_tracked\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.num_batches_tracked\", \"layer5.0.conv1.weight\", \"layer5.0.bn1.weight\", \"layer5.0.bn1.bias\", \"layer5.0.bn1.running_mean\", \"layer5.0.bn1.running_var\", \"layer5.0.bn1.num_batches_tracked\", \"layer5.0.conv2.weight\", \"layer5.0.bn2.weight\", \"layer5.0.bn2.bias\", \"layer5.0.bn2.running_mean\", \"layer5.0.bn2.running_var\", \"layer5.0.bn2.num_batches_tracked\", \"layer5.0.shortcut.0.weight\", \"layer5.0.shortcut.1.weight\", \"layer5.0.shortcut.1.bias\", \"layer5.0.shortcut.1.running_mean\", \"layer5.0.shortcut.1.running_var\", \"layer5.0.shortcut.1.num_batches_tracked\", \"layer5.1.conv1.weight\", \"layer5.1.bn1.weight\", \"layer5.1.bn1.bias\", \"layer5.1.bn1.running_mean\", \"layer5.1.bn1.running_var\", \"layer5.1.bn1.num_batches_tracked\", \"layer5.1.conv2.weight\", \"layer5.1.bn2.weight\", \"layer5.1.bn2.bias\", \"layer5.1.bn2.running_mean\", \"layer5.1.bn2.running_var\", \"layer5.1.bn2.num_batches_tracked\", \"layer6.0.conv1.weight\", \"layer6.0.bn1.weight\", \"layer6.0.bn1.bias\", \"layer6.0.bn1.running_mean\", \"layer6.0.bn1.running_var\", \"layer6.0.bn1.num_batches_tracked\", \"layer6.0.conv2.weight\", \"layer6.0.bn2.weight\", \"layer6.0.bn2.bias\", \"layer6.0.bn2.running_mean\", \"layer6.0.bn2.running_var\", \"layer6.0.bn2.num_batches_tracked\", \"layer6.0.shortcut.0.weight\", \"layer6.0.shortcut.1.weight\", \"layer6.0.shortcut.1.bias\", \"layer6.0.shortcut.1.running_mean\", \"layer6.0.shortcut.1.running_var\", \"layer6.0.shortcut.1.num_batches_tracked\", \"layer7.0.conv1.weight\", \"layer7.0.bn1.weight\", \"layer7.0.bn1.bias\", \"layer7.0.bn1.running_mean\", \"layer7.0.bn1.running_var\", \"layer7.0.bn1.num_batches_tracked\", \"layer7.0.conv2.weight\", \"layer7.0.bn2.weight\", \"layer7.0.bn2.bias\", \"layer7.0.bn2.running_mean\", \"layer7.0.bn2.running_var\", \"layer7.0.bn2.num_batches_tracked\", \"layer7.0.shortcut.0.weight\", \"layer7.0.shortcut.1.weight\", \"layer7.0.shortcut.1.bias\", \"layer7.0.shortcut.1.running_mean\", \"layer7.0.shortcut.1.running_var\", \"layer7.0.shortcut.1.num_batches_tracked\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m ResNet(BasicBlock, model_config)\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mmodel_store/best_model.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"model_blocks.0.conv1.weight\", \"model_blocks.0.bn1.weight\", \"model_blocks.0.bn1.bias\", \"model_blocks.0.bn1.running_mean\", \"model_blocks.0.bn1.running_var\", \"model_blocks.0.conv2.weight\", \"model_blocks.0.bn2.weight\", \"model_blocks.0.bn2.bias\", \"model_blocks.0.bn2.running_mean\", \"model_blocks.0.bn2.running_var\", \"model_blocks.1.conv1.weight\", \"model_blocks.1.bn1.weight\", \"model_blocks.1.bn1.bias\", \"model_blocks.1.bn1.running_mean\", \"model_blocks.1.bn1.running_var\", \"model_blocks.1.conv2.weight\", \"model_blocks.1.bn2.weight\", \"model_blocks.1.bn2.bias\", \"model_blocks.1.bn2.running_mean\", \"model_blocks.1.bn2.running_var\", \"model_blocks.2.conv1.weight\", \"model_blocks.2.bn1.weight\", \"model_blocks.2.bn1.bias\", \"model_blocks.2.bn1.running_mean\", \"model_blocks.2.bn1.running_var\", \"model_blocks.2.conv2.weight\", \"model_blocks.2.bn2.weight\", \"model_blocks.2.bn2.bias\", \"model_blocks.2.bn2.running_mean\", \"model_blocks.2.bn2.running_var\", \"model_blocks.2.shortcut.0.weight\", \"model_blocks.2.shortcut.1.weight\", \"model_blocks.2.shortcut.1.bias\", \"model_blocks.2.shortcut.1.running_mean\", \"model_blocks.2.shortcut.1.running_var\", \"model_blocks.3.conv1.weight\", \"model_blocks.3.bn1.weight\", \"model_blocks.3.bn1.bias\", \"model_blocks.3.bn1.running_mean\", \"model_blocks.3.bn1.running_var\", \"model_blocks.3.conv2.weight\", \"model_blocks.3.bn2.weight\", \"model_blocks.3.bn2.bias\", \"model_blocks.3.bn2.running_mean\", \"model_blocks.3.bn2.running_var\", \"model_blocks.4.conv1.weight\", \"model_blocks.4.bn1.weight\", \"model_blocks.4.bn1.bias\", \"model_blocks.4.bn1.running_mean\", \"model_blocks.4.bn1.running_var\", \"model_blocks.4.conv2.weight\", \"model_blocks.4.bn2.weight\", \"model_blocks.4.bn2.bias\", \"model_blocks.4.bn2.running_mean\", \"model_blocks.4.bn2.running_var\", \"model_blocks.4.shortcut.0.weight\", \"model_blocks.4.shortcut.1.weight\", \"model_blocks.4.shortcut.1.bias\", \"model_blocks.4.shortcut.1.running_mean\", \"model_blocks.4.shortcut.1.running_var\", \"model_blocks.5.conv1.weight\", \"model_blocks.5.bn1.weight\", \"model_blocks.5.bn1.bias\", \"model_blocks.5.bn1.running_mean\", \"model_blocks.5.bn1.running_var\", \"model_blocks.5.conv2.weight\", \"model_blocks.5.bn2.weight\", \"model_blocks.5.bn2.bias\", \"model_blocks.5.bn2.running_mean\", \"model_blocks.5.bn2.running_var\", \"model_blocks.6.conv1.weight\", \"model_blocks.6.bn1.weight\", \"model_blocks.6.bn1.bias\", \"model_blocks.6.bn1.running_mean\", \"model_blocks.6.bn1.running_var\", \"model_blocks.6.conv2.weight\", \"model_blocks.6.bn2.weight\", \"model_blocks.6.bn2.bias\", \"model_blocks.6.bn2.running_mean\", \"model_blocks.6.bn2.running_var\", \"model_blocks.6.shortcut.0.weight\", \"model_blocks.6.shortcut.1.weight\", \"model_blocks.6.shortcut.1.bias\", \"model_blocks.6.shortcut.1.running_mean\", \"model_blocks.6.shortcut.1.running_var\", \"model_blocks.7.conv1.weight\", \"model_blocks.7.bn1.weight\", \"model_blocks.7.bn1.bias\", \"model_blocks.7.bn1.running_mean\", \"model_blocks.7.bn1.running_var\", \"model_blocks.7.conv2.weight\", \"model_blocks.7.bn2.weight\", \"model_blocks.7.bn2.bias\", \"model_blocks.7.bn2.running_mean\", \"model_blocks.7.bn2.running_var\", \"model_blocks.8.conv1.weight\", \"model_blocks.8.bn1.weight\", \"model_blocks.8.bn1.bias\", \"model_blocks.8.bn1.running_mean\", \"model_blocks.8.bn1.running_var\", \"model_blocks.8.conv2.weight\", \"model_blocks.8.bn2.weight\", \"model_blocks.8.bn2.bias\", \"model_blocks.8.bn2.running_mean\", \"model_blocks.8.bn2.running_var\", \"model_blocks.8.shortcut.0.weight\", \"model_blocks.8.shortcut.1.weight\", \"model_blocks.8.shortcut.1.bias\", \"model_blocks.8.shortcut.1.running_mean\", \"model_blocks.8.shortcut.1.running_var\", \"model_blocks.9.conv1.weight\", \"model_blocks.9.bn1.weight\", \"model_blocks.9.bn1.bias\", \"model_blocks.9.bn1.running_mean\", \"model_blocks.9.bn1.running_var\", \"model_blocks.9.conv2.weight\", \"model_blocks.9.bn2.weight\", \"model_blocks.9.bn2.bias\", \"model_blocks.9.bn2.running_mean\", \"model_blocks.9.bn2.running_var\", \"model_blocks.10.conv1.weight\", \"model_blocks.10.bn1.weight\", \"model_blocks.10.bn1.bias\", \"model_blocks.10.bn1.running_mean\", \"model_blocks.10.bn1.running_var\", \"model_blocks.10.conv2.weight\", \"model_blocks.10.bn2.weight\", \"model_blocks.10.bn2.bias\", \"model_blocks.10.bn2.running_mean\", \"model_blocks.10.bn2.running_var\", \"model_blocks.10.shortcut.0.weight\", \"model_blocks.10.shortcut.1.weight\", \"model_blocks.10.shortcut.1.bias\", \"model_blocks.10.shortcut.1.running_mean\", \"model_blocks.10.shortcut.1.running_var\", \"model_blocks.11.conv1.weight\", \"model_blocks.11.bn1.weight\", \"model_blocks.11.bn1.bias\", \"model_blocks.11.bn1.running_mean\", \"model_blocks.11.bn1.running_var\", \"model_blocks.11.conv2.weight\", \"model_blocks.11.bn2.weight\", \"model_blocks.11.bn2.bias\", \"model_blocks.11.bn2.running_mean\", \"model_blocks.11.bn2.running_var\", \"model_blocks.11.shortcut.0.weight\", \"model_blocks.11.shortcut.1.weight\", \"model_blocks.11.shortcut.1.bias\", \"model_blocks.11.shortcut.1.running_mean\", \"model_blocks.11.shortcut.1.running_var\". \n\tUnexpected key(s) in state_dict: \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.num_batches_tracked\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.num_batches_tracked\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.num_batches_tracked\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.num_batches_tracked\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.bn1.num_batches_tracked\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.bn2.num_batches_tracked\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.0.shortcut.1.num_batches_tracked\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.bn1.num_batches_tracked\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.bn2.num_batches_tracked\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.num_batches_tracked\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.num_batches_tracked\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.0.shortcut.1.num_batches_tracked\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.num_batches_tracked\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.num_batches_tracked\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.num_batches_tracked\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.num_batches_tracked\", \"layer4.0.shortcut.0.weight\", \"layer4.0.shortcut.1.weight\", \"layer4.0.shortcut.1.bias\", \"layer4.0.shortcut.1.running_mean\", \"layer4.0.shortcut.1.running_var\", \"layer4.0.shortcut.1.num_batches_tracked\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.num_batches_tracked\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.num_batches_tracked\", \"layer5.0.conv1.weight\", \"layer5.0.bn1.weight\", \"layer5.0.bn1.bias\", \"layer5.0.bn1.running_mean\", \"layer5.0.bn1.running_var\", \"layer5.0.bn1.num_batches_tracked\", \"layer5.0.conv2.weight\", \"layer5.0.bn2.weight\", \"layer5.0.bn2.bias\", \"layer5.0.bn2.running_mean\", \"layer5.0.bn2.running_var\", \"layer5.0.bn2.num_batches_tracked\", \"layer5.0.shortcut.0.weight\", \"layer5.0.shortcut.1.weight\", \"layer5.0.shortcut.1.bias\", \"layer5.0.shortcut.1.running_mean\", \"layer5.0.shortcut.1.running_var\", \"layer5.0.shortcut.1.num_batches_tracked\", \"layer5.1.conv1.weight\", \"layer5.1.bn1.weight\", \"layer5.1.bn1.bias\", \"layer5.1.bn1.running_mean\", \"layer5.1.bn1.running_var\", \"layer5.1.bn1.num_batches_tracked\", \"layer5.1.conv2.weight\", \"layer5.1.bn2.weight\", \"layer5.1.bn2.bias\", \"layer5.1.bn2.running_mean\", \"layer5.1.bn2.running_var\", \"layer5.1.bn2.num_batches_tracked\", \"layer6.0.conv1.weight\", \"layer6.0.bn1.weight\", \"layer6.0.bn1.bias\", \"layer6.0.bn1.running_mean\", \"layer6.0.bn1.running_var\", \"layer6.0.bn1.num_batches_tracked\", \"layer6.0.conv2.weight\", \"layer6.0.bn2.weight\", \"layer6.0.bn2.bias\", \"layer6.0.bn2.running_mean\", \"layer6.0.bn2.running_var\", \"layer6.0.bn2.num_batches_tracked\", \"layer6.0.shortcut.0.weight\", \"layer6.0.shortcut.1.weight\", \"layer6.0.shortcut.1.bias\", \"layer6.0.shortcut.1.running_mean\", \"layer6.0.shortcut.1.running_var\", \"layer6.0.shortcut.1.num_batches_tracked\", \"layer7.0.conv1.weight\", \"layer7.0.bn1.weight\", \"layer7.0.bn1.bias\", \"layer7.0.bn1.running_mean\", \"layer7.0.bn1.running_var\", \"layer7.0.bn1.num_batches_tracked\", \"layer7.0.conv2.weight\", \"layer7.0.bn2.weight\", \"layer7.0.bn2.bias\", \"layer7.0.bn2.running_mean\", \"layer7.0.bn2.running_var\", \"layer7.0.bn2.num_batches_tracked\", \"layer7.0.shortcut.0.weight\", \"layer7.0.shortcut.1.weight\", \"layer7.0.shortcut.1.bias\", \"layer7.0.shortcut.1.running_mean\", \"layer7.0.shortcut.1.running_var\", \"layer7.0.shortcut.1.num_batches_tracked\". "
     ]
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, model_config)\n",
    "model.load_state_dict(torch.load(\"model_store/best_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"./model_store/best_model.pth\")\n",
    "sd_keys = list(state_dict.keys())\n",
    "len(sd_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmd_keys = list(model.state_dict().keys())\n",
    "len(lmd_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer5.0.conv1.weight', 'layer5.0.bn1.weight', 'layer5.0.bn1.bias', 'layer5.0.bn1.running_mean', 'layer5.0.bn1.running_var', 'layer5.0.bn1.num_batches_tracked', 'layer5.0.conv2.weight', 'layer5.0.bn2.weight', 'layer5.0.bn2.bias', 'layer5.0.bn2.running_mean', 'layer5.0.bn2.running_var', 'layer5.0.bn2.num_batches_tracked', 'layer5.0.shortcut.0.weight', 'layer5.0.shortcut.1.weight', 'layer5.0.shortcut.1.bias', 'layer5.0.shortcut.1.running_mean', 'layer5.0.shortcut.1.running_var', 'layer5.0.shortcut.1.num_batches_tracked', 'layer5.1.conv1.weight', 'layer5.1.bn1.weight', 'layer5.1.bn1.bias', 'layer5.1.bn1.running_mean', 'layer5.1.bn1.running_var', 'layer5.1.bn1.num_batches_tracked', 'layer5.1.conv2.weight', 'layer5.1.bn2.weight', 'layer5.1.bn2.bias', 'layer5.1.bn2.running_mean', 'layer5.1.bn2.running_var', 'layer5.1.bn2.num_batches_tracked', 'layer6.0.conv1.weight', 'layer6.0.bn1.weight', 'layer6.0.bn1.bias', 'layer6.0.bn1.running_mean', 'layer6.0.bn1.running_var', 'layer6.0.bn1.num_batches_tracked', 'layer6.0.conv2.weight', 'layer6.0.bn2.weight', 'layer6.0.bn2.bias', 'layer6.0.bn2.running_mean', 'layer6.0.bn2.running_var', 'layer6.0.bn2.num_batches_tracked', 'layer6.0.shortcut.0.weight', 'layer6.0.shortcut.1.weight', 'layer6.0.shortcut.1.bias', 'layer6.0.shortcut.1.running_mean', 'layer6.0.shortcut.1.running_var', 'layer6.0.shortcut.1.num_batches_tracked', 'layer7.0.conv1.weight', 'layer7.0.bn1.weight', 'layer7.0.bn1.bias', 'layer7.0.bn1.running_mean', 'layer7.0.bn1.running_var', 'layer7.0.bn1.num_batches_tracked', 'layer7.0.conv2.weight', 'layer7.0.bn2.weight', 'layer7.0.bn2.bias', 'layer7.0.bn2.running_mean', 'layer7.0.bn2.running_var', 'layer7.0.bn2.num_batches_tracked', 'layer7.0.shortcut.0.weight', 'layer7.0.shortcut.1.weight', 'layer7.0.shortcut.1.bias', 'layer7.0.shortcut.1.running_mean', 'layer7.0.shortcut.1.running_var', 'layer7.0.shortcut.1.num_batches_tracked', 'linear.weight', 'linear.bias'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys() = lmd_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "state_dict = OrderedDict((lmd_keys[i], value) for i, (key, value) in enumerate(state_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, model_config)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_obj.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\suriy\\AppData\\Local\\Temp\\ipykernel_9480\\1150101841.py\", line 1, in <module>\n",
      "    train_test_obj.test()\n",
      "  File \"c:\\Users\\suriy\\OneDrive\\Desktop\\NYU\\ECE-7123\\MiniProject\\Modified-ResNet\\train_test.py\", line 60, in test\n",
      "  File \"c:\\Users\\suriy\\OneDrive\\Desktop\\NYU\\ECE-7123\\MiniProject\\Modified-ResNet\\train_test.py\", line 112, in eval_step\n",
      "    image = image.to(self.device)\n",
      "  File \"C:\\Users\\suriy\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\suriy\\OneDrive\\Desktop\\NYU\\ECE-7123\\MiniProject\\Modified-ResNet\\resnet.py\", line 61, in forward\n",
      "    out = F.relu(self.bn1(self.conv1(x)))\n",
      "  File \"C:\\Users\\suriy\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\suriy\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"C:\\Users\\suriy\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2052, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\suriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\executing\\executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "train_test_obj.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['sd'] = sd_keys\n",
    "df['model'] = lmd_keys\n",
    "df.to_csv('keys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state_dict, './model_store/best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
